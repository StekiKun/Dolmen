<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="UTF-8">
<!--[if IE]><meta http-equiv="X-UA-Compatible" content="IE=edge"><![endif]-->
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<meta name="generator" content="Asciidoctor 1.5.5">
<meta name="author" content="Stéphane Lescuyer">
<title>Dolmen: A Generator for Lexical Analyzers and Parsers in Java</title>
<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:300,300italic,400,400italic,600,600italic%7CNoto+Serif:400,400italic,700,700italic%7CDroid+Sans+Mono:400,700">
<style>
/* Asciidoctor default stylesheet | MIT License | http://asciidoctor.org */
/* Remove comment around @import statement below when using as a custom stylesheet */
/*@import "https://fonts.googleapis.com/css?family=Open+Sans:300,300italic,400,400italic,600,600italic%7CNoto+Serif:400,400italic,700,700italic%7CDroid+Sans+Mono:400,700";*/
article,aside,details,figcaption,figure,footer,header,hgroup,main,nav,section,summary{display:block}
audio,canvas,video{display:inline-block}
audio:not([controls]){display:none;height:0}
[hidden],template{display:none}
script{display:none!important}
html{font-family:sans-serif;-ms-text-size-adjust:100%;-webkit-text-size-adjust:100%}
a{background:transparent}
a:focus{outline:thin dotted}
a:active,a:hover{outline:0}
h1{font-size:2em;margin:.67em 0}
abbr[title]{border-bottom:1px dotted}
b,strong{font-weight:bold}
dfn{font-style:italic}
hr{-moz-box-sizing:content-box;box-sizing:content-box;height:0}
mark{background:#ff0;color:#000}
code,kbd,pre,samp{font-family:monospace;font-size:1em}
pre{white-space:pre-wrap}
q{quotes:"\201C" "\201D" "\2018" "\2019"}
small{font-size:80%}
sub,sup{font-size:75%;line-height:0;position:relative;vertical-align:baseline}
sup{top:-.5em}
sub{bottom:-.25em}
img{border:0}
svg:not(:root){overflow:hidden}
figure{margin:0}
fieldset{border:1px solid silver;margin:0 2px;padding:.35em .625em .75em}
legend{border:0;padding:0}
button,input,select,textarea{font-family:inherit;font-size:100%;margin:0}
button,input{line-height:normal}
button,select{text-transform:none}
button,html input[type="button"],input[type="reset"],input[type="submit"]{-webkit-appearance:button;cursor:pointer}
button[disabled],html input[disabled]{cursor:default}
input[type="checkbox"],input[type="radio"]{box-sizing:border-box;padding:0}
input[type="search"]{-webkit-appearance:textfield;-moz-box-sizing:content-box;-webkit-box-sizing:content-box;box-sizing:content-box}
input[type="search"]::-webkit-search-cancel-button,input[type="search"]::-webkit-search-decoration{-webkit-appearance:none}
button::-moz-focus-inner,input::-moz-focus-inner{border:0;padding:0}
textarea{overflow:auto;vertical-align:top}
table{border-collapse:collapse;border-spacing:0}
*,*:before,*:after{-moz-box-sizing:border-box;-webkit-box-sizing:border-box;box-sizing:border-box}
html,body{font-size:100%}
body{background:#fff;color:rgba(0,0,0,.8);padding:0;margin:0;font-family:"Noto Serif","DejaVu Serif",serif;font-weight:400;font-style:normal;line-height:1;position:relative;cursor:auto;tab-size:4;-moz-osx-font-smoothing:grayscale;-webkit-font-smoothing:antialiased}
a:hover{cursor:pointer}
img,object,embed{max-width:100%;height:auto}
object,embed{height:100%}
img{-ms-interpolation-mode:bicubic}
.left{float:left!important}
.right{float:right!important}
.text-left{text-align:left!important}
.text-right{text-align:right!important}
.text-center{text-align:center!important}
.text-justify{text-align:justify!important}
.hide{display:none}
img,object,svg{display:inline-block;vertical-align:middle}
textarea{height:auto;min-height:50px}
select{width:100%}
.center{margin-left:auto;margin-right:auto}
.spread{width:100%}
p.lead,.paragraph.lead>p,#preamble>.sectionbody>.paragraph:first-of-type p{font-size:1.21875em;line-height:1.6}
.subheader,.admonitionblock td.content>.title,.audioblock>.title,.exampleblock>.title,.imageblock>.title,.listingblock>.title,.literalblock>.title,.stemblock>.title,.openblock>.title,.paragraph>.title,.quoteblock>.title,table.tableblock>.title,.verseblock>.title,.videoblock>.title,.dlist>.title,.olist>.title,.ulist>.title,.qlist>.title,.hdlist>.title{line-height:1.45;color:#7a2518;font-weight:400;margin-top:0;margin-bottom:.25em}
div,dl,dt,dd,ul,ol,li,h1,h2,h3,#toctitle,.sidebarblock>.content>.title,h4,h5,h6,pre,form,p,blockquote,th,td{margin:0;padding:0;direction:ltr}
a{color:#2156a5;text-decoration:underline;line-height:inherit}
a:hover,a:focus{color:#1d4b8f}
a img{border:none}
p{font-family:inherit;font-weight:400;font-size:1em;line-height:1.6;margin-bottom:1.25em;text-rendering:optimizeLegibility}
p aside{font-size:.875em;line-height:1.35;font-style:italic}
h1,h2,h3,#toctitle,.sidebarblock>.content>.title,h4,h5,h6{font-family:"Open Sans","DejaVu Sans",sans-serif;font-weight:300;font-style:normal;color:#ba3925;text-rendering:optimizeLegibility;margin-top:1em;margin-bottom:.5em;line-height:1.0125em}
h1 small,h2 small,h3 small,#toctitle small,.sidebarblock>.content>.title small,h4 small,h5 small,h6 small{font-size:60%;color:#e99b8f;line-height:0}
h1{font-size:2.125em}
h2{font-size:1.6875em}
h3,#toctitle,.sidebarblock>.content>.title{font-size:1.375em}
h4,h5{font-size:1.125em}
h6{font-size:1em}
hr{border:solid #ddddd8;border-width:1px 0 0;clear:both;margin:1.25em 0 1.1875em;height:0}
em,i{font-style:italic;line-height:inherit}
strong,b{font-weight:bold;line-height:inherit}
small{font-size:60%;line-height:inherit}
code{font-family:"Droid Sans Mono","DejaVu Sans Mono",monospace;font-weight:400;color:rgba(0,0,0,.9)}
ul,ol,dl{font-size:1em;line-height:1.6;margin-bottom:1.25em;list-style-position:outside;font-family:inherit}
ul,ol,ul.no-bullet,ol.no-bullet{margin-left:1.5em}
ul li ul,ul li ol{margin-left:1.25em;margin-bottom:0;font-size:1em}
ul.square li ul,ul.circle li ul,ul.disc li ul{list-style:inherit}
ul.square{list-style-type:square}
ul.circle{list-style-type:circle}
ul.disc{list-style-type:disc}
ul.no-bullet{list-style:none}
ol li ul,ol li ol{margin-left:1.25em;margin-bottom:0}
dl dt{margin-bottom:.3125em;font-weight:bold}
dl dd{margin-bottom:1.25em}
abbr,acronym{text-transform:uppercase;font-size:90%;color:rgba(0,0,0,.8);border-bottom:1px dotted #ddd;cursor:help}
abbr{text-transform:none}
blockquote{margin:0 0 1.25em;padding:.5625em 1.25em 0 1.1875em;border-left:1px solid #ddd}
blockquote cite{display:block;font-size:.9375em;color:rgba(0,0,0,.6)}
blockquote cite:before{content:"\2014 \0020"}
blockquote cite a,blockquote cite a:visited{color:rgba(0,0,0,.6)}
blockquote,blockquote p{line-height:1.6;color:rgba(0,0,0,.85)}
@media only screen and (min-width:768px){h1,h2,h3,#toctitle,.sidebarblock>.content>.title,h4,h5,h6{line-height:1.2}
h1{font-size:2.75em}
h2{font-size:2.3125em}
h3,#toctitle,.sidebarblock>.content>.title{font-size:1.6875em}
h4{font-size:1.4375em}}
table{background:#fff;margin-bottom:1.25em;border:solid 1px #dedede}
table thead,table tfoot{background:#f7f8f7;font-weight:bold}
table thead tr th,table thead tr td,table tfoot tr th,table tfoot tr td{padding:.5em .625em .625em;font-size:inherit;color:rgba(0,0,0,.8);text-align:left}
table tr th,table tr td{padding:.5625em .625em;font-size:inherit;color:rgba(0,0,0,.8)}
table tr.even,table tr.alt,table tr:nth-of-type(even){background:#f8f8f7}
table thead tr th,table tfoot tr th,table tbody tr td,table tr td,table tfoot tr td{display:table-cell;line-height:1.6}
h1,h2,h3,#toctitle,.sidebarblock>.content>.title,h4,h5,h6{line-height:1.2;word-spacing:-.05em}
h1 strong,h2 strong,h3 strong,#toctitle strong,.sidebarblock>.content>.title strong,h4 strong,h5 strong,h6 strong{font-weight:400}
.clearfix:before,.clearfix:after,.float-group:before,.float-group:after{content:" ";display:table}
.clearfix:after,.float-group:after{clear:both}
*:not(pre)>code{font-size:.9375em;font-style:normal!important;letter-spacing:0;padding:.1em .5ex;word-spacing:-.15em;background-color:#f7f7f8;-webkit-border-radius:4px;border-radius:4px;line-height:1.45;text-rendering:optimizeSpeed;word-wrap:break-word}
*:not(pre)>code.nobreak{word-wrap:normal}
*:not(pre)>code.nowrap{white-space:nowrap}
pre,pre>code{line-height:1.45;color:rgba(0,0,0,.9);font-family:"Droid Sans Mono","DejaVu Sans Mono",monospace;font-weight:400;text-rendering:optimizeSpeed}
em em{font-style:normal}
strong strong{font-weight:400}
.keyseq{color:rgba(51,51,51,.8)}
kbd{font-family:"Droid Sans Mono","DejaVu Sans Mono",monospace;display:inline-block;color:rgba(0,0,0,.8);font-size:.65em;line-height:1.45;background-color:#f7f7f7;border:1px solid #ccc;-webkit-border-radius:3px;border-radius:3px;-webkit-box-shadow:0 1px 0 rgba(0,0,0,.2),0 0 0 .1em white inset;box-shadow:0 1px 0 rgba(0,0,0,.2),0 0 0 .1em #fff inset;margin:0 .15em;padding:.2em .5em;vertical-align:middle;position:relative;top:-.1em;white-space:nowrap}
.keyseq kbd:first-child{margin-left:0}
.keyseq kbd:last-child{margin-right:0}
.menuseq,.menu{color:rgba(0,0,0,.8)}
b.button:before,b.button:after{position:relative;top:-1px;font-weight:400}
b.button:before{content:"[";padding:0 3px 0 2px}
b.button:after{content:"]";padding:0 2px 0 3px}
p a>code:hover{color:rgba(0,0,0,.9)}
#header,#content,#footnotes,#footer{width:100%;margin-left:auto;margin-right:auto;margin-top:0;margin-bottom:0;max-width:62.5em;*zoom:1;position:relative;padding-left:.9375em;padding-right:.9375em}
#header:before,#header:after,#content:before,#content:after,#footnotes:before,#footnotes:after,#footer:before,#footer:after{content:" ";display:table}
#header:after,#content:after,#footnotes:after,#footer:after{clear:both}
#content{margin-top:1.25em}
#content:before{content:none}
#header>h1:first-child{color:rgba(0,0,0,.85);margin-top:2.25rem;margin-bottom:0}
#header>h1:first-child+#toc{margin-top:8px;border-top:1px solid #ddddd8}
#header>h1:only-child,body.toc2 #header>h1:nth-last-child(2){border-bottom:1px solid #ddddd8;padding-bottom:8px}
#header .details{border-bottom:1px solid #ddddd8;line-height:1.45;padding-top:.25em;padding-bottom:.25em;padding-left:.25em;color:rgba(0,0,0,.6);display:-ms-flexbox;display:-webkit-flex;display:flex;-ms-flex-flow:row wrap;-webkit-flex-flow:row wrap;flex-flow:row wrap}
#header .details span:first-child{margin-left:-.125em}
#header .details span.email a{color:rgba(0,0,0,.85)}
#header .details br{display:none}
#header .details br+span:before{content:"\00a0\2013\00a0"}
#header .details br+span.author:before{content:"\00a0\22c5\00a0";color:rgba(0,0,0,.85)}
#header .details br+span#revremark:before{content:"\00a0|\00a0"}
#header #revnumber{text-transform:capitalize}
#header #revnumber:after{content:"\00a0"}
#content>h1:first-child:not([class]){color:rgba(0,0,0,.85);border-bottom:1px solid #ddddd8;padding-bottom:8px;margin-top:0;padding-top:1rem;margin-bottom:1.25rem}
#toc{border-bottom:1px solid #efefed;padding-bottom:.5em}
#toc>ul{margin-left:.125em}
#toc ul.sectlevel0>li>a{font-style:italic}
#toc ul.sectlevel0 ul.sectlevel1{margin:.5em 0}
#toc ul{font-family:"Open Sans","DejaVu Sans",sans-serif;list-style-type:none}
#toc li{line-height:1.3334;margin-top:.3334em}
#toc a{text-decoration:none}
#toc a:active{text-decoration:underline}
#toctitle{color:#7a2518;font-size:1.2em}
@media only screen and (min-width:768px){#toctitle{font-size:1.375em}
body.toc2{padding-left:15em;padding-right:0}
#toc.toc2{margin-top:0!important;background-color:#f8f8f7;position:fixed;width:15em;left:0;top:0;border-right:1px solid #efefed;border-top-width:0!important;border-bottom-width:0!important;z-index:1000;padding:1.25em 1em;height:100%;overflow:auto}
#toc.toc2 #toctitle{margin-top:0;margin-bottom:.8rem;font-size:1.2em}
#toc.toc2>ul{font-size:.9em;margin-bottom:0}
#toc.toc2 ul ul{margin-left:0;padding-left:1em}
#toc.toc2 ul.sectlevel0 ul.sectlevel1{padding-left:0;margin-top:.5em;margin-bottom:.5em}
body.toc2.toc-right{padding-left:0;padding-right:15em}
body.toc2.toc-right #toc.toc2{border-right-width:0;border-left:1px solid #efefed;left:auto;right:0}}
@media only screen and (min-width:1280px){body.toc2{padding-left:20em;padding-right:0}
#toc.toc2{width:20em}
#toc.toc2 #toctitle{font-size:1.375em}
#toc.toc2>ul{font-size:.95em}
#toc.toc2 ul ul{padding-left:1.25em}
body.toc2.toc-right{padding-left:0;padding-right:20em}}
#content #toc{border-style:solid;border-width:1px;border-color:#e0e0dc;margin-bottom:1.25em;padding:1.25em;background:#f8f8f7;-webkit-border-radius:4px;border-radius:4px}
#content #toc>:first-child{margin-top:0}
#content #toc>:last-child{margin-bottom:0}
#footer{max-width:100%;background-color:rgba(0,0,0,.8);padding:1.25em}
#footer-text{color:rgba(255,255,255,.8);line-height:1.44}
.sect1{padding-bottom:.625em}
@media only screen and (min-width:768px){.sect1{padding-bottom:1.25em}}
.sect1+.sect1{border-top:1px solid #efefed}
#content h1>a.anchor,h2>a.anchor,h3>a.anchor,#toctitle>a.anchor,.sidebarblock>.content>.title>a.anchor,h4>a.anchor,h5>a.anchor,h6>a.anchor{position:absolute;z-index:1001;width:1.5ex;margin-left:-1.5ex;display:block;text-decoration:none!important;visibility:hidden;text-align:center;font-weight:400}
#content h1>a.anchor:before,h2>a.anchor:before,h3>a.anchor:before,#toctitle>a.anchor:before,.sidebarblock>.content>.title>a.anchor:before,h4>a.anchor:before,h5>a.anchor:before,h6>a.anchor:before{content:"\00A7";font-size:.85em;display:block;padding-top:.1em}
#content h1:hover>a.anchor,#content h1>a.anchor:hover,h2:hover>a.anchor,h2>a.anchor:hover,h3:hover>a.anchor,#toctitle:hover>a.anchor,.sidebarblock>.content>.title:hover>a.anchor,h3>a.anchor:hover,#toctitle>a.anchor:hover,.sidebarblock>.content>.title>a.anchor:hover,h4:hover>a.anchor,h4>a.anchor:hover,h5:hover>a.anchor,h5>a.anchor:hover,h6:hover>a.anchor,h6>a.anchor:hover{visibility:visible}
#content h1>a.link,h2>a.link,h3>a.link,#toctitle>a.link,.sidebarblock>.content>.title>a.link,h4>a.link,h5>a.link,h6>a.link{color:#ba3925;text-decoration:none}
#content h1>a.link:hover,h2>a.link:hover,h3>a.link:hover,#toctitle>a.link:hover,.sidebarblock>.content>.title>a.link:hover,h4>a.link:hover,h5>a.link:hover,h6>a.link:hover{color:#a53221}
.audioblock,.imageblock,.literalblock,.listingblock,.stemblock,.videoblock{margin-bottom:1.25em}
.admonitionblock td.content>.title,.audioblock>.title,.exampleblock>.title,.imageblock>.title,.listingblock>.title,.literalblock>.title,.stemblock>.title,.openblock>.title,.paragraph>.title,.quoteblock>.title,table.tableblock>.title,.verseblock>.title,.videoblock>.title,.dlist>.title,.olist>.title,.ulist>.title,.qlist>.title,.hdlist>.title{text-rendering:optimizeLegibility;text-align:left;font-family:"Noto Serif","DejaVu Serif",serif;font-size:1rem;font-style:italic}
table.tableblock>caption.title{white-space:nowrap;overflow:visible;max-width:0}
.paragraph.lead>p,#preamble>.sectionbody>.paragraph:first-of-type p{color:rgba(0,0,0,.85)}
table.tableblock #preamble>.sectionbody>.paragraph:first-of-type p{font-size:inherit}
.admonitionblock>table{border-collapse:separate;border:0;background:none;width:100%}
.admonitionblock>table td.icon{text-align:center;width:80px}
.admonitionblock>table td.icon img{max-width:none}
.admonitionblock>table td.icon .title{font-weight:bold;font-family:"Open Sans","DejaVu Sans",sans-serif;text-transform:uppercase}
.admonitionblock>table td.content{padding-left:1.125em;padding-right:1.25em;border-left:1px solid #ddddd8;color:rgba(0,0,0,.6)}
.admonitionblock>table td.content>:last-child>:last-child{margin-bottom:0}
.exampleblock>.content{border-style:solid;border-width:1px;border-color:#e6e6e6;margin-bottom:1.25em;padding:1.25em;background:#fff;-webkit-border-radius:4px;border-radius:4px}
.exampleblock>.content>:first-child{margin-top:0}
.exampleblock>.content>:last-child{margin-bottom:0}
.sidebarblock{border-style:solid;border-width:1px;border-color:#e0e0dc;margin-bottom:1.25em;padding:1.25em;background:#f8f8f7;-webkit-border-radius:4px;border-radius:4px}
.sidebarblock>:first-child{margin-top:0}
.sidebarblock>:last-child{margin-bottom:0}
.sidebarblock>.content>.title{color:#7a2518;margin-top:0;text-align:center}
.exampleblock>.content>:last-child>:last-child,.exampleblock>.content .olist>ol>li:last-child>:last-child,.exampleblock>.content .ulist>ul>li:last-child>:last-child,.exampleblock>.content .qlist>ol>li:last-child>:last-child,.sidebarblock>.content>:last-child>:last-child,.sidebarblock>.content .olist>ol>li:last-child>:last-child,.sidebarblock>.content .ulist>ul>li:last-child>:last-child,.sidebarblock>.content .qlist>ol>li:last-child>:last-child{margin-bottom:0}
.literalblock pre,.listingblock pre:not(.highlight),.listingblock pre[class="highlight"],.listingblock pre[class^="highlight "],.listingblock pre.CodeRay,.listingblock pre.prettyprint{background:#f7f7f8}
.sidebarblock .literalblock pre,.sidebarblock .listingblock pre:not(.highlight),.sidebarblock .listingblock pre[class="highlight"],.sidebarblock .listingblock pre[class^="highlight "],.sidebarblock .listingblock pre.CodeRay,.sidebarblock .listingblock pre.prettyprint{background:#f2f1f1}
.literalblock pre,.literalblock pre[class],.listingblock pre,.listingblock pre[class]{-webkit-border-radius:4px;border-radius:4px;word-wrap:break-word;padding:1em;font-size:.8125em}
.literalblock pre.nowrap,.literalblock pre[class].nowrap,.listingblock pre.nowrap,.listingblock pre[class].nowrap{overflow-x:auto;white-space:pre;word-wrap:normal}
@media only screen and (min-width:768px){.literalblock pre,.literalblock pre[class],.listingblock pre,.listingblock pre[class]{font-size:.90625em}}
@media only screen and (min-width:1280px){.literalblock pre,.literalblock pre[class],.listingblock pre,.listingblock pre[class]{font-size:1em}}
.literalblock.output pre{color:#f7f7f8;background-color:rgba(0,0,0,.9)}
.listingblock pre.highlightjs{padding:0}
.listingblock pre.highlightjs>code{padding:1em;-webkit-border-radius:4px;border-radius:4px}
.listingblock pre.prettyprint{border-width:0}
.listingblock>.content{position:relative}
.listingblock code[data-lang]:before{display:none;content:attr(data-lang);position:absolute;font-size:.75em;top:.425rem;right:.5rem;line-height:1;text-transform:uppercase;color:#999}
.listingblock:hover code[data-lang]:before{display:block}
.listingblock.terminal pre .command:before{content:attr(data-prompt);padding-right:.5em;color:#999}
.listingblock.terminal pre .command:not([data-prompt]):before{content:"$"}
table.pyhltable{border-collapse:separate;border:0;margin-bottom:0;background:none}
table.pyhltable td{vertical-align:top;padding-top:0;padding-bottom:0;line-height:1.45}
table.pyhltable td.code{padding-left:.75em;padding-right:0}
pre.pygments .lineno,table.pyhltable td:not(.code){color:#999;padding-left:0;padding-right:.5em;border-right:1px solid #ddddd8}
pre.pygments .lineno{display:inline-block;margin-right:.25em}
table.pyhltable .linenodiv{background:none!important;padding-right:0!important}
.quoteblock{margin:0 1em 1.25em 1.5em;display:table}
.quoteblock>.title{margin-left:-1.5em;margin-bottom:.75em}
.quoteblock blockquote,.quoteblock blockquote p{color:rgba(0,0,0,.85);font-size:1.15rem;line-height:1.75;word-spacing:.1em;letter-spacing:0;font-style:italic;text-align:justify}
.quoteblock blockquote{margin:0;padding:0;border:0}
.quoteblock blockquote:before{content:"\201c";float:left;font-size:2.75em;font-weight:bold;line-height:.6em;margin-left:-.6em;color:#7a2518;text-shadow:0 1px 2px rgba(0,0,0,.1)}
.quoteblock blockquote>.paragraph:last-child p{margin-bottom:0}
.quoteblock .attribution{margin-top:.5em;margin-right:.5ex;text-align:right}
.quoteblock .quoteblock{margin-left:0;margin-right:0;padding:.5em 0;border-left:3px solid rgba(0,0,0,.6)}
.quoteblock .quoteblock blockquote{padding:0 0 0 .75em}
.quoteblock .quoteblock blockquote:before{display:none}
.verseblock{margin:0 1em 1.25em 1em}
.verseblock pre{font-family:"Open Sans","DejaVu Sans",sans;font-size:1.15rem;color:rgba(0,0,0,.85);font-weight:300;text-rendering:optimizeLegibility}
.verseblock pre strong{font-weight:400}
.verseblock .attribution{margin-top:1.25rem;margin-left:.5ex}
.quoteblock .attribution,.verseblock .attribution{font-size:.9375em;line-height:1.45;font-style:italic}
.quoteblock .attribution br,.verseblock .attribution br{display:none}
.quoteblock .attribution cite,.verseblock .attribution cite{display:block;letter-spacing:-.025em;color:rgba(0,0,0,.6)}
.quoteblock.abstract{margin:0 0 1.25em 0;display:block}
.quoteblock.abstract blockquote,.quoteblock.abstract blockquote p{text-align:left;word-spacing:0}
.quoteblock.abstract blockquote:before,.quoteblock.abstract blockquote p:first-of-type:before{display:none}
table.tableblock{max-width:100%;border-collapse:separate}
table.tableblock td>.paragraph:last-child p>p:last-child,table.tableblock th>p:last-child,table.tableblock td>p:last-child{margin-bottom:0}
table.tableblock,th.tableblock,td.tableblock{border:0 solid #dedede}
table.grid-all th.tableblock,table.grid-all td.tableblock{border-width:0 1px 1px 0}
table.grid-all tfoot>tr>th.tableblock,table.grid-all tfoot>tr>td.tableblock{border-width:1px 1px 0 0}
table.grid-cols th.tableblock,table.grid-cols td.tableblock{border-width:0 1px 0 0}
table.grid-all *>tr>.tableblock:last-child,table.grid-cols *>tr>.tableblock:last-child{border-right-width:0}
table.grid-rows th.tableblock,table.grid-rows td.tableblock{border-width:0 0 1px 0}
table.grid-all tbody>tr:last-child>th.tableblock,table.grid-all tbody>tr:last-child>td.tableblock,table.grid-all thead:last-child>tr>th.tableblock,table.grid-rows tbody>tr:last-child>th.tableblock,table.grid-rows tbody>tr:last-child>td.tableblock,table.grid-rows thead:last-child>tr>th.tableblock{border-bottom-width:0}
table.grid-rows tfoot>tr>th.tableblock,table.grid-rows tfoot>tr>td.tableblock{border-width:1px 0 0 0}
table.frame-all{border-width:1px}
table.frame-sides{border-width:0 1px}
table.frame-topbot{border-width:1px 0}
th.halign-left,td.halign-left{text-align:left}
th.halign-right,td.halign-right{text-align:right}
th.halign-center,td.halign-center{text-align:center}
th.valign-top,td.valign-top{vertical-align:top}
th.valign-bottom,td.valign-bottom{vertical-align:bottom}
th.valign-middle,td.valign-middle{vertical-align:middle}
table thead th,table tfoot th{font-weight:bold}
tbody tr th{display:table-cell;line-height:1.6;background:#f7f8f7}
tbody tr th,tbody tr th p,tfoot tr th,tfoot tr th p{color:rgba(0,0,0,.8);font-weight:bold}
p.tableblock>code:only-child{background:none;padding:0}
p.tableblock{font-size:1em}
td>div.verse{white-space:pre}
ol{margin-left:1.75em}
ul li ol{margin-left:1.5em}
dl dd{margin-left:1.125em}
dl dd:last-child,dl dd:last-child>:last-child{margin-bottom:0}
ol>li p,ul>li p,ul dd,ol dd,.olist .olist,.ulist .ulist,.ulist .olist,.olist .ulist{margin-bottom:.625em}
ul.unstyled,ol.unnumbered,ul.checklist,ul.none{list-style-type:none}
ul.unstyled,ol.unnumbered,ul.checklist{margin-left:.625em}
ul.checklist li>p:first-child>.fa-square-o:first-child,ul.checklist li>p:first-child>.fa-check-square-o:first-child{width:1em;font-size:.85em}
ul.checklist li>p:first-child>input[type="checkbox"]:first-child{width:1em;position:relative;top:1px}
ul.inline{margin:0 auto .625em auto;margin-left:-1.375em;margin-right:0;padding:0;list-style:none;overflow:hidden}
ul.inline>li{list-style:none;float:left;margin-left:1.375em;display:block}
ul.inline>li>*{display:block}
.unstyled dl dt{font-weight:400;font-style:normal}
ol.arabic{list-style-type:decimal}
ol.decimal{list-style-type:decimal-leading-zero}
ol.loweralpha{list-style-type:lower-alpha}
ol.upperalpha{list-style-type:upper-alpha}
ol.lowerroman{list-style-type:lower-roman}
ol.upperroman{list-style-type:upper-roman}
ol.lowergreek{list-style-type:lower-greek}
.hdlist>table,.colist>table{border:0;background:none}
.hdlist>table>tbody>tr,.colist>table>tbody>tr{background:none}
td.hdlist1,td.hdlist2{vertical-align:top;padding:0 .625em}
td.hdlist1{font-weight:bold;padding-bottom:1.25em}
.literalblock+.colist,.listingblock+.colist{margin-top:-.5em}
.colist>table tr>td:first-of-type{padding:0 .75em;line-height:1}
.colist>table tr>td:last-of-type{padding:.25em 0}
.thumb,.th{line-height:0;display:inline-block;border:solid 4px #fff;-webkit-box-shadow:0 0 0 1px #ddd;box-shadow:0 0 0 1px #ddd}
.imageblock.left,.imageblock[style*="float: left"]{margin:.25em .625em 1.25em 0}
.imageblock.right,.imageblock[style*="float: right"]{margin:.25em 0 1.25em .625em}
.imageblock>.title{margin-bottom:0}
.imageblock.thumb,.imageblock.th{border-width:6px}
.imageblock.thumb>.title,.imageblock.th>.title{padding:0 .125em}
.image.left,.image.right{margin-top:.25em;margin-bottom:.25em;display:inline-block;line-height:0}
.image.left{margin-right:.625em}
.image.right{margin-left:.625em}
a.image{text-decoration:none;display:inline-block}
a.image object{pointer-events:none}
sup.footnote,sup.footnoteref{font-size:.875em;position:static;vertical-align:super}
sup.footnote a,sup.footnoteref a{text-decoration:none}
sup.footnote a:active,sup.footnoteref a:active{text-decoration:underline}
#footnotes{padding-top:.75em;padding-bottom:.75em;margin-bottom:.625em}
#footnotes hr{width:20%;min-width:6.25em;margin:-.25em 0 .75em 0;border-width:1px 0 0 0}
#footnotes .footnote{padding:0 .375em 0 .225em;line-height:1.3334;font-size:.875em;margin-left:1.2em;text-indent:-1.05em;margin-bottom:.2em}
#footnotes .footnote a:first-of-type{font-weight:bold;text-decoration:none}
#footnotes .footnote:last-of-type{margin-bottom:0}
#content #footnotes{margin-top:-.625em;margin-bottom:0;padding:.75em 0}
.gist .file-data>table{border:0;background:#fff;width:100%;margin-bottom:0}
.gist .file-data>table td.line-data{width:99%}
div.unbreakable{page-break-inside:avoid}
.big{font-size:larger}
.small{font-size:smaller}
.underline{text-decoration:underline}
.overline{text-decoration:overline}
.line-through{text-decoration:line-through}
.aqua{color:#00bfbf}
.aqua-background{background-color:#00fafa}
.black{color:#000}
.black-background{background-color:#000}
.blue{color:#0000bf}
.blue-background{background-color:#0000fa}
.fuchsia{color:#bf00bf}
.fuchsia-background{background-color:#fa00fa}
.gray{color:#606060}
.gray-background{background-color:#7d7d7d}
.green{color:#006000}
.green-background{background-color:#007d00}
.lime{color:#00bf00}
.lime-background{background-color:#00fa00}
.maroon{color:#600000}
.maroon-background{background-color:#7d0000}
.navy{color:#000060}
.navy-background{background-color:#00007d}
.olive{color:#606000}
.olive-background{background-color:#7d7d00}
.purple{color:#600060}
.purple-background{background-color:#7d007d}
.red{color:#bf0000}
.red-background{background-color:#fa0000}
.silver{color:#909090}
.silver-background{background-color:#bcbcbc}
.teal{color:#006060}
.teal-background{background-color:#007d7d}
.white{color:#bfbfbf}
.white-background{background-color:#fafafa}
.yellow{color:#bfbf00}
.yellow-background{background-color:#fafa00}
span.icon>.fa{cursor:default}
.admonitionblock td.icon [class^="fa icon-"]{font-size:2.5em;text-shadow:1px 1px 2px rgba(0,0,0,.5);cursor:default}
.admonitionblock td.icon .icon-note:before{content:"\f05a";color:#19407c}
.admonitionblock td.icon .icon-tip:before{content:"\f0eb";text-shadow:1px 1px 2px rgba(155,155,0,.8);color:#111}
.admonitionblock td.icon .icon-warning:before{content:"\f071";color:#bf6900}
.admonitionblock td.icon .icon-caution:before{content:"\f06d";color:#bf3400}
.admonitionblock td.icon .icon-important:before{content:"\f06a";color:#bf0000}
.conum[data-value]{display:inline-block;color:#fff!important;background-color:rgba(0,0,0,.8);-webkit-border-radius:100px;border-radius:100px;text-align:center;font-size:.75em;width:1.67em;height:1.67em;line-height:1.67em;font-family:"Open Sans","DejaVu Sans",sans-serif;font-style:normal;font-weight:bold}
.conum[data-value] *{color:#fff!important}
.conum[data-value]+b{display:none}
.conum[data-value]:after{content:attr(data-value)}
pre .conum[data-value]{position:relative;top:-.125em}
b.conum *{color:inherit!important}
.conum:not([data-value]):empty{display:none}
dt,th.tableblock,td.content,div.footnote{text-rendering:optimizeLegibility}
h1,h2,p,td.content,span.alt{letter-spacing:-.01em}
p strong,td.content strong,div.footnote strong{letter-spacing:-.005em}
p,blockquote,dt,td.content,span.alt{font-size:1.0625rem}
p{margin-bottom:1.25rem}
.sidebarblock p,.sidebarblock dt,.sidebarblock td.content,p.tableblock{font-size:1em}
.exampleblock>.content{background-color:#fffef7;border-color:#e0e0dc;-webkit-box-shadow:0 1px 4px #e0e0dc;box-shadow:0 1px 4px #e0e0dc}
.print-only{display:none!important}
@media print{@page{margin:1.25cm .75cm}
*{-webkit-box-shadow:none!important;box-shadow:none!important;text-shadow:none!important}
a{color:inherit!important;text-decoration:underline!important}
a.bare,a[href^="#"],a[href^="mailto:"]{text-decoration:none!important}
a[href^="http:"]:not(.bare):after,a[href^="https:"]:not(.bare):after{content:"(" attr(href) ")";display:inline-block;font-size:.875em;padding-left:.25em}
abbr[title]:after{content:" (" attr(title) ")"}
pre,blockquote,tr,img,object,svg{page-break-inside:avoid}
thead{display:table-header-group}
svg{max-width:100%}
p,blockquote,dt,td.content{font-size:1em;orphans:3;widows:3}
h2,h3,#toctitle,.sidebarblock>.content>.title{page-break-after:avoid}
#toc,.sidebarblock,.exampleblock>.content{background:none!important}
#toc{border-bottom:1px solid #ddddd8!important;padding-bottom:0!important}
.sect1{padding-bottom:0!important}
.sect1+.sect1{border:0!important}
#header>h1:first-child{margin-top:1.25rem}
body.book #header{text-align:center}
body.book #header>h1:first-child{border:0!important;margin:2.5em 0 1em 0}
body.book #header .details{border:0!important;display:block;padding:0!important}
body.book #header .details span:first-child{margin-left:0!important}
body.book #header .details br{display:block}
body.book #header .details br+span:before{content:none!important}
body.book #toc{border:0!important;text-align:left!important;padding:0!important;margin:0!important}
body.book #toc,body.book #preamble,body.book h1.sect0,body.book .sect1>h2{page-break-before:always}
.listingblock code[data-lang]:before{display:block}
#footer{background:none!important;padding:0 .9375em}
#footer-text{color:rgba(0,0,0,.6)!important;font-size:.9em}
.hide-on-print{display:none!important}
.print-only{display:block!important}
.hide-for-print{display:none!important}
.show-for-print{display:inherit!important}}
</style>
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.6.3/css/font-awesome.min.css">
<style>
.listingblock .pygments .hll { background-color: #ffffcc }
.listingblock .pygments, .listingblock .pygments code { background: #f8f8f8; }
.listingblock .pygments .tok-c { color: #8f5902; font-style: italic } /* Comment */
.listingblock .pygments .tok-err { color: #a40000; border: 1px solid #ef2929 } /* Error */
.listingblock .pygments .tok-g { color: #000000; background-color: #e8e8f8 } /* Generic */
.listingblock .pygments .tok-k { color: #204a87; font-weight: bold } /* Keyword */
.listingblock .pygments .tok-l { color: #000000 } /* Literal */
.listingblock .pygments .tok-n { color: #000000 } /* Name */
.listingblock .pygments .tok-o { color: #ce5c00; font-weight: bold } /* Operator */
.listingblock .pygments .tok-x { color: #000000 } /* Other */
.listingblock .pygments .tok-p { color: #000000; font-weight: bold } /* Punctuation */
.listingblock .pygments .tok-ch { color: #8f5902; font-style: italic } /* Comment.Hashbang */
.listingblock .pygments .tok-cm { color: #8f5902; font-style: italic } /* Comment.Multiline */
.listingblock .pygments .tok-cp { color: #8f5902; font-style: italic } /* Comment.Preproc */
.listingblock .pygments .tok-cpf { color: #8f5902; font-style: italic } /* Comment.PreprocFile */
.listingblock .pygments .tok-c1 { color: #8f5902; font-style: italic } /* Comment.Single */
.listingblock .pygments .tok-cs { color: #8f5902; font-style: italic } /* Comment.Special */
.listingblock .pygments .tok-gd { color: #8f5902; font-style: italic; background-color: #e8e8f8 } /* Generic.Deleted */
.listingblock .pygments .tok-ge { color: #204a87; font-weight: bold; background-color: #e8e8f8 } /* Generic.Emph */
.listingblock .pygments .tok-gr { color: #ef2929; background-color: #e8e8f8 } /* Generic.Error */
.listingblock .pygments .tok-gh { color: #000080; font-weight: bold; background-color: #e8e8f8 } /* Generic.Heading */
.listingblock .pygments .tok-gi { color: #800080; font-weight: bold; background-color: #e8e8f8 } /* Generic.Inserted */
.listingblock .pygments .tok-go { color: #000000; font-style: italic; background-color: #e8e8f8 } /* Generic.Output */
.listingblock .pygments .tok-gp { color: #8f5902; background-color: #e8e8f8 } /* Generic.Prompt */
.listingblock .pygments .tok-gs { color: #4e9a06; background-color: #e8e8f8 } /* Generic.Strong */
.listingblock .pygments .tok-gu { color: #800080; font-weight: bold; background-color: #e8e8f8 } /* Generic.Subheading */
.listingblock .pygments .tok-gt { color: #a40000; font-weight: bold; background-color: #e8e8f8 } /* Generic.Traceback */
.listingblock .pygments .tok-kc { color: #204a87; font-weight: bold } /* Keyword.Constant */
.listingblock .pygments .tok-kd { color: #204a87; font-weight: bold } /* Keyword.Declaration */
.listingblock .pygments .tok-kn { color: #204a87; font-weight: bold } /* Keyword.Namespace */
.listingblock .pygments .tok-kp { color: #204a87; font-weight: bold } /* Keyword.Pseudo */
.listingblock .pygments .tok-kr { color: #204a87; font-weight: bold } /* Keyword.Reserved */
.listingblock .pygments .tok-kt { color: #204a87; font-weight: bold } /* Keyword.Type */
.listingblock .pygments .tok-ld { color: #000000 } /* Literal.Date */
.listingblock .pygments .tok-m { color: #0000cf; font-weight: bold } /* Literal.Number */
.listingblock .pygments .tok-s { color: #4e9a06 } /* Literal.String */
.listingblock .pygments .tok-na { color: #c4a000 } /* Name.Attribute */
.listingblock .pygments .tok-nb { color: #204a87 } /* Name.Builtin */
.listingblock .pygments .tok-nc { color: #000000 } /* Name.Class */
.listingblock .pygments .tok-no { color: #000000 } /* Name.Constant */
.listingblock .pygments .tok-nd { color: #5c35cc; font-weight: bold } /* Name.Decorator */
.listingblock .pygments .tok-ni { color: #ce5c00 } /* Name.Entity */
.listingblock .pygments .tok-ne { color: #cc0000; font-weight: bold } /* Name.Exception */
.listingblock .pygments .tok-nf { color: #000000 } /* Name.Function */
.listingblock .pygments .tok-nl { color: #f57900; font-weight: bold } /* Name.Label */
.listingblock .pygments .tok-nn { color: #000000 } /* Name.Namespace */
.listingblock .pygments .tok-nx { color: #4eba06; font-weight: bold } /* Name.Other */
.listingblock .pygments .tok-py { color: #000000 } /* Name.Property */
.listingblock .pygments .tok-nt { color: #204a87; font-weight: bold } /* Name.Tag */
.listingblock .pygments .tok-nv { color: #000000 } /* Name.Variable */
.listingblock .pygments .tok-ow { color: #204a87; font-weight: bold } /* Operator.Word */
.listingblock .pygments .tok-w { color: #f8f8f8; text-decoration: underline } /* Text.Whitespace */
.listingblock .pygments .tok-mb { color: #0000cf; font-weight: bold } /* Literal.Number.Bin */
.listingblock .pygments .tok-mf { color: #0000cf; font-weight: bold } /* Literal.Number.Float */
.listingblock .pygments .tok-mh { color: #0000cf; font-weight: bold } /* Literal.Number.Hex */
.listingblock .pygments .tok-mi { color: #0000cf; font-weight: bold } /* Literal.Number.Integer */
.listingblock .pygments .tok-mo { color: #0000cf; font-weight: bold } /* Literal.Number.Oct */
.listingblock .pygments .tok-sa { color: #4e9a06 } /* Literal.String.Affix */
.listingblock .pygments .tok-sb { color: #4e9a06 } /* Literal.String.Backtick */
.listingblock .pygments .tok-sc { color: #4e9a06 } /* Literal.String.Char */
.listingblock .pygments .tok-dl { color: #4e9a06 } /* Literal.String.Delimiter */
.listingblock .pygments .tok-sd { color: #8f5902; font-style: italic } /* Literal.String.Doc */
.listingblock .pygments .tok-s2 { color: #4e9a06 } /* Literal.String.Double */
.listingblock .pygments .tok-se { color: #4e9a06 } /* Literal.String.Escape */
.listingblock .pygments .tok-sh { color: #4e9a06 } /* Literal.String.Heredoc */
.listingblock .pygments .tok-si { color: #4e9a06 } /* Literal.String.Interpol */
.listingblock .pygments .tok-sx { color: #4e9a06 } /* Literal.String.Other */
.listingblock .pygments .tok-sr { color: #4e9a06 } /* Literal.String.Regex */
.listingblock .pygments .tok-s1 { color: #4e9a06 } /* Literal.String.Single */
.listingblock .pygments .tok-ss { color: #4e9a06 } /* Literal.String.Symbol */
.listingblock .pygments .tok-bp { color: #3465a4 } /* Name.Builtin.Pseudo */
.listingblock .pygments .tok-fm { color: #000000 } /* Name.Function.Magic */
.listingblock .pygments .tok-vc { color: #000000 } /* Name.Variable.Class */
.listingblock .pygments .tok-vg { color: #000000 } /* Name.Variable.Global */
.listingblock .pygments .tok-vi { color: #000000 } /* Name.Variable.Instance */
.listingblock .pygments .tok-vm { color: #000000 } /* Name.Variable.Magic */
.listingblock .pygments .tok-il { color: #0000cf; font-weight: bold } /* Literal.Number.Integer.Long */
</style>
</head>
<body class="article toc2 toc-left">
<div id="header">
<h1>Dolmen: A Generator for Lexical Analyzers and Parsers in Java</h1>
<div class="details">
<span id="author" class="author">Stéphane Lescuyer</span><br>
<span id="email" class="email"><a href="mailto:stephane.lescuyer@m4x.org">stephane.lescuyer@m4x.org</a></span><br>
</div>
<div id="toc" class="toc2">
<div id="toctitle">Table of Contents</div>
<ul class="sectlevel1">
<li><a href="#Introduction">Introduction</a>
<ul class="sectlevel2">
<li><a href="#_from_characters_to_abstract_syntax_trees">From characters to abstract syntax trees</a></li>
<li><a href="#_tokenization">Tokenization</a>
<ul class="sectlevel3">
<li><a href="#_tokens">Tokens</a></li>
<li><a href="#_regular_expressions">Regular Expressions</a></li>
<li><a href="#_lexical_analyzer_generators">Lexical Analyzer Generators</a></li>
</ul>
</li>
<li><a href="#_parsing">Parsing</a></li>
<li><a href="#_references">References</a></li>
</ul>
</li>
<li><a href="#Lexers">Lexical Analyzers</a>
<ul class="sectlevel2">
<li><a href="#_a_complete_example_lexical_analyzer_for_json">A Complete Example: Lexical Analyzer for JSON</a>
<ul class="sectlevel3">
<li><a href="#_dolmen_lexer_structure">Dolmen Lexer Structure</a></li>
<li><a href="#_adding_lexer_entries">Adding Lexer Entries</a></li>
<li><a href="#_compiling_and_testing_the_lexer">Compiling and Testing the Lexer</a></li>
<li><a href="#_adding_more_entries">Adding More Entries</a></li>
<li><a href="#Lexers_Error_Reports">Improving Error Reports</a></li>
<li><a href="#_debugging_locations">Debugging locations</a></li>
<li><a href="#_afterword">Afterword</a></li>
</ul>
</li>
<li><a href="#_lexer_entries">Lexer Entries</a>
<ul class="sectlevel3">
<li><a href="#Lexers_Regular_Expressions">Regular Expressions</a></li>
<li><a href="#Lexers_Semantic_Actions_Ref">Semantic Actions</a></li>
<li><a href="#Lexers_Wildcards">Understanding <code>eof</code>, <code>_</code> and <code>orelse</code></a></li>
<li><a href="#Lexers_Options">Lexer Options</a></li>
<li><a href="#Lexers_CLI">Command Line Interface</a></li>
</ul>
</li>
<li><a href="#_advanced_concepts">Advanced Concepts</a>
<ul class="sectlevel3">
<li><a href="#Lexers_Nested_Rules">Nested Rules</a></li>
<li><a href="#Lexers_Token_Locations">Managing Token Locations</a></li>
<li><a href="#Lexers_Tail_Recursion_Ref">Tail-Recursion</a></li>
</ul>
</li>
<li><a href="#Lexers_Syntax_Ref">Dolmen Lexers: Syntax Reference</a>
<ul class="sectlevel3">
<li><a href="#Lexers_Lexical_Conventions">Lexical conventions</a></li>
<li><a href="#_grammar_of_dolmen_lexers">Grammar of Dolmen Lexers</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="#Parsers">Parsers</a>
<ul class="sectlevel2">
<li><a href="#_dolmen_parsers_syntax_reference">Dolmen Parsers: Syntax Reference</a>
<ul class="sectlevel3">
<li><a href="#_lexical_conventions">Lexical conventions</a></li>
<li><a href="#_grammar_of_dolmen_parsers">Grammar of Dolmen Parsers</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</div>
</div>
<div id="content">
<div id="preamble">
<div class="sectionbody">
<div class="paragraph">
<p>Dolmen is a generator of
<a href="https://en.wikipedia.org/wiki/Lexical_analysis">lexical analyzers</a> and
<a href="https://en.wikipedia.org/wiki/Parsing">parsers</a> for the Java
programming language. It will produce lexical analyzers
(resp. syntactic analyzers) based on textual lexer descriptions
(resp. grammar descriptions). Dolmen can be used declaratively, as a
library, to produce lexers and parsers from descriptions, or more
commonly as a command-line tool. There also exists a dedicated
<a href="https://github.com/StekiKun/DolmenPlugin">Eclipse plug-in</a> for Dolmen.</p>
</div>
<div style="page-break-after: always;"></div>
</div>
</div>
<div class="sect1">
<h2 id="Introduction">Introduction</h2>
<div class="sectionbody">
<div class="paragraph">
<p>In this section, we shortly introduce the notions of lexical and
syntactic analyses and how they are typically combined into parsers
for structured languages such as programming languages, configuration
files, markup, etc. For a more thorough presentation of these
concepts, one can for instance refer to resources such as <a href="#ASU">[ASU]</a> and
<a href="#App">[App]</a>. If you are familiar with these concepts, you can skip
directly to the documentation for Dolmen <a href="#Lexers">Lexical Analyzers</a> or <a href="#Parsers">Parsers</a>.</p>
</div>
<div class="sect2">
<h3 id="_from_characters_to_abstract_syntax_trees">From characters to abstract syntax trees</h3>
<div class="paragraph">
<p>To illustrate the kind of tasks that Dolmen may help you perform,
consider a couple of statements in some programming language:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="pygments highlight"><code data-lang="ruby"><span class="tok-n">x</span> <span class="tok-o">=</span> <span class="tok-mi">1</span> <span class="tok-o">+</span> <span class="tok-n">y</span> <span class="tok-o">*</span> <span class="tok-mi">3</span><span class="tok-p">;</span>
<span class="tok-c1"># Some comment</span>
<span class="tok-k">if</span> <span class="tok-p">(</span><span class="tok-n">x</span> <span class="tok-o">&lt;</span> <span class="tok-mi">0</span><span class="tok-p">)</span> <span class="tok-k">then</span> <span class="tok-nb">printf</span><span class="tok-p">(</span><span class="tok-s2">&quot;(if;=</span><span class="tok-se">\&quot;</span><span class="tok-s2">#1</span><span class="tok-se">\n</span><span class="tok-s2">&quot;</span><span class="tok-p">);</span></code></pre>
</div>
</div>
<div class="paragraph">
<p>These statements are initially read from a source file as a mere
sequence of <em>characters</em>. The process of turning this sequence of
characters into a structured object that can be manipulated by a
program (e.g. an interpreter, a compiler, a static analyzer, etc) is
called <em>parsing</em>. For the statements above, the structured object
would typically look somewhat like this:</p>
</div>
<div class="listingblock">
<div class="content">
<pre>Sequence
 ├─ Assignment
 │   ├─ Variable "x"
 │   └─ Add
 │       ├─ Integer 0x00000001
 │       └─ Mult
 │           ├─ Variable "y"
 │           └─ Integer 0x00000003
 └─ IfThenElse
     ├─ LessThan
     │   ├─ Variable "x"
     │   └─ Integer 0x00000000
     ├─ Call "printf"
     │   └─ String ['i' 'f' ';' '=' '"' '#' '1' 0x0A]
     └─ Nop</pre>
</div>
</div>
<div class="paragraph">
<p>Such a structure is usually called an <em>Abstract Syntax Tree</em> (AST), as
it conveys the actual abstract structure that is expressed in the
original syntactic piece of code. There are a few important things to
note when comparing the AST and the original source:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>Punctuation and operator symbols do not appear in the AST <em>as such</em>
but they contribute to its structure:</p>
<div class="ulist">
<ul>
<li>
<p>punctuation symbols, such as semi-colons used to terminate
statements, block delimiters or separation whitespace (e.g. the
space between <code>then</code> and <code>printf</code>), are useful to express the
structure of the program and separate its core syntactic elements;
they are reflected in the AST for instance in the <code>Sequence</code> node
or the <code>IfThenElse</code> control-flow structure;</p>
</li>
<li>
<p>operators such as <code>+</code>, <code>if .. then</code> or <code>=</code> are translated to
abstract nodes for the operations they represent, such as
<code>Assignment</code>, <code>Add</code> and so on.</p>
<div class="paragraph">
<p>It is technically possible to modify these syntactic conventions in
the language and adapt the source snippet without changing the AST at
all, i.e. without needing to change the back-ends of your compiler,
interpreter, etc.</p>
</div>
</li>
</ul>
</div>
</li>
<li>
<p>Comments do not appear in the AST as they have no bearing on the
actual meaning of the program (the same goes for extra whitespace as
well, e.g. indentation or formatting). Of course, a tool which needs
to interpret some special comments (such as
<a href="https://docs.oracle.com/javase/8/docs/technotes/tools/windows/javadoc.html">Javadoc</a>
or <a href="http://www.doxygen.nl">Doxygen</a> documentation) will typically have
to keep at least some of the comments as part of the AST.</p>
</li>
<li>
<p>Some things that were implicit in the original source have been made
explicit in the AST:</p>
<div class="ulist">
<ul>
<li>
<p>rules that govern the <em>precedence</em> of various operators have been
applied; in that case the fact that the multiplication operator <code>*</code>
binds tighter than the addition operator <code>+</code> is reflected in the
way the arithmetic expression <code>1 + y * 3</code> was parsed;</p>
</li>
<li>
<p>some forms of syntactic sugar have been removed, such as the
missing <code>else</code> branch being filled with a default no-operation
<code>Nop</code> node.</p>
<div class="paragraph">
<p>In essence, a program manipulating an AST need not care about all the
subtle syntactic possibilites to write the same statement or
expression, and writing <code>1 + (y * 3)</code> or an explicit <code>else {}</code> branch
would have made no difference.</p>
</div>
</li>
</ul>
</div>
</li>
<li>
<p>Last but not least, constant literals are also usually canonized in
ASTs:</p>
<div class="ulist">
<ul>
<li>
<p>integer literals may be input using decimal, hexadecimal or octal
notations for instance, and it is the actual value represented by
the literal which is normally stored in the AST;</p>
</li>
<li>
<p>string or character literals may contain escape sequences for
Unicode values or special characters such as <code>"</code> and the line feed
<code>\n</code> in our example, and these are replaced by the actual encoded
character when parsing the literal into the AST.</p>
</li>
</ul>
</div>
</li>
</ul>
</div>
<div class="paragraph">
<p>Some of the things that are typically not performed during parsing
include the resolution of identifiers (is <code>x</code> a global constant or
some local variable? is <code>printf</code> a local function or one from an
imported external module?&#8230;&#8203;), type-checking (calling <code>printf(4, x)</code>
would have been parsed successfully) and other semantic analyses.</p>
</div>
</div>
<div class="sect2">
<h3 id="_tokenization">Tokenization</h3>
<div class="paragraph">
<p>Although it is always technically possible, it should be clear that
manually parsing source code into an AST <em>in a single-pass</em> is not
very practical: one needs to keep track of all possible contexts,
handle possible comments everywhere, match opening and closing
delimiters such as parentheses and braces, handle precedence rules and
syntactic varieties, unescape characters when applicable, etc. It is
code that is definitely hard to write, hard to read and even harder
to maintain.</p>
</div>
<div class="sect3">
<h4 id="_tokens">Tokens</h4>
<div class="paragraph">
<p>A better way of handling this parsing problem is to first split the
source code into its atomic lexical elements, much like reading a
sentence in a natural language requires to first identify the various
words before checking whether their arrangement is grammatically
correct. These lexical elements are called <em>tokens</em> and the phase
which transforms the input stream of characters into a stream of
tokens is called <em>tokenization</em>.</p>
</div>
<div class="paragraph">
<p>The tokens of a programming language usually consist of:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>punctuation symbols such as <code>;</code>, <code>,</code>, <code>(</code>&#8230;&#8203;</p>
</li>
<li>
<p>operators such as <code>+</code>, <code>==</code>, <code>&lt;&lt;</code>, <code>&amp;</code>, <code>&gt;=</code>&#8230;&#8203;</p>
</li>
<li>
<p>keywords of the language such as <code>if</code>, <code>while</code>, <code>def</code>&#8230;&#8203;</p>
</li>
<li>
<p>identifiers such as <code>x</code>, <code>_y12</code>, <code>speedX</code>&#8230;&#8203;</p>
</li>
<li>
<p>constant literals such as <code>12</code>, <code>0xFA2E</code>, <code>0.85f</code>, <code>'c'</code>, <code>"hello"</code>&#8230;&#8203;</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>In particular, there are usually no tokens for whitespace or comments,
although there could be tokens for special documentation comments if
required. Looking at these couple of statements again:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="pygments highlight"><code data-lang="ruby"><span class="tok-n">x</span> <span class="tok-o">=</span> <span class="tok-mi">1</span> <span class="tok-o">+</span> <span class="tok-n">y</span> <span class="tok-o">*</span> <span class="tok-mi">3</span><span class="tok-p">;</span>
<span class="tok-c1"># Some comment</span>
<span class="tok-k">if</span> <span class="tok-p">(</span><span class="tok-n">x</span> <span class="tok-o">&lt;</span> <span class="tok-mi">0</span><span class="tok-p">)</span> <span class="tok-k">then</span> <span class="tok-nb">printf</span><span class="tok-p">(</span><span class="tok-s2">&quot;(if;=</span><span class="tok-se">\&quot;</span><span class="tok-s2">#1</span><span class="tok-se">\n</span><span class="tok-s2">&quot;</span><span class="tok-p">);</span></code></pre>
</div>
</div>
<div class="paragraph">
<p>the corresponding tokens would be</p>
</div>
<div class="openblock">
<div class="content">
<div class="paragraph">
<p><code>x</code>, <code>=</code>, <code>1</code>, <code>+</code>, <code>y</code>, <code>*</code>, <code>3</code>, <code>;</code>, <code>if</code>, <code>(</code>, <code>x</code>, <code>&lt;</code>, <code>0</code>, <code>)</code>,
<code>then</code>, <code>printf</code>, <code>"(if;=\"#1\n"</code>, <code>)</code> and <code>;</code>.</p>
</div>
</div>
</div>
<div class="paragraph">
<p>Some tokens such as constant literals or identifiers are associated to
a <em>value</em>, such as the literal&#8217;s value or the identifier&#8217;s name,
whereas the other tokens hold no particular value other than
themselves.</p>
</div>
</div>
<div class="sect3">
<h4 id="_regular_expressions">Regular Expressions</h4>
<div class="paragraph">
<p>The tokenization process is usually simple enough for the different
tokens to be recognizable by <em>regular expressions</em>. For instance, one
might informally describe some of the rules to identify the tokens of
our language above as follows:</p>
</div>
<div class="listingblock">
<div class="content">
<pre>";" -&gt; SEMICOLON
"&amp;" -&gt; AMPERSAND
...
"if" -&gt; IF
"def" -&gt; DEF
...
[_a-zA-Z][_a-zA-Z0-9]* -&gt; IDENT
(0 | [1-9][0-9]*) -&gt; INT
...
'"' [^"] '"' -&gt; STRING</pre>
</div>
</div>
<div class="paragraph">
<p>where <code>SEMICOLON</code>, <code>IF</code>, <code>IDENT</code>, etc. are the symbolic names given to
the different kinds of tokens. The regular expressions for operators
and keywords are straightforward and match the associated symbols
exactly. Identifiers are simply a letter or an underscore followed by
any number of alphanumeric characters, whereas decimal integer
literals are either 0 or any number not starting with 0. There would
be other rules for integer literals in other radices, but they could
share the same token kind. Finally, string literals are formed by a
pair of matching <code>"</code> without any double quotes in the middle; of
course this is an oversimplification as it does not account for
escaped characters appearing inside the string. The different rules
are not necessarily exclusive, in which case some <em>disambiguation
rules</em> must be applied. For instance, keywords look very much like
valid identifiers, and in fact they are pretty much just that:
reserved identifiers. A common way of handling this is to use the
<em>"longest-match rule"</em>, expressing that when a choice exists, the
token that consumes the most characters in the input should be given
preference. This ensures that <code>defined</code> is a single identifier token
instead of the keyword <code>def</code> followed by an identifier <code>ined</code>, and
that <code>1234</code> is a single integer instead of <code>1</code> followed by <code>234</code> or
any other combination. When several rules match the same amount of
input, a possible choice is to always pick the one which appears first
in the set of rules; in our case above, this ensures the keyword <code>if</code>
is matched as <code>IF</code> and not as an identifier.</p>
</div>
<div class="paragraph">
<p>Disambiguation aside, these regular expressions can be merged into a
single regular expression which in turn can be transformed into a
<em>deterministic finite automaton</em> (DFA) that recognizes the tokens. The
final states of the DFA represent the various token rules and the DFA
can be used to efficiently consume characters from the input
stream. When the DFA reaches a final state, it emits the corresponding
token, and in this fashion the input character stream can be
transformed into a token stream. If ever the DFA fails to recognize
the input characters at some point, this means the input string has a
syntax error. With our rules above, this would for instance happen
with an non-terminated string literal. Last but not least, we have not
explained how whitespace and comments are handled: they must
definitely be recognized and <em>consumed</em> but should produce no
tokens. One way to do this in our informal description is to add
the corresponding rules:</p>
</div>
<div class="listingblock">
<div class="content">
<pre>(' ' | '\r' | '\n' | '\t')+ -&gt;          /* whitespace, skip */
"//" [^\r\n]* -&gt;                        /* comments, skip */</pre>
</div>
</div>
<div class="paragraph">
<p>but have them produce no token at all. When the DFA reaches the
corresponding state, it simply starts over with the remaining input
without emitting any token in the output stream.</p>
</div>
</div>
<div class="sect3">
<h4 id="_lexical_analyzer_generators">Lexical Analyzer Generators</h4>
<div class="paragraph">
<p>Lexical analyzer generators are tools which automate the process of
turning a set of rules, such as those given informally above, into
source code which implements the recognition mechanism for the DFA
associated with the rules. This allows developers to keep a reasonably
abstract view of the tokenization process, concentrate on designing
the various regular expressions correctly, and leave everything else
to the generator:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>managing the input stream buffer and character encoding;</p>
</li>
<li>
<p>the translation of the regular expressions into an optimized DFA;</p>
</li>
<li>
<p>handling disambiguation rules, in particular the backtracking which
is normally entailed by using the longest-match rule;</p>
</li>
<li>
<p>checking for potential ambiguities or issues in the rules, such as
rules which are always shadowed by another rule;</p>
</li>
<li>
<p>keeping track of line and column numbers or character offsets, which
are useful both for error reporting and to associate source
locations to AST nodes during the parsing phase.</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>As none of the above is particularly easy to deal with, these
generators are a great asset when trying to write a parser. Many
generators, including Dolmen, will additionnally support input rules
which are more expressive than simple regular expressions, like
<a href="https://en.wikipedia.org/wiki/Pushdown_automaton">pushdown automata</a>,
making it possible to perform quite complex tasks during the
tokenization phase.</p>
</div>
<div class="paragraph">
<p>Some lexical analyzer generators such as the ones in
<a href="https://www.antlr.org/">ANTLR</a> or <a href="https://www.antlr.org/">JavaCC</a> are
intrinsically linked to an associated parser generator and are used to
produce tokens for these parsers, but lexical analysis is not limited
to producing tokens for a grammar-based syntactic analysis. One can
actually associate the lexer rules to any computable action, such as
printing something or aggregating some information. Possible
applications of a "standalone" lexical analyzer may be:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>counting the lines or the number of occurrences of some lexical
element in a file, skipping comments;</p>
</li>
<li>
<p>perform simple C-style pre-processing of a program;</p>
</li>
<li>
<p>simple syntax highlighting such as the one applied to code
blocks in this very document;</p>
</li>
<li>
<p>character stream transformation passes such as the initial Unicode
unescaping phase in
<a href="https://docs.oracle.com/javase/specs/jls/se9/html/jls-3.html#jls-3.3">lexical
translation of Java sources</a>.</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>Lexers generated by Dolmen are not specialized for tokenization and
can be used for any kind of lexical analysis by designing the
appropriate actions. Another lexer generator in the Java ecosystem
which produces standalone lexical analyzers is
<a href="https://jflex.de/">JFlex</a>. In particular both can be used to produce
token streams for other parser generators such as
<a href="http://www2.cs.tum.edu/projects/cup/">Cup</a> or
<a href="http://byaccj.sourceforge.net/">BYacc/J</a>. The <a href="#Lexers">Lexical Analyzers</a> chapter in
this documentation explains how to write your own lexers with Dolmen.</p>
</div>
</div>
</div>
<div class="sect2">
<h3 id="_parsing">Parsing</h3>
<div class="paragraph">
<p><em>Coming soon</em></p>
</div>
</div>
<div class="sect2">
<h3 id="_references">References</h3>
<div class="ulist">
<ul>
<li>
<p><a id="ASU"></a>[ASU] <em>Compilers: principles, techniques, and
tools.</em> Aho, Sethi and Ullman. (Addison-Wesley, 1986)</p>
</li>
<li>
<p><a id="App"></a>[App] <em>Modern compiler implementation in ML</em>.
Appel. (Cambridge University Press, 1998)</p>
</li>
</ul>
</div>
<div style="page-break-after: always;"></div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="Lexers">Lexical Analyzers</h2>
<div class="sectionbody">
<div class="paragraph">
<p>In this chapter, we explain how to produce lexical analysers with
Dolmen by writing <em>Dolmen lexer descriptions</em>. We start by showing how
to write a simple lexer description for the JSON format before
presenting the various features of the lexer description format in
more detailed fashion. A complete reference for the lexer description
syntax can be found at <a href="#Lexers_Syntax_Ref">the end of this chapter</a>.</p>
</div>
<div class="sect2">
<h3 id="_a_complete_example_lexical_analyzer_for_json">A Complete Example: Lexical Analyzer for JSON</h3>
<div class="paragraph">
<p>We introduce lexical analysis with Dolmen by writing a lexical
analyzer for the <a href="https://www.json.org">JavaScript Object Notation
(JSON) format</a>. JSON is a very common format for data exchange which
has generally less overhead than XML and is more human-readable. A
possible JSON value can be as follows:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="pygments highlight"><code data-lang="javascript"><span class="tok-p">{</span> <span class="tok-s2">&quot;persons&quot;</span><span class="tok-o">:</span> <span class="tok-p">[</span><span class="tok-s2">&quot;Joe&quot;</span><span class="tok-p">,</span> <span class="tok-s2">&quot;Bob&quot;</span><span class="tok-p">,</span> <span class="tok-kc">null</span><span class="tok-p">],</span>
  <span class="tok-s2">&quot;open&quot;</span><span class="tok-o">:</span> <span class="tok-kc">true</span><span class="tok-p">,</span>
  <span class="tok-s2">&quot;loc&quot;</span><span class="tok-o">:</span> <span class="tok-p">[</span><span class="tok-o">-</span><span class="tok-mf">12.45</span><span class="tok-p">,</span> <span class="tok-mf">3.40e1</span><span class="tok-p">],</span>
  <span class="tok-s2">&quot;text&quot;</span><span class="tok-o">:</span> <span class="tok-s2">&quot;sdfk\&quot;j&quot;</span>
<span class="tok-p">}</span></code></pre>
</div>
</div>
<div class="paragraph">
<p>A JSON value can be an <em>object</em> mapping string keys to other JSON
values, an <em>array</em> of values, a string, a number, or any of the three
literals <code>true</code>, <code>false</code> and <code>null</code>. In order to design a lexical
analyzer for this language, we need to recognize the following tokens:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>the various <em>punctuation symbols</em> used in JSON: <code>{</code>, <code>}</code>, <code>[</code>, <code>]</code>,
<code>:</code> and <code>,</code> (note that <code>"</code>, <code>-</code>, <code>+</code> and <code>.</code> are not considered as
 punctuation tokens, rather they are part of string and number
 literals);</p>
</li>
<li>
<p>the keywords <code>true</code>, <code>false</code> and <code>null</code>;</p>
</li>
<li>
<p>the number literals such as <code>0</code>, <code>-1.34</code> or <code>0.699e+4</code>;</p>
</li>
<li>
<p>the string literals such as <code>"foo"</code>, <code>"\u0025\n"</code> or <code>"א"</code>.</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>Our lexical analyzer will need to recognize these various lexical
elements and take actions upon doing so. A typical action when some
token has been recognized is to build an object describing the token
and return it; we will follow this principle here in this example but
other actions such as printing the tokens could be possible.</p>
</div>
<div class="paragraph">
<p>In the following, we suppose we have some Java class <code>mypackage.Token</code>
describing the various tokens and some static factories to build
each kind of token:</p>
</div>
<table class="tableblock frame-all grid-all spread">
<colgroup>
<col style="width: 50%;">
<col style="width: 50%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Token(s)</th>
<th class="tableblock halign-left valign-top">Static factory</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>{</code> and <code>}</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>Token.LBRACE</code> and <code>Token.RBRACE</code></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>[</code> and <code>]</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>Token.LBRACKET</code> and <code>Token.RBRACKET</code></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>:</code> and <code>,</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>Token.COLON</code> and <code>Token.COMMA</code></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>true</code> and <code>false</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>Token.TRUE</code> and <code>Token.FALSE</code></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>null</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>Token.NULL</code></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><em>number</em></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>Token.NUMBER(double d)</code></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><em>string</em></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>Token.STRING(String s)</code></p></td>
</tr>
</tbody>
</table>
<div class="admonitionblock tip">
<table>
<tr>
<td class="icon">
<i class="fa icon-tip" title="Tip"></i>
</td>
<td class="content">
When writing a lexical analyzer to use wih a Dolmen-generated
     parser, this <code>Token</code> class would simply be generated by Dolmen
     from the <a href="#TokenDecl">token declarations</a> in the grammar
     description.
</td>
</tr>
</table>
</div>
<div class="sect3">
<h4 id="_dolmen_lexer_structure">Dolmen Lexer Structure</h4>
<div class="paragraph">
<p>The overall structure of a Dolmen lexer description is as follows:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="pygments highlight"><code data-lang="jl">... <span class="tok-nf">Options</span> ...

... <span class="tok-nf">Java</span> <span class="tok-nf">imports</span> ...

<span class="tok-g">{ ... </span><span class="tok-gd">/* Java prelude */</span><span class="tok-g"> ... }</span>

... <span class="tok-nf">Regexp</span> <span class="tok-nf">definitions</span> ...

... <span class="tok-nf">Lexer</span> <span class="tok-nf">entries</span> ...

<span class="tok-g">{ ... </span><span class="tok-gd">/* Java postlude */</span><span class="tok-g"> ... }</span></code></pre>
</div>
</div>
<div class="paragraph">
<p>We will come back to the options and regular expression definitions
parts later. The Java imports section contains plain
<a href="https://docs.oracle.com/javase/specs/jls/se8/html/jls-7.html#jls-ImportDeclaration">Java
import declarations</a> which are added by Dolmen to the generated
lexical analyzer and can be used in the various Java actions of the
lexer description. In our case, we will import the <code>Token</code> class for
sure, and we may even import its static members to simplify access to
the token static factories:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="pygments highlight"><code data-lang="jl"><span class="tok-k">import</span> <span class="tok-nf">mypackage</span>.<span class="tok-nf">Token</span><span class="tok-p">;</span>
<span class="tok-k">import</span> <span class="tok-k">static</span> <span class="tok-nf">mypackage</span>.<span class="tok-nf">Token</span>.<span class="tok-o">*</span><span class="tok-p">;</span></code></pre>
</div>
</div>
<div class="paragraph">
<p>The Java prelude and postlude are arbitrary Java snippets which will
be added respectively to the top and bottom of the generated lexical
analyzer. They can typically be used for local auxiliary methods or
static initializers. We can leave them empty for now, and will come
back and add convenient methods to the prelude if need arises.</p>
</div>
<div class="paragraph">
<p>The main part of a Dolmen lexer consists of lexer <em>entries</em>, of which
there must be at least one per lexer. At this point, our partial lexer
description looks like this and is just missing some entries:</p>
</div>
<div class="listingblock">
<div class="title">A Dolmen lexer description skeleton</div>
<div class="content">
<pre class="pygments highlight"><code data-lang="jl"><span class="tok-k">import</span> <span class="tok-nf">mypackage</span>.<span class="tok-nf">Token</span><span class="tok-p">;</span>
<span class="tok-k">import</span> <span class="tok-k">static</span> <span class="tok-nf">mypackage</span>.<span class="tok-nf">Token</span>.<span class="tok-o">*</span><span class="tok-p">;</span>

<span class="tok-g">{ }</span>

<span class="tok-c tok-c-Singleline">// TODO here: add some lexer entries!</span>

<span class="tok-g">{ }</span></code></pre>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_adding_lexer_entries">Adding Lexer Entries</h4>
<div class="paragraph">
<p>When a lexical analyzer starts consuming a file, a string or any
stream of characters, it needs a set of rules explaining what patterns
must be recognized and what actions must be taken in response. In
Dolmen lexer descriptions, such a set of rules is called a <em>lexer
entry</em> and has the following structure:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="pygments highlight"><code data-lang="jl"><span class="tok-nf">visibility</span> <span class="tok-g">{ ... </span><span class="tok-gd">/* return type */</span><span class="tok-g"> ... }</span> <span class="tok-k">rule</span> <span class="tok-nf">name</span> <span class="tok-o">=</span>
<span class="tok-o">|</span> <span class="tok-nf">regexp</span> <span class="tok-g">{ ... </span><span class="tok-gd">/* semantic action */</span><span class="tok-g"> ... }</span>
...
<span class="tok-o">|</span> <span class="tok-nf">regexp</span> <span class="tok-g">{ ... </span><span class="tok-gd">/* semantic action */</span><span class="tok-g"> ... }</span></code></pre>
</div>
</div>
<div class="paragraph">
<p>An entry has a visibility and a name; the entry&#8217;s visibility can be
either <code>public</code> or <code>private</code> and specifies the visibility of the
corresponding entry point in the generated lexer. Each of the
following line is called a <em>clause</em> and specifies some <em>regular
expression</em> and an associated <em>semantic action</em> in Java. Each entry
must have at least one clause.</p>
</div>
<div class="paragraph">
<p>Using a lexer entry will match the character stream for the regular
expressions in the entry&#8217;s clauses, and when a match is found, will
consume the corresponding part of the character stream and execute the
corresponding Java action.</p>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
<div class="paragraph">
<p>When more than one clause matches the input stream,
disambiguation happens based on the two following rules:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>the rule which matches the <strong>longest</strong> prefix of the input will
take precedence;</p>
</li>
<li>
<p>when more than one rule match the same number of characters,
the rule that appears <strong>first</strong> in the entry&#8217;s definition takes
precedence.</p>
</li>
</ul>
</div>
</td>
</tr>
</table>
</div>
<div class="paragraph">
<p>The entry defines a Java <em>return type</em> which is the actual return type
of the corresponding Java entry point in the lexical analyzer, and the
semantic actions in the entry&#8217;s clauses must be consistent with that
return type. In the case of our JSON lexical analyzer, let us add a
main public rule which will return an instance of the <code>Token</code> class:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="pygments highlight"><code data-lang="jl"><span class="tok-k">public</span> <span class="tok-g">{ Token }</span> <span class="tok-k">rule</span> <span class="tok-nf">main</span> <span class="tok-o">=</span>
<span class="tok-o">|</span> ...</code></pre>
</div>
</div>
<div class="paragraph">
<p>We can first add the clauses to recognize the punctuation tokens,
these clauses simply match the punctuation character and return the
associated token:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="pygments highlight"><code data-lang="jl">...
<span class="tok-o">|</span> <span class="tok-sc">&#39;{&#39;</span>   <span class="tok-g">{ </span><span class="tok-ge">return</span><span class="tok-g"> LBRACE; }</span>
<span class="tok-o">|</span> <span class="tok-sc">&#39;}&#39;</span>   <span class="tok-g">{ </span><span class="tok-ge">return</span><span class="tok-g"> RBRACE; }</span>
<span class="tok-o">|</span> <span class="tok-sc">&#39;[&#39;</span>   <span class="tok-g">{ </span><span class="tok-ge">return</span><span class="tok-g"> LBRACKET; }</span>
<span class="tok-o">|</span> <span class="tok-sc">&#39;]&#39;</span>   <span class="tok-g">{ </span><span class="tok-ge">return</span><span class="tok-g"> RBRACKET; }</span>
<span class="tok-o">|</span> <span class="tok-sc">&#39;:&#39;</span>   <span class="tok-g">{ </span><span class="tok-ge">return</span><span class="tok-g"> COLON; }</span>
<span class="tok-o">|</span> <span class="tok-sc">&#39;,&#39;</span>   <span class="tok-g">{ </span><span class="tok-ge">return</span><span class="tok-g"> COMMA; }</span></code></pre>
</div>
</div>
<div class="paragraph">
<p>When used in a regular expression, a simple character literal will
exactly match said character. Similarly, a double-quoted string literal
will exactly match the given string, so we can easily add clauses to
match the tokens for the <code>true</code>, <code>false</code> and <code>null</code> JSON keywords:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="pygments highlight"><code data-lang="jl">...
<span class="tok-o">|</span> <span class="tok-s">&quot;true&quot;</span>   <span class="tok-g">{ </span><span class="tok-ge">return</span><span class="tok-g"> TRUE; }</span>
<span class="tok-o">|</span> <span class="tok-s">&quot;false&quot;</span>  <span class="tok-g">{ </span><span class="tok-ge">return</span><span class="tok-g"> FALSE; }</span>
<span class="tok-o">|</span> <span class="tok-s">&quot;null&quot;</span>   <span class="tok-g">{ </span><span class="tok-ge">return</span><span class="tok-g"> NULL; }</span></code></pre>
</div>
</div>
<div class="paragraph">
<p>The exact syntax for number literals is for instance described in the
<a href="http://www.ecma-international.org/publications/files/ECMA-ST/ECMA-404.pdf">JSON standard</a> by the following <em>railroad diagram</em>:</p>
</div>
<div class="imageblock" style="text-align: center">
<div class="content">
<img src="./images/json_number.png" alt="JSON numbers" width="50%">
</div>
</div>
<div class="paragraph">
<p>A JSON number literal is therefore a decimal integer (without leading
zeroes), preceded by an optional sign, and optionally followed by a
fractional part and/or an exponent part, allowing common scientific
notation to be used. It is straightforward to translate that diagram
into a regular expression, but that expression would get quite large,
which is both error-prone and hard to maintain. To alleviate this
issue, Dolmen allows defining auxiliary regular expressions and
composing them into bigger regular expressions. In a lexer
description, definitions of auxiliary regular expressions can be
inserted between the prelude and the lexer entries. Let us add a few
auxiliary definitions to our description in order to tackle number
literals:</p>
</div>
<div class="listingblock">
<div class="title">Auxiliary regular expressions for number literals (1/2)</div>
<div class="content">
<pre class="pygments highlight"><code data-lang="jl"><span class="tok-nf">digit</span> <span class="tok-o">=</span> <span class="tok-p">[</span><span class="tok-sc">&#39;0&#39;</span><span class="tok-o">-</span><span class="tok-sc">&#39;9&#39;</span><span class="tok-p">];</span>
<span class="tok-nf">nzdigit</span> <span class="tok-o">=</span> <span class="tok-nf">digit</span> <span class="tok-o">#</span> <span class="tok-sc">&#39;0&#39;</span><span class="tok-p">;</span>
<span class="tok-nf">int</span> <span class="tok-o">=</span> <span class="tok-sc">&#39;-&#39;</span><span class="tok-o">?</span> <span class="tok-p">(</span><span class="tok-sc">&#39;0&#39;</span> <span class="tok-o">|</span> <span class="tok-nf">nzdigit</span> <span class="tok-nf">digit</span><span class="tok-o">*</span><span class="tok-p">);</span>
...</code></pre>
</div>
</div>
<div class="paragraph">
<p>We define a digit as being any character between <code>0</code> and <code>9</code>. The
<code>[&#8230;&#8203;]</code> syntax defines a <em>character set</em>; it can contain any number of
single characters, as well as character ranges described by the first
and last characters of the range separated by <code>-</code>. The second
definition uses the <em>difference</em> operator <code>#</code> to define a non-zero
digit (<code>nzdigit</code>) as being any digit except <code>0</code>. The difference
operator can only be used with characters or character sets and will
match any character in the left-hand side operand that is not also in
the right-hand operand. The third definition makes use of traditional
regular expression operators to define the <em>integral</em> part of a JSON
number literal: <code>?</code> for an optional match, <code>|</code> for the choice operator
and <code>*</code> for matching any number of repetitions of a regular
expression. Of course, the operator <code>+</code> is not needed here but can
also be used to match one or more repetitions.</p>
</div>
<div class="listingblock">
<div class="title">Auxiliary regular expressions for number literals (2/2)</div>
<div class="content">
<pre class="pygments highlight"><code data-lang="jl">...
<span class="tok-nf">frac</span> <span class="tok-o">=</span> <span class="tok-sc">&#39;.&#39;</span> <span class="tok-nf">digit</span><span class="tok-o">+</span><span class="tok-p">;</span>
<span class="tok-nf">e</span> <span class="tok-o">=</span> <span class="tok-p">(</span><span class="tok-sc">&#39;e&#39;</span> <span class="tok-o">|</span> <span class="tok-sc">&#39;E&#39;</span><span class="tok-p">)</span> <span class="tok-p">(</span><span class="tok-sc">&#39;+&#39;</span> <span class="tok-o">|</span> <span class="tok-sc">&#39;-&#39;</span><span class="tok-p">)</span><span class="tok-o">?</span><span class="tok-p">;</span>
<span class="tok-nf">exp</span> <span class="tok-o">=</span> <span class="tok-nf">e</span> <span class="tok-nf">digit</span><span class="tok-o">+</span><span class="tok-p">;</span>
<span class="tok-nf">number</span> <span class="tok-o">=</span> <span class="tok-nf">int</span> <span class="tok-nf">frac</span><span class="tok-o">?</span> <span class="tok-nf">exp</span><span class="tok-o">?</span><span class="tok-p">;</span></code></pre>
</div>
</div>
<div class="paragraph">
<p>Similarly, it is straightforward to add definitions for the fractional
and exponent parts, and finally to define <code>number</code> as the concatenation
of the integral and (optional) fractional and exponent parts. We can
now simply use <code>number</code> in the clause which must match number literals
in the <code>main</code> lexer entry:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="pygments highlight"><code data-lang="jl">...
<span class="tok-o">|</span> <span class="tok-nf">number</span>   <span class="tok-g">{ </span><span class="tok-ge">return</span><span class="tok-g"> NUMBER(...); }</span></code></pre>
</div>
</div>
<div class="paragraph">
<p>Unlike the symbols and keywords we had matched so far, the number
token which must be constructed depends on the actual contents that
have been matched by the clause; in other words, we need to construct
the adequate <code>double</code> value to pass to the <code>NUMBER</code> static factory.
The string which has been matched can be retrieved in the semantic
action using the method <code>getLexeme()</code>. The various methods and fields
which are available in semantic actions to interact with the lexing
engine are listed in the reference section on
<a href="#Lexers_Semantic_Actions_Ref">semantic actions</a>. In our case here, we
can simply use <code>getLexeme()</code> and the
<a href="https://docs.oracle.com/javase/8/docs/api/java/lang/Double.html#parseDouble-java.lang.String-">Double.parseDouble</a>
method from the Java API:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="pygments highlight"><code data-lang="jl">...
<span class="tok-o">|</span> <span class="tok-nf">number</span>   <span class="tok-g">{ </span><span class="tok-ge">return</span><span class="tok-g"> NUMBER(Double.parseDouble(getLexeme())); }</span></code></pre>
</div>
</div>
<div class="admonitionblock caution">
<table>
<tr>
<td class="icon">
<i class="fa icon-caution" title="Caution"></i>
</td>
<td class="content">
You may note that not all strings matched by the <code>number</code>
  regular expression are representations of valid Java
  double-precision numbers (e.g. it can match arbitrary large
  numbers), and that this semantic action could therefore throw a
  <a href="https://docs.oracle.com/javase/8/docs/api/java/lang/NumberFormatException.html">NumberFormatException</a>. We
  will see later in this tutorial how to improve error reporting in
  our lexer.
</td>
</tr>
</table>
</div>
</div>
<div class="sect3">
<h4 id="_compiling_and_testing_the_lexer">Compiling and Testing the Lexer</h4>
<div class="paragraph">
<p>At this point, our lexer is far from finished but it is not too early
to try and generate the lexical analyzer. As with regular programs, it
is not advised to write several hundred lines of lexer description
without stopping regularly to test their behaviour.</p>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
In this tutorial, we will generate and test the lexical analyzer
  using a command line interface, which may seem a tad tedious. A more
  convenient way of using Dolmen is via the companion
  <a href="https://dolmenplugin.stekikun.org">Eclipse plug-in</a>.  Nonetheless,
  the command line is useful in a variety of scenarios like building
  scripts, Makefile, continuous integration, etc.
</td>
</tr>
</table>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
The best way to enjoy this tutorial is to try and proceed
  along on your own system, following the different steps to
  reach an actual complete JSON lexer. We provide an
  <a href="./files/lexer-tutorial.tgz">archive</a>
  to set up a working directory just like the one we assume
  in this section. This archive also contains a basic <code>Makefile</code>
  to compiler the lexer and tokenizer, and a target <code>test</code> which
  runs the tokenizer as described below.
</td>
</tr>
</table>
</div>
<div class="paragraph">
<p>Suppose we have created a file <code>JsonLexer.jl</code> with our lexer
description so far, which looks as follows:</p>
</div>
<div class="listingblock">
<div class="title">JsonLexer.jl</div>
<div class="content">
<pre class="pygments highlight"><code data-lang="jl"><span class="tok-k">import</span> <span class="tok-nf">mypackage</span>.<span class="tok-nf">Token</span><span class="tok-p">;</span>
<span class="tok-k">import</span> <span class="tok-k">static</span> <span class="tok-nf">mypackage</span>.<span class="tok-nf">Token</span>.<span class="tok-o">*</span><span class="tok-p">;</span>

<span class="tok-g">{ }</span>

<span class="tok-nf">digit</span> <span class="tok-o">=</span> <span class="tok-p">[</span><span class="tok-sc">&#39;0&#39;</span><span class="tok-o">-</span><span class="tok-sc">&#39;9&#39;</span><span class="tok-p">];</span>
<span class="tok-nf">nzdigit</span> <span class="tok-o">=</span> <span class="tok-nf">digit</span> <span class="tok-o">#</span> <span class="tok-sc">&#39;0&#39;</span><span class="tok-p">;</span>
<span class="tok-nf">int</span> <span class="tok-o">=</span> <span class="tok-sc">&#39;-&#39;</span><span class="tok-o">?</span> <span class="tok-p">(</span><span class="tok-sc">&#39;0&#39;</span> <span class="tok-o">|</span> <span class="tok-nf">nzdigit</span> <span class="tok-nf">digit</span><span class="tok-o">*</span><span class="tok-p">);</span>
<span class="tok-nf">frac</span> <span class="tok-o">=</span> <span class="tok-sc">&#39;.&#39;</span> <span class="tok-nf">digit</span><span class="tok-o">+</span><span class="tok-p">;</span>
<span class="tok-nf">e</span> <span class="tok-o">=</span> <span class="tok-p">(</span><span class="tok-sc">&#39;e&#39;</span> <span class="tok-o">|</span> <span class="tok-sc">&#39;E&#39;</span><span class="tok-p">)</span> <span class="tok-p">(</span><span class="tok-sc">&#39;+&#39;</span> <span class="tok-o">|</span> <span class="tok-sc">&#39;-&#39;</span><span class="tok-p">)</span><span class="tok-o">?</span><span class="tok-p">;</span>
<span class="tok-nf">exp</span> <span class="tok-o">=</span> <span class="tok-nf">e</span> <span class="tok-nf">digit</span><span class="tok-o">+</span><span class="tok-p">;</span>
<span class="tok-nf">number</span> <span class="tok-o">=</span> <span class="tok-nf">int</span> <span class="tok-nf">frac</span><span class="tok-o">?</span> <span class="tok-nf">exp</span><span class="tok-o">?</span><span class="tok-p">;</span>

<span class="tok-k">public</span> <span class="tok-g">{ Token }</span> <span class="tok-k">rule</span> <span class="tok-nf">main</span> <span class="tok-o">=</span>
<span class="tok-o">|</span> <span class="tok-sc">&#39;{&#39;</span>      <span class="tok-g">{ </span><span class="tok-ge">return</span><span class="tok-g"> LBRACE; }</span>
<span class="tok-o">|</span> <span class="tok-sc">&#39;}&#39;</span>      <span class="tok-g">{ </span><span class="tok-ge">return</span><span class="tok-g"> RBRACE; }</span>
<span class="tok-o">|</span> <span class="tok-sc">&#39;[&#39;</span>      <span class="tok-g">{ </span><span class="tok-ge">return</span><span class="tok-g"> LBRACKET; }</span>
<span class="tok-o">|</span> <span class="tok-sc">&#39;]&#39;</span>      <span class="tok-g">{ </span><span class="tok-ge">return</span><span class="tok-g"> RBRACKET; }</span>
<span class="tok-o">|</span> <span class="tok-sc">&#39;:&#39;</span>      <span class="tok-g">{ </span><span class="tok-ge">return</span><span class="tok-g"> COLON; }</span>
<span class="tok-o">|</span> <span class="tok-sc">&#39;,&#39;</span>      <span class="tok-g">{ </span><span class="tok-ge">return</span><span class="tok-g"> COMMA; }</span>
<span class="tok-o">|</span> <span class="tok-s">&quot;true&quot;</span>   <span class="tok-g">{ </span><span class="tok-ge">return</span><span class="tok-g"> TRUE; }</span>
<span class="tok-o">|</span> <span class="tok-s">&quot;false&quot;</span>  <span class="tok-g">{ </span><span class="tok-ge">return</span><span class="tok-g"> FALSE; }</span>
<span class="tok-o">|</span> <span class="tok-s">&quot;null&quot;</span>   <span class="tok-g">{ </span><span class="tok-ge">return</span><span class="tok-g"> NULL; }</span>
<span class="tok-o">|</span> <span class="tok-nf">number</span>   <span class="tok-g">{ </span><span class="tok-ge">return</span><span class="tok-g"> NUMBER(Double.parseDouble(getLexeme())); }</span>

<span class="tok-g">{ }</span></code></pre>
</div>
</div>
<div class="paragraph">
<p>We also assume our working directory has the following structure:</p>
</div>
<div class="listingblock">
<div class="content">
<pre>./
 ├─ Dolmen_1.0.0.jar
 ├─ bin/
 │   └─ mypackage
 │       └─ Token.class
 └─ mypackage/
     ├─ Token.java
     └─ JsonLexer.jl</pre>
</div>
</div>
<div class="paragraph">
<p>Besides the source folder with our <code>Token</code> class and lexer file,
we also have a <code>bin/</code> folder for compiled classes, where <code>Token</code>
has already been compiled, and the Dolmen JAR. The JAR contains
both the runtime for Dolmen-generated analyzers, and the command
line interface to Dolmen. We can invoke the latter to generate
a lexical analyzer from our <code>JsonLexer.jl</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="pygments highlight"><code data-lang="console"><span class="tok-gp">$</span> java -jar Dolmen_1.0.0.jar -o mypackage -p mypackage mypackage/JsonLexer.jl
<span class="tok-go">Compiling lexer description mypackage/JsonLexer.jl</span>
<span class="tok-go">├─ Lexer description successfully parsed			[77ms]</span>
<span class="tok-go">├─ Compiled lexer description to automata			[57ms]</span>
<span class="tok-go">│  (29 states in 1 automata)</span>
<span class="tok-go">│  (1 potential problem found)</span>
<span class="tok-go">├─ Generated lexer in mypackage/JsonLexer.java			[29ms]</span>
<span class="tok-go">└─ Done in 163ms</span></code></pre>
</div>
</div>
<div class="paragraph">
<p>Dolmen reports the various steps of the generation process and
successfully generates a Java compilation unit <code>JSonLexer.java</code> in the
<code>mypackage</code> directory (as instructed by the <code>-o</code> option).  It also
found one "potential problem" along the way; unlike errors which are
fatal, problems are mere <em>warnings</em> which do not prevent the
generation of the analyzer. We will see below how to check and address
these problem reports, but for now let us continue with our main goal
and compile the generated analyzer:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="pygments highlight"><code data-lang="console"><span class="tok-gp">$</span> javac -d bin -classpath bin:Dolmen_1.0.0.jar mypackage/JsonLexer.java
<span class="tok-gp">$</span> javap -public bin/mypackage/JsonLexer.class
<span class="tok-go">Compiled from &quot;JsonLexer.java&quot;</span>
<span class="tok-go">public final class mypackage.JsonLexer extends org.stekikun.dolmen.codegen.LexBuffer {</span>
<span class="tok-go">  public mypackage.JsonLexer(java.lang.String, java.io.Reader);</span>
<span class="tok-go">  public mypackage.Token main();</span>
<span class="tok-go">}</span></code></pre>
</div>
</div>
<div class="paragraph">
<p>We have to add <code>Dolmen_1.0.0.jar</code> to the class path when invoking
<code>javac</code> since the JAR contains the Dolmen runtime that is used by the
generated lexer. Once the class is compiled, we can use the <code>javap</code>
disassembler tool to check that the generated lexer consists in a
single class <code>JsonLexer</code> with:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>a public constructor taking a <code>java.io.Reader</code> as an input
character stream (the first <code>String</code> argument is a user-friendly
<em>source name</em> and is only used in locations and error reports);</p>
</li>
<li>
<p>a public method <code>main</code> returning a <code>Token</code>, corresponding to
our main lexer entry.</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>In order to actually test this generated lexer, we write the following
<code>Tokenizer</code> class in <code>mypackage</code>:</p>
</div>
<div class="listingblock">
<div class="title">Tokenizer.java</div>
<div class="content">
<pre class="pygments highlight"><code data-lang="java"><table class="pyhltable"><tr><td class="linenos"><div class="linenodiv"> 1
 2
 3
 4
 5
 6
 7
 8
 9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26</div></td><td class="code"><span></span><span class="tok-kn">package</span> <span class="tok-nn">mypackage</span><span class="tok-o">;</span>

<span class="tok-kn">import</span> <span class="tok-nn">java.io.StringReader</span><span class="tok-o">;</span>
<span class="tok-kn">import</span> <span class="tok-nn">org.stekikun.dolmen.common.Prompt</span><span class="tok-o">;</span>
<span class="tok-kn">import</span> <span class="tok-nn">org.stekikun.dolmen.codegen.LexBuffer</span><span class="tok-o">;</span>
<span class="tok-kn">import</span> <span class="tok-nn">mypackage.Token</span><span class="tok-o">;</span>
<span class="tok-kn">import</span> <span class="tok-nn">mypackage.JsonLexer</span><span class="tok-o">;</span>

<span class="tok-kd">public</span> <span class="tok-kd">class</span> <span class="tok-nc">Tokenizer</span> <span class="tok-o">{</span>
    <span class="tok-kd">public</span> <span class="tok-kd">static</span> <span class="tok-kt">void</span> <span class="tok-nf">main</span><span class="tok-o">(</span><span class="tok-n">String</span> <span class="tok-n">args</span><span class="tok-o">[])</span> <span class="tok-o">{</span>
        <span class="tok-k">while</span> <span class="tok-o">(</span><span class="tok-kc">true</span><span class="tok-o">)</span> <span class="tok-o">{</span>
            <span class="tok-n">String</span> <span class="tok-n">line</span> <span class="tok-o">=</span> <span class="tok-n">Prompt</span><span class="tok-o">.</span><span class="tok-na">getInputLine</span><span class="tok-o">(</span><span class="tok-s">&quot;&quot;</span><span class="tok-o">);</span> <i class="conum" data-value="1"></i><b>(1)</b>
            <span class="tok-k">if</span> <span class="tok-o">(</span><span class="tok-n">line</span> <span class="tok-o">==</span> <span class="tok-kc">null</span> <span class="tok-o">||</span> <span class="tok-s">&quot;&quot;</span><span class="tok-o">.</span><span class="tok-na">equals</span><span class="tok-o">(</span><span class="tok-n">line</span><span class="tok-o">))</span> <span class="tok-k">break</span><span class="tok-o">;</span>

            <span class="tok-n">JsonLexer</span> <span class="tok-n">lexer</span> <span class="tok-o">=</span> <span class="tok-k">new</span> <span class="tok-n">JsonLexer</span><span class="tok-o">(</span><span class="tok-s">&quot;stdin&quot;</span><span class="tok-o">,</span> <span class="tok-k">new</span> <span class="tok-n">StringReader</span><span class="tok-o">(</span><span class="tok-n">line</span><span class="tok-o">));</span> <i class="conum" data-value="2"></i><b>(2)</b>
            <span class="tok-k">try</span> <span class="tok-o">{</span>
                <span class="tok-k">while</span> <span class="tok-o">(</span><span class="tok-kc">true</span><span class="tok-o">)</span> <span class="tok-o">{</span>
                    <span class="tok-n">System</span><span class="tok-o">.</span><span class="tok-na">out</span><span class="tok-o">.</span><span class="tok-na">println</span><span class="tok-o">(</span><span class="tok-n">lexer</span><span class="tok-o">.</span><span class="tok-na">main</span><span class="tok-o">());</span> <i class="conum" data-value="3"></i><b>(3)</b>
                <span class="tok-o">}</span>
            <span class="tok-o">}</span>
            <span class="tok-k">catch</span> <span class="tok-o">(</span><span class="tok-n">LexBuffer</span><span class="tok-o">.</span><span class="tok-na">LexicalError</span> <span class="tok-n">e</span><span class="tok-o">)</span> <span class="tok-o">{</span> <i class="conum" data-value="4"></i><b>(4)</b>
                <span class="tok-n">e</span><span class="tok-o">.</span><span class="tok-na">printStackTrace</span><span class="tok-o">();</span>
            <span class="tok-o">}</span>
        <span class="tok-o">}</span>
    <span class="tok-o">}</span>
<span class="tok-o">}</span>
</td></tr></table></code></pre>
</div>
</div>
<div class="colist arabic">
<table>
<tr>
<td><i class="conum" data-value="1"></i><b>1</b></td>
<td><a href="./javadoc/org/stekikun/dolmen/common/Prompt.html#getInputLine-java.lang.String-"><code>Prompt.getInputLine</code></a>
 is provided for quick testing by
the Dolmen runtime and simply returns a line of standard
input.</td>
</tr>
<tr>
<td><i class="conum" data-value="2"></i><b>2</b></td>
<td>We initialize a lexical analyzer with a stream formed
of the single line of input text.</td>
</tr>
<tr>
<td><i class="conum" data-value="3"></i><b>3</b></td>
<td>We call <code>lexer.main()</code> repeatedly to tokenize the input
stream and print the tokens.</td>
</tr>
<tr>
<td><i class="conum" data-value="4"></i><b>4</b></td>
<td><code>lexer.main()</code> will throw a <a href="./javadoc/org/stekikun/dolmen/codegen/LexBuffer.LexicalError.html"><code>LexicalError</code></a>
exception when encountering unsuitable input.</td>
</tr>
</table>
</div>
<div class="paragraph">
<p>We can compile <code>Tokenizer</code> and execute it, this shows us
a prompt waiting for some input to feed to the lexical analyzer:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="pygments highlight"><code data-lang="console"><span class="tok-gp">$</span> javac -d bin -classpath bin:Dolmen_1.0.0.jar mypackage/Tokenizer.java
<span class="tok-gp">$</span> java -classpath bin:Dolmen_1.0.0.jar mypackage.Tokenizer
<span class="tok-gp">&gt;</span></code></pre>
</div>
</div>
<div class="paragraph">
<p>If we try a couple of very simple sentences using some JSON literals, we
see the tokens seem to be recognized correctly but our lexer always ends
up throwing an exception:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="pygments highlight"><code data-lang="doscon"><span class="tok-gp">&gt;</span> true
<span class="tok-go">TRUE</span>
<span class="tok-go">org.stekikun.dolmen.codegen.LexBuffer$LexicalError: Empty token (in stdin, at line 1, column 5)</span>
<span class="tok-go">	at org.stekikun.dolmen.codegen.LexBuffer.error(LexBuffer.java:639)</span>
<span class="tok-go">	at mypackage.JsonLexer.main(JsonLexer.java:67)</span>
<span class="tok-go">	at mypackage.Tokenizer.main(Tokenizer.java:18)</span>
<span class="tok-gp">&gt;</span> 3.14159e+0
<span class="tok-go">NUMBER(3,14159)</span>
<span class="tok-go">org.stekikun.dolmen.codegen.LexBuffer$LexicalError: Empty token (in stdin, at line 1, column 11)</span>
<span class="tok-go">	at org.stekikun.dolmen.codegen.LexBuffer.error(LexBuffer.java:639)</span>
<span class="tok-go">	at mypackage.JsonLexer.main(JsonLexer.java:67)</span>
<span class="tok-go">	at mypackage.Tokenizer.main(Tokenizer.java:18)</span>
<span class="tok-gp">&gt;</span> {}
<span class="tok-go">LBRACE</span>
<span class="tok-go">RBRACE</span>
<span class="tok-go">org.stekikun.dolmen.codegen.LexBuffer$LexicalError: Empty token (in stdin, at line 1, column 3)</span>
<span class="tok-go">	at org.stekikun.dolmen.codegen.LexBuffer.error(LexBuffer.java:639)</span>
<span class="tok-go">	at mypackage.JsonLexer.main(JsonLexer.java:67)</span>
<span class="tok-go">	at mypackage.Tokenizer.main(Tokenizer.java:18)</span></code></pre>
</div>
</div>
<div class="paragraph">
<p>The <code>Empty token</code> lexical error is Dolmen&#8217;s way of expressing that the
input stream at this point did not match any of the clauses in the
main lexer entry. Dolmen also reports the position in the input stream
at which the error occurred, in our case it always seems to occur at
the end of our input string. Indeed, we never put any rule in our
lexer entry to express what needed to be done when running out of
input; because the entry cannot match an empty string either, it fails
with an empty token error when reaching end of input.</p>
</div>
<div class="paragraph">
<p>A typical way of handling the end of input when parsing a language is
to use a dedicated token to represent when it has been reached. In
order to produce such token, we need to write a clause which
recognizes the end of input specifically: for that purpose, the <code>eof</code>
keyword can be used in regular expressions inside Dolmen lexer
descriptions. <code>eof</code> will match the input if and only if the end of
input has been reached, and will not consume any of it. Therefore,
let us add a new token <code>Token.EOF</code> to our token factory, and
a new clause to our lexer description:</p>
</div>
<div class="listingblock">
<div class="title">JsonLexer.jl</div>
<div class="content">
<pre class="pygments highlight"><code data-lang="jl">...
<span class="tok-o">|</span> <span class="tok-k">eof</span>   <span class="tok-g">{ </span><span class="tok-ge">return</span><span class="tok-g"> EOF; }</span></code></pre>
</div>
</div>
<div class="paragraph">
<p>We also fix the inner loop of the <code>Tokenizer</code> class so that
it stops the lexical analysis as soon as it reaches the
<code>EOF</code> token:</p>
</div>
<div class="listingblock">
<div class="title">Tokenizer.java</div>
<div class="content">
<pre class="pygments highlight"><code data-lang="java">    <span class="tok-o">...</span>
    <span class="tok-n">Token</span> <span class="tok-n">tok</span><span class="tok-o">;</span>
    <span class="tok-k">while</span> <span class="tok-o">((</span><span class="tok-n">tok</span> <span class="tok-o">=</span> <span class="tok-n">lexer</span><span class="tok-o">.</span><span class="tok-na">main</span><span class="tok-o">())</span> <span class="tok-o">!=</span> <span class="tok-n">Token</span><span class="tok-o">.</span><span class="tok-na">EOF</span><span class="tok-o">)</span> <span class="tok-o">{</span>
        <span class="tok-n">System</span><span class="tok-o">.</span><span class="tok-na">out</span><span class="tok-o">.</span><span class="tok-na">println</span><span class="tok-o">(</span><span class="tok-n">tok</span><span class="tok-o">);</span>
    <span class="tok-o">}</span>
    <span class="tok-o">...</span></code></pre>
</div>
</div>
<div class="paragraph">
<p>After generating the lexer anew and recompiling everything, we see the
end of input seems to be handled correctly now:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="pygments highlight"><code data-lang="doscon"><span class="tok-gp">&gt;</span> false
<span class="tok-go">FALSE</span>
<span class="tok-gp">&gt;</span> 27.1828E-1
<span class="tok-go">NUMBER(2,71828)</span>
<span class="tok-gp">&gt;</span> [:]
<span class="tok-go">LBRACKET</span>
<span class="tok-go">COLON</span>
<span class="tok-go">RBRACKET</span></code></pre>
</div>
</div>
<div class="paragraph">
<p>Armed with such success, surely we can start testing more complex
sequences of tokens!</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="pygments highlight"><code data-lang="doscon"><span class="tok-gp">&gt;</span> [12.34e5, {false}, null]
<span class="tok-go">LBRACKET</span>
<span class="tok-go">NUMBER(1,23400e+06)</span>
<span class="tok-go">COMMA</span>
<span class="tok-go">org.stekikun.dolmen.codegen.LexBuffer$LexicalError: Empty token (in stdin, at line 1, column 10)</span>
<span class="tok-go">	at org.stekikun.dolmen.codegen.LexBuffer.error(LexBuffer.java:639)</span>
<span class="tok-go">	at mypackage.JsonLexer1.main(JsonLexer1.java:70)</span>
<span class="tok-go">	at mypackage.Tokenizer1.main(Tokenizer1.java:18)</span></code></pre>
</div>
</div>
<div class="paragraph">
<p>This time, the empty token error occurs at the space following the
first comma in our input string. So far our clauses have only dealt
with recognizing and producing actual tokens of the language, but we
have not yet instructed the lexer as to what sequences of characters,
if any, can safely be skipped during lexical analysis, in other words
we have not dealt with <em>whitespace</em>. The <a href="http://www.ecma-international.org/publications/files/ECMA-ST/ECMA-404.pdf">JSON standard</a>
defines exactly what constitutes whitespace in a JSON file:</p>
</div>
<div class="quoteblock">
<blockquote>
<div class="paragraph">
<p>Insignificant whitespace is allowed before or after any
token. Whitespace is any sequence of one or more of the following code
points: character tabulation (U+0009), line feed (U+000A), carriage
return (U+000D), and space (U+0020).Whitespace is not allowed within
any token, except that space is allowed in strings.</p>
</div>
</blockquote>
<div class="attribution">
&#8212; The JSON standard (Sec. 4)
</div>
</div>
<div class="paragraph">
<p>We can now define a regular expression to match that definition
and use it in a clause to correctly skip whitespace:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="pygments highlight"><code data-lang="jl"><span class="tok-nf">ws</span> <span class="tok-o">=</span> <span class="tok-p">[</span><span class="tok-sc">&#39;\</span><span class="tok-s">u0009</span><span class="tok-sc">&#39;</span> <span class="tok-sc">&#39;\</span><span class="tok-s">u000A</span><span class="tok-sc">&#39;</span> <span class="tok-sc">&#39;\</span><span class="tok-s">u000D</span><span class="tok-sc">&#39;</span> <span class="tok-sc">&#39;\</span><span class="tok-s">u0020</span><span class="tok-sc">&#39;</span><span class="tok-p">]</span><span class="tok-o">+</span><span class="tok-p">;</span></code></pre>
</div>
</div>
<div class="paragraph">
<p>We will, for reasons that will be explained later on,
do things slightly differently and handle regular whitespace
and line terminators separately. Moreover, we use the more
traditional escape characters to keep things more readable:</p>
</div>
<div class="listingblock">
<div class="title">Adding whitespace clauses to JSonLexer.jl</div>
<div class="content">
<pre class="pygments highlight"><code data-lang="jl"><span class="tok-nf">ws</span> <span class="tok-o">=</span> <span class="tok-p">[</span><span class="tok-sc">&#39;\</span><span class="tok-s">t</span><span class="tok-sc">&#39;</span> <span class="tok-sc">&#39; &#39;</span><span class="tok-p">]</span><span class="tok-o">+</span><span class="tok-p">;</span>
<span class="tok-nf">nl</span> <span class="tok-o">=</span> <span class="tok-p">(</span><span class="tok-sc">&#39;\</span><span class="tok-s">n</span><span class="tok-sc">&#39;</span> <span class="tok-o">|</span> <span class="tok-sc">&#39;\</span><span class="tok-s">r</span><span class="tok-sc">&#39;</span> <span class="tok-o">|</span> <span class="tok-s">&quot;\r\n&quot;</span><span class="tok-p">);</span>
... <span class="tok-c tok-c-Singleline">// other regexps</span>

<span class="tok-k">public</span> <span class="tok-g">{ Token }</span> <span class="tok-k">rule</span> <span class="tok-nf">main</span> <span class="tok-o">=</span>
<span class="tok-o">|</span> <span class="tok-nf">ws</span>   <span class="tok-g">{ </span><span class="tok-ge">continue</span><span class="tok-g"> main; }</span>
<span class="tok-o">|</span> <span class="tok-nf">nl</span>   <span class="tok-g">{ </span><span class="tok-ge">continue</span><span class="tok-g"> main; }</span>
... <span class="tok-c tok-c-Singleline">// other clauses</span></code></pre>
</div>
</div>
<div class="paragraph">
<p>Along with the regular expressions, We added clauses at the beginning
of our <code>main</code> lexer entry to handle both whitespace and newline
sequences. The way we express in our semantic actions that the matched
whitespace should be skipped is by simply starting the <code>main</code> entry
again on the remaining input. There are mostly two ways to do that:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>using a Java <code>continue</code> statement as we do here, to restart the
current lexer entry without actually calling the Java method
implementing the entry; this works because Dolmen always generates
the code of a lexer entry in a loop with a
<a href="https://docs.oracle.com/javase/specs/jls/se8/html/jls-14.html#jls-LabeledStatement">labeled statement</a>
whose label is exactly the name of the entry;</p>
</li>
<li>
<p>simply calling the <code>main</code> rule (tail-)recursively by
writing <code>{ return main(); }</code>, which would have been almost
equivalent to the <code>continue</code> alternative.</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>The trade-offs of choosing the latter over the <code>continue</code> statement
are discussed in <a href="#Lexers_Tail_Recursion_Ref">advanced concepts</a>, but
a good rule of thumb is that <code>continue</code> should be preferred whenever
possible.</p>
</div>
<div class="paragraph">
<p>After recompiling everything, we can test that whitespace now seems to
be handled correctly, and we can tokenize non-trivial JSON contents:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="pygments highlight"><code data-lang="doscon"><span class="tok-gp">&gt;</span> [false, 2.71828, [null, []], true]
<span class="tok-go">LBRACKET</span>
<span class="tok-go">FALSE</span>
<span class="tok-go">COMMA</span>
<span class="tok-go">NUMBER(2,71828)</span>
<span class="tok-go">COMMA</span>
<span class="tok-go">LBRACKET</span>
<span class="tok-go">NULL</span>
<span class="tok-go">COMMA</span>
<span class="tok-go">LBRACKET</span>
<span class="tok-go">RBRACKET</span>
<span class="tok-go">RBRACKET</span>
<span class="tok-go">COMMA</span>
<span class="tok-go">TRUE</span>
<span class="tok-go">RBRACKET</span></code></pre>
</div>
</div>
<div class="paragraph">
<p>The only JSON feature missing at this point in our lexer
is actually string literals, and we will see how to handle
them in the next section.</p>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
<div class="paragraph">
<p>The JSON language does not allow comments, but this is where
comments would be handled in our lexical analyzer if we needed to.
Indeed, from a lexical point of view, comments are just delimited
parts of the input which serve as whitespace and separate the
actual tokens. For instance, a typical <code>//</code> line-terminated C++
comment could be handled by the following clause:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="pygments highlight"><code data-lang="jl"><span class="tok-c tok-c-Singleline">// Single-line comment</span>
<span class="tok-o">|</span> <span class="tok-s">&quot;//&quot;</span> <span class="tok-p">[</span><span class="tok-o">^</span><span class="tok-sc">&#39;\</span><span class="tok-s">n</span><span class="tok-sc">&#39;</span> <span class="tok-sc">&#39;\</span><span class="tok-s">r</span><span class="tok-sc">&#39;</span><span class="tok-p">]</span><span class="tok-o">*</span>    <span class="tok-g">{ </span><span class="tok-ge">continue</span><span class="tok-g"> main; }</span></code></pre>
</div>
</div>
</td>
</tr>
</table>
</div>
<div class="admonitionblock caution">
<table>
<tr>
<td class="icon">
<i class="fa icon-caution" title="Caution"></i>
</td>
<td class="content">
<div class="paragraph">
<p>Note that the JSON standard does not make whitespace <em>mandatory</em>
between lexical elements. In particular, it is fine, even if perhaps
surprising at first, that our lexer analyzes the input string
<code>truefalse</code> as the two keywords <code>true</code> and <code>false</code> in succession:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="pygments highlight"><code data-lang="doscon"><span class="tok-gp">&gt;</span> truefalse
<span class="tok-go">TRUE</span>
<span class="tok-go">FALSE</span></code></pre>
</div>
</div>
<div class="paragraph">
<p>This is the correct lexical analysis of the input, and stems from the
fact that there are no lexical elements like user-defined
"identifiers" in JSON. In a language with alphanumeric identifiers,
the longest-match rule would ensure that this input be seen as the
single identifier <em>truefalse</em>.</p>
</div>
<div class="paragraph">
<p>Now, there is no valid JSON file where the keywords <code>true</code> and
<code>false</code> would make sense in succession, but this is a matter for
the syntactic analysis and not for the lexing phase to sort out.</p>
</div>
</td>
</tr>
</table>
</div>
</div>
<div class="sect3">
<h4 id="_adding_more_entries">Adding More Entries</h4>
<div class="paragraph">
<p>The last kind of tokens we need to recognize is string
literals. Again, the <a href="http://www.ecma-international.org/publications/files/ECMA-ST/ECMA-404.pdf">JSON standard</a> proposes a <em>railroad
diagram</em> for JSON string values:</p>
</div>
<div class="imageblock" style="text-align: center">
<div class="content">
<img src="./images/json_string.png" alt="JSON strings" width="50%">
</div>
</div>
<div class="paragraph">
<p>A literal string is therefore a sequence of unicode code points
delimited by double-quote characters. Between the delimiters, all
unicode code points are valid except for the <em>control characters</em>
(code points below 0x20), the backslash character <code>\</code> and the
quotation mark <code>"</code> itself of course. The <code>"</code> and <code>\</code> characters can be
inserted via <em>escape sequences</em> instead, as well as a few common
control characters.  Finally, any code point in the Basic Multilingual
Plane can be inserted via its four-digit hexadecimal value using the
<code>\uxxxx</code> escaping sequence.</p>
</div>
<div class="admonitionblock warning">
<table>
<tr>
<td class="icon">
<i class="fa icon-warning" title="Warning"></i>
</td>
<td class="content">
<div class="paragraph">
<p>The JSON standard does not assume a particular <em>encoding</em> and
specifies characters using their Unicode code points. The whole point
of having <code>\uxxxx</code> escape sequences in the syntax is precisely to
allow a portable way of adding any code point that is not directly
available in the input encoding.</p>
</div>
<div class="paragraph">
<p>In our case, Dolmen relies on Java and thus uses UTF-16, as does the
input stream in our <code>Tokenizer</code> class. Unicode code points outside the
Basic Multilingual Plane cannot be represented with a single character
or escape sequence; one must use two code points (a
<a href="https://docs.oracle.com/javase/tutorial/i18n/text/supplementaryChars.html"><em>surrogate
pair</em></a>) instead. For instance, the Unicode code point <code>U+1D11E</code>, which
is the symbol for the musical G clef &#119070;, can be obtained with
two Unicode escape sequences <code>\uD834\uDD1E</code>.</p>
</div>
</td>
</tr>
</table>
</div>
<div class="paragraph">
<p>A possible approach to recognizing these string literals would be
to write a complex regular expression such as this:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="pygments highlight"><code data-lang="jl"><span class="tok-nf">hexDigit</span> <span class="tok-o">=</span> <span class="tok-p">[</span><span class="tok-sc">&#39;0&#39;</span><span class="tok-o">-</span><span class="tok-sc">&#39;9&#39;</span> <span class="tok-sc">&#39;a&#39;</span><span class="tok-o">-</span><span class="tok-sc">&#39;f&#39;</span> <span class="tok-sc">&#39;A&#39;</span><span class="tok-o">-</span><span class="tok-sc">&#39;F&#39;</span><span class="tok-p">];</span>
<span class="tok-nf">escapeChar</span> <span class="tok-o">=</span> <span class="tok-p">[</span><span class="tok-sc">&#39;&quot;&#39;</span> <span class="tok-sc">&#39;\</span><span class="tok-s">\</span><span class="tok-sc">&#39;</span> <span class="tok-sc">&#39;/&#39;</span> <span class="tok-sc">&#39;b&#39;</span> <span class="tok-sc">&#39;n&#39;</span> <span class="tok-sc">&#39;r&#39;</span> <span class="tok-sc">&#39;f&#39;</span> <span class="tok-sc">&#39;t&#39;</span><span class="tok-p">];</span>
<span class="tok-nf">escapeSeq</span> <span class="tok-o">=</span> <span class="tok-sc">&#39;\</span><span class="tok-s">\</span><span class="tok-sc">&#39;</span> <span class="tok-p">(</span> <span class="tok-sc">&#39;u&#39;</span> <span class="tok-nf">hexDigit</span><span class="tok-p">&lt;</span><span class="tok-m">4</span><span class="tok-p">&gt;</span> <span class="tok-o">|</span> <span class="tok-nf">escapeChar</span> <span class="tok-p">);</span>
<span class="tok-nf">string</span> <span class="tok-o">=</span> <span class="tok-sc">&#39;&quot;&#39;</span> <span class="tok-p">([</span><span class="tok-o">^</span><span class="tok-sc">&#39;\</span><span class="tok-s">000</span><span class="tok-sc">&#39;</span><span class="tok-o">-</span><span class="tok-sc">&#39;\</span><span class="tok-s">037</span><span class="tok-sc">&#39;</span> <span class="tok-sc">&#39;&quot;&#39;</span> <span class="tok-sc">&#39;\</span><span class="tok-s">\</span><span class="tok-sc">&#39;</span><span class="tok-p">]</span> <span class="tok-o">|</span> <span class="tok-nf">escapeSeq</span><span class="tok-p">)</span><span class="tok-o">*</span> <span class="tok-sc">&#39;&quot;&#39;</span><span class="tok-p">;</span></code></pre>
</div>
</div>
<div class="paragraph">
<p>and add the corresponding clause in our <code>main</code> lexer entry:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="pygments highlight"><code data-lang="jl">...
<span class="tok-o">|</span> <span class="tok-nf">string</span>     <span class="tok-g">{ </span><span class="tok-ge">return</span><span class="tok-g"> STRING(decode(getLexeme())); }</span></code></pre>
</div>
</div>
<div class="paragraph">
<p>where <code>decode</code> would be some Java method to decode the contents of the
literal string, by removing the quotation marks and replacing the
escape sequences with the characters they stand for. Now there are at
least two shortcomings with proceeding in this fashion:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>the <code>decode</code> method will have to match the contents of the string,
including the various escape sequences, and that is exactly the job
the lexer did whilst matching the <code>string</code> regular expression; we
are using a lexical analyzer generator precisely to avoid having to
write such code manually so it would be quite disappointing to have
to duplicate the analysis in this way;</p>
</li>
<li>
<p>when a lexical error occurs inside a string literal, the input will
not match the <code>string</code> regular expression and a lexical error will
be raised <strong>at the position of the opening quotation mark</strong>; if the
error is about an invalid character or an invalid escape sequence,
it would be much more user-friendly and informative to actually
report the error at its actual position, allowing a more specific
error message and also showing that the contents of the string
up to that point were valid.</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>The solution to both of those issues is simply to use the lexical
analyzer itself to recognize, and decode at the same time, the
contents of a string literal. As explained earlier in this tutorial, a
lexical analyzer can be used for many things besides simply tokenizing
input in a parser, and unescaping a string is one of them. To that
end, we introduce in <code>JSonLexer.jl</code> a new lexer entry called <code>string</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="pygments highlight"><code data-lang="jl"><span class="tok-k">private</span> <span class="tok-g">{ String }</span> <span class="tok-k">rule</span> <span class="tok-nf">string</span><span class="tok-g">{StringBuilder buf}</span> <span class="tok-o">=</span>
<span class="tok-o">|</span> <span class="tok-sc">&#39;&quot;&#39;</span>      <span class="tok-g">{ </span><span class="tok-ge">return</span><span class="tok-g"> buf.toString(); }</span>
...</code></pre>
</div>
</div>
<div class="paragraph">
<p>which differs from the <code>main</code> entry in several aspects:</p>
</div>
<div class="olist arabic">
<ol class="arabic">
<li>
<p>The rule <code>string</code> has <code>private</code> visibility, which means the
corresponding method will be a private Java method. Indeed, <code>string</code>
is intended to be called from <code>main</code> and not from client code
outside the analyzer. A Dolmen lexer description can have more than
one public entry nonetheless.</p>
</li>
<li>
<p>The return type for this rule is <code>String</code> and not <code>Token</code>. Indeed,
the purpose of this entry is to recognize and decode a string literal,
and the result of a successful match will be the contents of the
decoded literal.</p>
</li>
<li>
<p>The rule <code>string</code> has <em>arguments</em>, namely a single argument <code>buf</code>
with type <code>java.lang.Stringbuilder</code>. In Dolmen, lexer entries can be
parameterized with arguments, which can be passed from client Java
code or when calling an entry from another entry&#8217;s semantic action.
In this case, the rule expects a buffer which will be filled as the
contents of the string literal are matched.</p>
</li>
</ol>
</div>
<div class="paragraph">
<p>This entry is intended to be called after encountering the opening
quotation mark of a string literal, and must stop at the corresponding
closing delimiter. This is handled by the first clause above, which
returns the contents of the given buffer <code>buf</code> when matching <code>"</code>. We
need two other clauses: one for escape sequences introduced by the <code>\</code>
character and the other for all other valid Unicode characters. Here
is our <code>string</code> entry in full:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="pygments highlight"><code data-lang="jl"><span class="tok-k">private</span> <span class="tok-g">{ String }</span> <span class="tok-k">rule</span> <span class="tok-nf">string</span><span class="tok-g">{StringBuilder buf}</span> <span class="tok-o">=</span>
<span class="tok-o">|</span> <span class="tok-sc">&#39;&quot;&#39;</span>      <span class="tok-g">{ </span><span class="tok-ge">return</span><span class="tok-g"> buf.toString(); }</span>
<span class="tok-o">|</span> <span class="tok-sc">&#39;\</span><span class="tok-s">\</span><span class="tok-sc">&#39;</span>     <span class="tok-g">{ </span><span class="tok-ge">char</span><span class="tok-g"> c = escapeSequence();</span>
<span class="tok-g">             buf.append(c);</span>
<span class="tok-g">             </span><span class="tok-ge">continue</span><span class="tok-g"> string;</span>
<span class="tok-g">           }</span>
<span class="tok-o">|</span> <span class="tok-p">[</span><span class="tok-o">^</span><span class="tok-sc">&#39;\</span><span class="tok-s">000</span><span class="tok-sc">&#39;</span><span class="tok-o">-</span><span class="tok-sc">&#39;\</span><span class="tok-s">037</span><span class="tok-sc">&#39;</span> <span class="tok-sc">&#39;&quot;&#39;</span> <span class="tok-sc">&#39;\</span><span class="tok-s">\</span><span class="tok-sc">&#39;</span><span class="tok-p">]</span><span class="tok-o">+</span>
           <span class="tok-g">{ buf.append(getLexeme());</span>
<span class="tok-g">             </span><span class="tok-ge">continue</span><span class="tok-g"> string;</span>
<span class="tok-g">           }</span></code></pre>
</div>
</div>
<div class="paragraph">
<p>The third clause matches all non-escaped contents and uses the
<code>[^&#8230;&#8203;]</code> construct to match all characters that <strong>do not</strong> belong to the
specified character set; the characters <code>\000</code> and <code>\037</code> are given in
<em>octal code</em> syntax and their interval corresponds to control
characters. Matched input in this clause is simply appended to the
string buffer that will be returned eventually, and the rule is
started over using the <code>continue</code> operator. Now the second clause is
more interesting as it deals with escape sequences; it simply matches
a backslash character and then calls a method <code>escapeSequence</code> to
retrieve the escaped character, append it to the buffer and continue
the analysis. This <code>escapeSequence</code> method is simply yet another lexer
entry whose job it is to parse and interpret any escape character or
code and return the corresponding character:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="pygments highlight"><code data-lang="jl"><span class="tok-k">private</span> <span class="tok-g">{ </span><span class="tok-ge">char</span><span class="tok-g"> }</span> <span class="tok-k">rule</span> <span class="tok-nf">escapeSequence</span> <span class="tok-o">=</span>
<span class="tok-o">|</span> <span class="tok-sc">&#39;b&#39;</span>	 <span class="tok-g">{ </span><span class="tok-ge">return</span><span class="tok-g"> </span><span class="tok-gs">&#39;\b&#39;</span><span class="tok-g">; }</span>
<span class="tok-o">|</span> <span class="tok-sc">&#39;t&#39;</span>	 <span class="tok-g">{ </span><span class="tok-ge">return</span><span class="tok-g"> </span><span class="tok-gs">&#39;\t&#39;</span><span class="tok-g">; }</span>
<span class="tok-o">|</span> <span class="tok-sc">&#39;n&#39;</span>	 <span class="tok-g">{ </span><span class="tok-ge">return</span><span class="tok-g"> </span><span class="tok-gs">&#39;\n&#39;</span><span class="tok-g">; }</span>
<span class="tok-o">|</span> <span class="tok-sc">&#39;f&#39;</span>	 <span class="tok-g">{ </span><span class="tok-ge">return</span><span class="tok-g"> </span><span class="tok-gs">&#39;\f&#39;</span><span class="tok-g">; }</span>
<span class="tok-o">|</span> <span class="tok-sc">&#39;r&#39;</span>	 <span class="tok-g">{ </span><span class="tok-ge">return</span><span class="tok-g"> </span><span class="tok-gs">&#39;\r&#39;</span><span class="tok-g">; }</span>
<span class="tok-o">|</span> <span class="tok-sc">&#39;&quot;&#39;</span>	 <span class="tok-g">{ </span><span class="tok-ge">return</span><span class="tok-g"> </span><span class="tok-gs">&#39;&quot;&#39;</span><span class="tok-g">; }</span>
<span class="tok-o">|</span> <span class="tok-sc">&#39;\</span><span class="tok-s">&#39;</span><span class="tok-sc">&#39;</span>	 <span class="tok-g">{ </span><span class="tok-ge">return</span><span class="tok-g"> </span><span class="tok-gs">&#39;\&#39;&#39;</span><span class="tok-g">; }</span>
<span class="tok-o">|</span> <span class="tok-sc">&#39;\</span><span class="tok-s">\</span><span class="tok-sc">&#39;</span>	 <span class="tok-g">{ </span><span class="tok-ge">return</span><span class="tok-g"> </span><span class="tok-gs">&#39;\\&#39;</span><span class="tok-g">; }</span>
<span class="tok-o">|</span> <span class="tok-sc">&#39;/&#39;</span>	 <span class="tok-g">{ </span><span class="tok-ge">return</span><span class="tok-g"> </span><span class="tok-gs">&#39;/&#39;</span><span class="tok-g">; }</span>
<span class="tok-o">|</span> <span class="tok-sc">&#39;u&#39;</span> <span class="tok-p">(</span><span class="tok-nf">hexDigit</span><span class="tok-p">&lt;</span><span class="tok-m">4</span><span class="tok-p">&gt;</span> <span class="tok-k">as</span> <span class="tok-nf">code</span><span class="tok-p">)</span>
	 <span class="tok-g">{ </span><span class="tok-ge">return</span><span class="tok-g"> ((</span><span class="tok-ge">char</span><span class="tok-g">)(Integer.parseInt(code, 16))); }</span></code></pre>
</div>
</div>
<div class="paragraph">
<p>The rule <code>escapeSequence</code> is private, expects no arguments, and simply
returns a simple Java <code>char</code>. It matches all accepted escape
characters as well as Unicode escape codes. For the latter, the
regular expression <code>hexDigit&lt;4&gt; as code</code> is particularly interesting:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>the repetition operator <code>r&lt;n&gt;</code> is used to parse exactly <code>n</code> repetitions
of the regular expression <code>r</code>; in its more general form <code>r&lt;n, m&gt;</code>, it
matches from <code>n</code> to (inclusive) <code>m</code> repetitions of <code>r</code>;</p>
</li>
<li>
<p>the <code>as</code> operator is used to <em>capture</em> a sub-part of the input which
matches a rule: <code>r as id</code> will make the part of the input which
matched the regular expression <code>r</code> available in the semantic action
as a Java variable with the name <code>id</code>; this avoids potentially
costly manipulation of the lexeme string in the semantic action (in
this case, extracting a suffix) which often duplicates some of the
work that has been performed when matching the input in the first
place.</p>
</li>
</ul>
</div>
<div class="exampleblock">
<div class="title">Example</div>
<div class="content">
<div class="paragraph">
<p>For an example of how the <code>as</code> operator can really help improve
a clause, consider the <a href="https://docs.oracle.com/javase/specs/jls/se8/html/jls-3.html#jls-3.3">Unicode
escape sequences</a> in Java which accept any number of leading <code>u</code>s,
using:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="pygments highlight"><code data-lang="jl"><span class="tok-o">|</span> <span class="tok-sc">&#39;u&#39;</span><span class="tok-o">+</span> <span class="tok-p">(</span><span class="tok-nf">hexDigit</span><span class="tok-p">&lt;</span><span class="tok-m">4</span><span class="tok-p">&gt;</span> <span class="tok-k">as</span> <span class="tok-nf">code</span><span class="tok-p">)</span>
       <span class="tok-g">{ ... </span><span class="tok-gd">/* use code */</span><span class="tok-g"> ... }</span></code></pre>
</div>
</div>
<div class="paragraph">
<p>is more readable and more efficient than a solution without captures:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="pygments highlight"><code data-lang="jl"><span class="tok-o">|</span> <span class="tok-sc">&#39;u&#39;</span><span class="tok-o">+</span> <span class="tok-nf">hexDigit</span><span class="tok-p">&lt;</span><span class="tok-m">4</span><span class="tok-p">&gt;</span>
       <span class="tok-g">{ String lex = getLexeme();</span>
<span class="tok-g">         String code = lex.substring(lex.lastOf(</span><span class="tok-gs">&#39;u&#39;</span><span class="tok-g">) + 1);</span>
<span class="tok-g">         ... </span><span class="tok-gd">/* use code */</span><span class="tok-g"> ... }</span></code></pre>
</div>
</div>
</div>
</div>
<div class="paragraph">
<p>At this point, our <code>string</code> entry&#8212;&#8203;and its auxiliary rule for escape
sequences&#8212;&#8203;can recognize and decode JSon string literals' contents in
an elegant fashion, the last step is simply to call <code>string</code> from our
<code>main</code> lexer entry:</p>
</div>
<div class="listingblock">
<div class="title">JSonLexer.jl, main entry</div>
<div class="content">
<pre class="pygments highlight"><code data-lang="jl">...
<span class="tok-o">|</span> <span class="tok-sc">&#39;&quot;&#39;</span>      <span class="tok-g">{ </span><span class="tok-ge">return</span><span class="tok-g"> STRING(string(</span><span class="tok-ge">new</span><span class="tok-g"> StringBuilder())); }</span>
...</code></pre>
</div>
</div>
<div class="paragraph">
<p>This simply matches the opening quotation mark, and calls the <code>string</code>
rule recursively with a fresh <code>StringBuilder</code> instance before
returning the overall token. Now, our analyzer&#8217;s entries are not
<em>reentrant</em> (or rather, they do not <strong>need</strong> to be), so it seems a bit
wasteful to build a <code>StringBuilder</code> instance for every string that we
are going to encounter, especially because typical JSON objects
contain many string literals, in part as keys of JSON objects. A more
resourceful way of proceeding is to use a single local buffer.
We can add such a buffer to the fields of the generated lexer by using
the <em>prelude</em> or <em>postlude</em>, which we had left empty so far, and adapt our
clause accordingly:</p>
</div>
<div class="listingblock">
<div class="title">JSonLexer.jl, main entry</div>
<div class="content">
<pre class="pygments highlight"><code data-lang="jl"><span class="tok-c tok-c-Singleline">// Prelude</span>
<span class="tok-g">{</span>
<span class="tok-g">    </span><span class="tok-ge">private</span><span class="tok-g"> </span><span class="tok-ge">final</span><span class="tok-g"> StringBuilder buffer = </span><span class="tok-ge">new</span><span class="tok-g"> StringBuilder(); </span><i class="conum" data-value="1"></i><b>(1)</b>
<span class="tok-g">}</span>

<span class="tok-c tok-c-Singleline">// In the main entry</span>
...
<span class="tok-o">|</span> <span class="tok-sc">&#39;&quot;&#39;</span>      <span class="tok-g">{ buffer.setLength(0); </span><i class="conum" data-value="2"></i><b>(2)</b>
<span class="tok-g">             String s = string(buffer);</span>
<span class="tok-g">             </span><span class="tok-ge">return</span><span class="tok-g"> STRING(s);</span>
<span class="tok-g">           }</span>
...</code></pre>
</div>
</div>
<div class="colist arabic">
<table>
<tr>
<td><i class="conum" data-value="1"></i><b>1</b></td>
<td>Declare and initialize a local string buffer</td>
</tr>
<tr>
<td><i class="conum" data-value="2"></i><b>2</b></td>
<td>Take care of clearing the buffer before passing it to the <code>string</code> rule.</td>
</tr>
</table>
</div>
<div class="paragraph">
<p>We are now ready to regenerate our lexical analyzer:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="pygments highlight"><code data-lang="console"><span class="tok-go">java -jar Dolmen_1.0.0.jar -o mypackage -p mypackage mypackage/JsonLexer.jl</span>
<span class="tok-go">Compiling lexer description mypackage/JsonLexer.jl</span>
<span class="tok-go">├─ Lexer description successfully parsed			[83ms]</span>
<span class="tok-go">├─ Compiled lexer description to automata			[66ms]</span>
<span class="tok-go">│  (51 states in 3 automata)</span>
<span class="tok-go">│  (3 potential problems found)</span>
<span class="tok-go">├─ Generated lexer in mypackage/JsonLexer.java			[38ms]</span>
<span class="tok-go">└─ Done in 187ms</span></code></pre>
</div>
</div>
<div class="paragraph">
<p>and after recompiling the Java units, we can finally handle full JSON:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="pygments highlight"><code data-lang="doscon"><span class="tok-gp">&gt;</span> { <span class="tok-s2">&quot;\u0025foo\\&quot;</span>: [-1.34, <span class="tok-s2">&quot;Foo&quot;</span>, [null, <span class="tok-s2">&quot;Barא&quot;</span>, <span class="tok-s2">&quot;\uD834\uDD1E&quot;</span>]] }
<span class="tok-go">LBRACE</span>
<span class="tok-go">STRING(%foo\)</span>
<span class="tok-go">COLON</span>
<span class="tok-go">LBRACKET</span>
<span class="tok-go">NUMBER(-1,34000)</span>
<span class="tok-go">COMMA</span>
<span class="tok-go">STRING(Foo)</span>
<span class="tok-go">COMMA</span>
<span class="tok-go">LBRACKET</span>
<span class="tok-go">NULL</span>
<span class="tok-go">COMMA</span>
<span class="tok-go">STRING(Barא)</span>
<span class="tok-go">COMMA</span>
<span class="tok-go">STRING(𝄞)</span>
<span class="tok-go">RBRACKET</span>
<span class="tok-go">RBRACKET</span>
<span class="tok-go">RBRACE</span></code></pre>
</div>
</div>
<div class="paragraph">
<p>Our full lexer description now looks like this:</p>
</div>
<div class="listingblock">
<div class="title">JsonLexer.jl</div>
<div class="content">
<pre class="pygments highlight"><code data-lang="jl"><table class="pyhltable"><tr><td class="linenos"><div class="linenodiv"> 1
 2
 3
 4
 5
 6
 7
 8
 9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63</div></td><td class="code"><span></span><span class="tok-k">import</span> <span class="tok-nf">mypackage</span>.<span class="tok-nf">Token</span><span class="tok-p">;</span>
<span class="tok-k">import</span> <span class="tok-k">static</span> <span class="tok-nf">mypackage</span>.<span class="tok-nf">Token</span>.<span class="tok-o">*</span><span class="tok-p">;</span>

<span class="tok-g">{</span>
<span class="tok-g">  </span><span class="tok-ge">private</span><span class="tok-g"> </span><span class="tok-ge">final</span><span class="tok-g"> StringBuilder buffer = </span><span class="tok-ge">new</span><span class="tok-g"> StringBuilder();</span>
<span class="tok-g">}</span>

<span class="tok-nf">ws</span> <span class="tok-o">=</span> <span class="tok-p">[</span><span class="tok-sc">&#39;\</span><span class="tok-s">t</span><span class="tok-sc">&#39;</span> <span class="tok-sc">&#39; &#39;</span><span class="tok-p">]</span><span class="tok-o">+</span><span class="tok-p">;</span>
<span class="tok-nf">nl</span> <span class="tok-o">=</span> <span class="tok-p">(</span><span class="tok-sc">&#39;\</span><span class="tok-s">n</span><span class="tok-sc">&#39;</span> <span class="tok-o">|</span> <span class="tok-sc">&#39;\</span><span class="tok-s">r</span><span class="tok-sc">&#39;</span> <span class="tok-o">|</span> <span class="tok-s">&quot;\r\n&quot;</span><span class="tok-p">);</span>

<span class="tok-nf">digit</span> <span class="tok-o">=</span> <span class="tok-p">[</span><span class="tok-sc">&#39;0&#39;</span><span class="tok-o">-</span><span class="tok-sc">&#39;9&#39;</span><span class="tok-p">];</span>
<span class="tok-nf">nzdigit</span> <span class="tok-o">=</span> <span class="tok-nf">digit</span> <span class="tok-o">#</span> <span class="tok-sc">&#39;0&#39;</span><span class="tok-p">;</span>
<span class="tok-nf">int</span> <span class="tok-o">=</span> <span class="tok-sc">&#39;-&#39;</span><span class="tok-o">?</span> <span class="tok-p">(</span><span class="tok-sc">&#39;0&#39;</span> <span class="tok-o">|</span> <span class="tok-nf">nzdigit</span> <span class="tok-nf">digit</span><span class="tok-o">*</span><span class="tok-p">);</span>
<span class="tok-nf">frac</span> <span class="tok-o">=</span> <span class="tok-sc">&#39;.&#39;</span> <span class="tok-nf">digit</span><span class="tok-o">+</span><span class="tok-p">;</span>
<span class="tok-nf">e</span> <span class="tok-o">=</span> <span class="tok-p">(</span><span class="tok-sc">&#39;e&#39;</span> <span class="tok-o">|</span> <span class="tok-sc">&#39;E&#39;</span><span class="tok-p">)</span> <span class="tok-p">(</span><span class="tok-sc">&#39;+&#39;</span> <span class="tok-o">|</span> <span class="tok-sc">&#39;-&#39;</span><span class="tok-p">)</span><span class="tok-o">?</span><span class="tok-p">;</span>
<span class="tok-nf">exp</span> <span class="tok-o">=</span> <span class="tok-nf">e</span> <span class="tok-nf">digit</span><span class="tok-o">+</span><span class="tok-p">;</span>
<span class="tok-nf">number</span> <span class="tok-o">=</span> <span class="tok-nf">int</span> <span class="tok-nf">frac</span><span class="tok-o">?</span> <span class="tok-nf">exp</span><span class="tok-o">?</span><span class="tok-p">;</span>
<span class="tok-nf">hexDigit</span> <span class="tok-o">=</span> <span class="tok-nf">digit</span> <span class="tok-o">|</span> <span class="tok-p">[</span><span class="tok-sc">&#39;a&#39;</span><span class="tok-o">-</span><span class="tok-sc">&#39;f&#39;</span> <span class="tok-sc">&#39;A&#39;</span><span class="tok-o">-</span><span class="tok-sc">&#39;F&#39;</span><span class="tok-p">];</span>

<span class="tok-k">public</span> <span class="tok-g">{ Token }</span> <span class="tok-k">rule</span> <span class="tok-nf">main</span> <span class="tok-o">=</span>
<span class="tok-o">|</span> <span class="tok-nf">ws</span>       <span class="tok-g">{ </span><span class="tok-ge">continue</span><span class="tok-g"> main; }</span>
<span class="tok-o">|</span> <span class="tok-nf">nl</span>       <span class="tok-g">{ </span><span class="tok-ge">continue</span><span class="tok-g"> main; }</span>
<span class="tok-o">|</span> <span class="tok-sc">&#39;{&#39;</span>      <span class="tok-g">{ </span><span class="tok-ge">return</span><span class="tok-g"> LBRACE; }</span>
<span class="tok-o">|</span> <span class="tok-sc">&#39;}&#39;</span>      <span class="tok-g">{ </span><span class="tok-ge">return</span><span class="tok-g"> RBRACE; }</span>
<span class="tok-o">|</span> <span class="tok-sc">&#39;[&#39;</span>      <span class="tok-g">{ </span><span class="tok-ge">return</span><span class="tok-g"> LBRACKET; }</span>
<span class="tok-o">|</span> <span class="tok-sc">&#39;]&#39;</span>      <span class="tok-g">{ </span><span class="tok-ge">return</span><span class="tok-g"> RBRACKET; }</span>
<span class="tok-o">|</span> <span class="tok-sc">&#39;:&#39;</span>      <span class="tok-g">{ </span><span class="tok-ge">return</span><span class="tok-g"> COLON; }</span>
<span class="tok-o">|</span> <span class="tok-sc">&#39;,&#39;</span>      <span class="tok-g">{ </span><span class="tok-ge">return</span><span class="tok-g"> COMMA; }</span>
<span class="tok-o">|</span> <span class="tok-s">&quot;true&quot;</span>   <span class="tok-g">{ </span><span class="tok-ge">return</span><span class="tok-g"> TRUE; }</span>
<span class="tok-o">|</span> <span class="tok-s">&quot;false&quot;</span>  <span class="tok-g">{ </span><span class="tok-ge">return</span><span class="tok-g"> FALSE; }</span>
<span class="tok-o">|</span> <span class="tok-s">&quot;null&quot;</span>   <span class="tok-g">{ </span><span class="tok-ge">return</span><span class="tok-g"> NULL; }</span>
<span class="tok-o">|</span> <span class="tok-nf">number</span>   <span class="tok-g">{ </span><span class="tok-ge">return</span><span class="tok-g"> NUMBER(Double.parseDouble(getLexeme())); }</span>
<span class="tok-o">|</span> <span class="tok-sc">&#39;&quot;&#39;</span>      <span class="tok-g">{ buffer.setLength(0);</span>
<span class="tok-g">             String s = string(buffer);</span>
<span class="tok-g">             </span><span class="tok-ge">return</span><span class="tok-g"> STRING(s);</span>
<span class="tok-g">           }</span>
<span class="tok-o">|</span> <span class="tok-k">eof</span>      <span class="tok-g">{ </span><span class="tok-ge">return</span><span class="tok-g"> EOF; }</span>

<span class="tok-k">private</span> <span class="tok-g">{ String }</span> <span class="tok-k">rule</span> <span class="tok-nf">string</span><span class="tok-g">{StringBuilder buf}</span> <span class="tok-o">=</span>
<span class="tok-o">|</span> <span class="tok-sc">&#39;&quot;&#39;</span>      <span class="tok-g">{ </span><span class="tok-ge">return</span><span class="tok-g"> buf.toString(); }</span>
<span class="tok-o">|</span> <span class="tok-sc">&#39;\</span><span class="tok-s">\</span><span class="tok-sc">&#39;</span>     <span class="tok-g">{ </span><span class="tok-ge">char</span><span class="tok-g"> c = escapeSequence();</span>
<span class="tok-g">             buf.append(c);</span>
<span class="tok-g">             </span><span class="tok-ge">continue</span><span class="tok-g"> string;</span>
<span class="tok-g">           }</span>
<span class="tok-o">|</span> <span class="tok-p">[</span><span class="tok-o">^</span><span class="tok-sc">&#39;\</span><span class="tok-s">000</span><span class="tok-sc">&#39;</span><span class="tok-o">-</span><span class="tok-sc">&#39;\</span><span class="tok-s">037</span><span class="tok-sc">&#39;</span> <span class="tok-sc">&#39;&quot;&#39;</span> <span class="tok-sc">&#39;\</span><span class="tok-s">\</span><span class="tok-sc">&#39;</span><span class="tok-p">]</span><span class="tok-o">+</span>
           <span class="tok-g">{ buf.append(getLexeme());</span>
<span class="tok-g">             </span><span class="tok-ge">continue</span><span class="tok-g"> string;</span>
<span class="tok-g">           }</span>

<span class="tok-k">private</span> <span class="tok-g">{ </span><span class="tok-ge">char</span><span class="tok-g"> }</span> <span class="tok-k">rule</span> <span class="tok-nf">escapeSequence</span> <span class="tok-o">=</span>
<span class="tok-o">|</span> <span class="tok-sc">&#39;b&#39;</span>	 <span class="tok-g">{ </span><span class="tok-ge">return</span><span class="tok-g"> </span><span class="tok-gs">&#39;\b&#39;</span><span class="tok-g">; }</span>
<span class="tok-o">|</span> <span class="tok-sc">&#39;t&#39;</span>	 <span class="tok-g">{ </span><span class="tok-ge">return</span><span class="tok-g"> </span><span class="tok-gs">&#39;\t&#39;</span><span class="tok-g">; }</span>
<span class="tok-o">|</span> <span class="tok-sc">&#39;n&#39;</span>	 <span class="tok-g">{ </span><span class="tok-ge">return</span><span class="tok-g"> </span><span class="tok-gs">&#39;\n&#39;</span><span class="tok-g">; }</span>
<span class="tok-o">|</span> <span class="tok-sc">&#39;f&#39;</span>	 <span class="tok-g">{ </span><span class="tok-ge">return</span><span class="tok-g"> </span><span class="tok-gs">&#39;\f&#39;</span><span class="tok-g">; }</span>
<span class="tok-o">|</span> <span class="tok-sc">&#39;r&#39;</span>	 <span class="tok-g">{ </span><span class="tok-ge">return</span><span class="tok-g"> </span><span class="tok-gs">&#39;\r&#39;</span><span class="tok-g">; }</span>
<span class="tok-o">|</span> <span class="tok-sc">&#39;&quot;&#39;</span>	 <span class="tok-g">{ </span><span class="tok-ge">return</span><span class="tok-g"> </span><span class="tok-gs">&#39;&quot;&#39;</span><span class="tok-g">; }</span>
<span class="tok-o">|</span> <span class="tok-sc">&#39;\</span><span class="tok-s">&#39;</span><span class="tok-sc">&#39;</span>	 <span class="tok-g">{ </span><span class="tok-ge">return</span><span class="tok-g"> </span><span class="tok-gs">&#39;\&#39;&#39;</span><span class="tok-g">; }</span>
<span class="tok-o">|</span> <span class="tok-sc">&#39;\</span><span class="tok-s">\</span><span class="tok-sc">&#39;</span>	 <span class="tok-g">{ </span><span class="tok-ge">return</span><span class="tok-g"> </span><span class="tok-gs">&#39;\\&#39;</span><span class="tok-g">; }</span>
<span class="tok-o">|</span> <span class="tok-sc">&#39;/&#39;</span>	 <span class="tok-g">{ </span><span class="tok-ge">return</span><span class="tok-g"> </span><span class="tok-gs">&#39;/&#39;</span><span class="tok-g">; }</span>
<span class="tok-o">|</span> <span class="tok-sc">&#39;u&#39;</span> <span class="tok-p">(</span><span class="tok-nf">hexDigit</span><span class="tok-p">&lt;</span><span class="tok-m">4</span><span class="tok-p">&gt;</span> <span class="tok-k">as</span> <span class="tok-nf">code</span><span class="tok-p">)</span>
	 <span class="tok-g">{ </span><span class="tok-ge">return</span><span class="tok-g"> ((</span><span class="tok-ge">char</span><span class="tok-g">)(Integer.parseInt(code, 16))); }</span>

<span class="tok-g">{ }</span>
</td></tr></table></code></pre>
</div>
</div>
<div class="paragraph">
<p>The description is merely 63 lines long, relatively easy to read and
understand, and it can correctly analyze any correct JSON file! In the
next section of this tutorial, we will see how to improve the lexer&#8217;s
behaviour in the case where it is fed syntactically incorrect files.</p>
</div>
</div>
<div class="sect3">
<h4 id="Lexers_Error_Reports">Improving Error Reports</h4>
<div class="paragraph">
<p>So far, we have designed a working lexical analyzer for JSON files, but
we have kept ignoring the "potential problems" that are reported by
Dolmen every time we regenerate the lexer from the description:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="pygments highlight"><code data-lang="console"><span class="tok-go">java -jar Dolmen_1.0.0.jar -o mypackage -p mypackage mypackage/JsonLexer.jl</span>
<span class="tok-go">Compiling lexer description mypackage/JsonLexer.jl</span>
<span class="tok-go">├─ Lexer description successfully parsed			[94ms]</span>
<span class="tok-go">├─ Compiled lexer description to automata			[79ms]</span>
<span class="tok-go">│  (52 states in 3 automata)</span>
<span class="tok-go">│  (3 potential problems found)</span>
<span class="tok-go">├─ Generated lexer in mypackage/JsonLexer.java			[37ms]</span>
<span class="tok-go">└─ Done in 211ms</span></code></pre>
</div>
</div>
<div class="paragraph">
<p>As you can see, there are now three potential problems
reported. Unlike errors which force Dolmen to abort the generation and
are always reported on the standard output, these problems are
recorded in a special <em>reports</em> file. By default, the reports file has
the name of the lexer description with an extra <code>.reports</code> extension;
this can be controlled on the command line with the <code>-r/--reports</code>
option. Inspecting the file shows it reports three warnings:</p>
</div>
<div class="listingblock">
<div class="title">Contents of JsonLexer.jl.reports</div>
<div class="content">
<pre class="pygments highlight"><code data-lang="reports"><span class="tok-k">File</span> <span class="tok-s">&quot;mypackage/JsonLexer.jl&quot;</span><span class="tok-o">,</span> <span class="tok-k">line</span> <span class="tok-m">20</span><span class="tok-o">,</span> <span class="tok-k">characters</span> <span class="tok-m">22</span><span class="tok-o">-</span><span class="tok-m">26</span>:
<span class="tok-nl">Warning:</span> The lexer entry main cannot recognize all possible input sequences.
Here are examples of input sequences which will result in an empty token error:
 <span class="tok-o">-</span> <span class="tok-sc">&#39;t&#39;</span> <span class="tok-sc">&#39;r&#39;</span> <span class="tok-sc">&#39;u&#39;</span> <span class="tok-sc">&#39;\u0000&#39;</span>
 <span class="tok-o">-</span> <span class="tok-sc">&#39;t&#39;</span> <span class="tok-sc">&#39;r&#39;</span> <span class="tok-sc">&#39;\u0000&#39;</span>
 <span class="tok-o">-</span> <span class="tok-sc">&#39;t&#39;</span> <span class="tok-sc">&#39;\u0000&#39;</span>
 <span class="tok-o">-</span> <span class="tok-sc">&#39;n&#39;</span> <span class="tok-sc">&#39;u&#39;</span> <span class="tok-sc">&#39;l&#39;</span> <span class="tok-sc">&#39;\u0000&#39;</span>
 <span class="tok-o">-</span> <span class="tok-sc">&#39;n&#39;</span> <span class="tok-sc">&#39;u&#39;</span> <span class="tok-sc">&#39;\u0000&#39;</span>
 <span class="tok-o">-</span> <span class="tok-sc">&#39;n&#39;</span> <span class="tok-sc">&#39;\u0000&#39;</span>
 <span class="tok-o">-</span> <span class="tok-sc">&#39;f&#39;</span> <span class="tok-sc">&#39;a&#39;</span> <span class="tok-sc">&#39;l&#39;</span> <span class="tok-sc">&#39;s&#39;</span> <span class="tok-sc">&#39;\u0000&#39;</span>
 <span class="tok-o">-</span> <span class="tok-sc">&#39;f&#39;</span> <span class="tok-sc">&#39;a&#39;</span> <span class="tok-sc">&#39;l&#39;</span> <span class="tok-sc">&#39;\u0000&#39;</span>
 <span class="tok-o">-</span> <span class="tok-sc">&#39;f&#39;</span> <span class="tok-sc">&#39;a&#39;</span> <span class="tok-sc">&#39;\u0000&#39;</span>
 <span class="tok-o">-</span> <span class="tok-sc">&#39;f&#39;</span> <span class="tok-sc">&#39;\u0000&#39;</span>
 <span class="tok-o">...</span>
You may want to add <span class="tok-sc">&#39;_&#39;</span> or <span class="tok-sc">&#39;orelse&#39;</span> catch<span class="tok-o">-</span>all clauses and provide a better error report.

<span class="tok-k">File</span> <span class="tok-s">&quot;mypackage/JsonLexer.jl&quot;</span><span class="tok-o">,</span> <span class="tok-k">line</span> <span class="tok-m">39</span><span class="tok-o">,</span> <span class="tok-k">characters</span> <span class="tok-m">24</span><span class="tok-o">-</span><span class="tok-m">30</span>:
<span class="tok-nl">Warning:</span> The lexer entry string cannot recognize all possible input sequences.
Here are examples of input sequences which will result in an empty token error:
 <span class="tok-o">-</span> <span class="tok-sc">&#39;\u0000&#39;</span>
You may want to add <span class="tok-sc">&#39;_&#39;</span> or <span class="tok-sc">&#39;orelse&#39;</span> catch<span class="tok-o">-</span>all clauses and provide a better error report.

<span class="tok-k">File</span> <span class="tok-s">&quot;mypackage/JsonLexer.jl&quot;</span><span class="tok-o">,</span> <span class="tok-k">line</span> <span class="tok-m">50</span><span class="tok-o">,</span> <span class="tok-k">characters</span> <span class="tok-m">22</span><span class="tok-o">-</span><span class="tok-m">36</span>:
<span class="tok-nl">Warning:</span> The lexer entry escapeSequence cannot recognize all possible input sequences.
Here are examples of input sequences which will result in an empty token error:
 <span class="tok-o">-</span> <span class="tok-sc">&#39;u&#39;</span> <span class="tok-sc">&#39;\u0000&#39;</span>
 <span class="tok-o">-</span> <span class="tok-sc">&#39;u&#39;</span> <span class="tok-sc">&#39;0&#39;</span> <span class="tok-sc">&#39;\u0000&#39;</span>
 <span class="tok-o">-</span> <span class="tok-sc">&#39;u&#39;</span> <span class="tok-sc">&#39;0&#39;</span> <span class="tok-sc">&#39;0&#39;</span> <span class="tok-sc">&#39;\u0000&#39;</span>
 <span class="tok-o">-</span> <span class="tok-sc">&#39;u&#39;</span> <span class="tok-sc">&#39;0&#39;</span> <span class="tok-sc">&#39;0&#39;</span> <span class="tok-sc">&#39;0&#39;</span> <span class="tok-sc">&#39;\u0000&#39;</span>
 <span class="tok-o">-</span> <span class="tok-sc">&#39;\u0000&#39;</span>
You may want to add <span class="tok-sc">&#39;_&#39;</span> or <span class="tok-sc">&#39;orelse&#39;</span> catch<span class="tok-o">-</span>all clauses and provide a better error report.</code></pre>
</div>
</div>
<div class="paragraph">
<p>These warnings are three instances of the same potential issue, one
for each of our entries. The message explains that the entry <em>"cannot
recognize all possible input sequences"</em> and goes on to give a few
examples of unrecognized input strings.</p>
</div>
<div class="paragraph">
<p>This warning may come as a surprise: after all, a lexer is usually
supposed to recognize some kind of language, and therefore should
often reject at least <em>some</em> input sequences. As we have experienced
already, an <em>"Empty token"</em> lexical error is raised by the generated
lexer when an entry faces input which does not match any of the
entry&#8217;s clauses. The actual idea behind this warning is to avoid
occurrences of this lexical error, by encouraging programmers to
account for invalid or unexpected input in their lexer descriptions,
and raising exceptions with more specialized messages. Indeed, the
<em>"Empty token"</em> message is really generic and rather unhelpful in
most situations; in essence, it tells you the input cannot be
recognized but does not tell you what is wrong, or what could be
expected at this point in the stream.</p>
</div>
<div class="paragraph">
<p>Let us illustrate how our lexer can be improved can looking at the
<code>escapeSequence</code> rule:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="pygments highlight"><code data-lang="jl"><span class="tok-k">private</span> <span class="tok-g">{ </span><span class="tok-ge">char</span><span class="tok-g"> }</span> <span class="tok-k">rule</span> <span class="tok-nf">escapeSequence</span> <span class="tok-o">=</span>
<span class="tok-o">|</span> <span class="tok-sc">&#39;b&#39;</span>	 <span class="tok-g">{ </span><span class="tok-ge">return</span><span class="tok-g"> </span><span class="tok-gs">&#39;\b&#39;</span><span class="tok-g">; }</span>
<span class="tok-o">|</span> <span class="tok-sc">&#39;t&#39;</span>	 <span class="tok-g">{ </span><span class="tok-ge">return</span><span class="tok-g"> </span><span class="tok-gs">&#39;\t&#39;</span><span class="tok-g">; }</span>
<span class="tok-o">|</span> <span class="tok-sc">&#39;n&#39;</span>	 <span class="tok-g">{ </span><span class="tok-ge">return</span><span class="tok-g"> </span><span class="tok-gs">&#39;\n&#39;</span><span class="tok-g">; }</span>
<span class="tok-o">|</span> <span class="tok-sc">&#39;f&#39;</span>	 <span class="tok-g">{ </span><span class="tok-ge">return</span><span class="tok-g"> </span><span class="tok-gs">&#39;\f&#39;</span><span class="tok-g">; }</span>
<span class="tok-o">|</span> <span class="tok-sc">&#39;r&#39;</span>	 <span class="tok-g">{ </span><span class="tok-ge">return</span><span class="tok-g"> </span><span class="tok-gs">&#39;\r&#39;</span><span class="tok-g">; }</span>
<span class="tok-o">|</span> <span class="tok-sc">&#39;&quot;&#39;</span>	 <span class="tok-g">{ </span><span class="tok-ge">return</span><span class="tok-g"> </span><span class="tok-gs">&#39;&quot;&#39;</span><span class="tok-g">; }</span>
<span class="tok-o">|</span> <span class="tok-sc">&#39;\</span><span class="tok-s">&#39;</span><span class="tok-sc">&#39;</span>	 <span class="tok-g">{ </span><span class="tok-ge">return</span><span class="tok-g"> </span><span class="tok-gs">&#39;\&#39;&#39;</span><span class="tok-g">; }</span>
<span class="tok-o">|</span> <span class="tok-sc">&#39;\</span><span class="tok-s">\</span><span class="tok-sc">&#39;</span>	 <span class="tok-g">{ </span><span class="tok-ge">return</span><span class="tok-g"> </span><span class="tok-gs">&#39;\\&#39;</span><span class="tok-g">; }</span>
<span class="tok-o">|</span> <span class="tok-sc">&#39;/&#39;</span>	 <span class="tok-g">{ </span><span class="tok-ge">return</span><span class="tok-g"> </span><span class="tok-gs">&#39;/&#39;</span><span class="tok-g">; }</span>
<span class="tok-o">|</span> <span class="tok-sc">&#39;u&#39;</span> <span class="tok-p">(</span><span class="tok-nf">hexDigit</span><span class="tok-p">&lt;</span><span class="tok-m">4</span><span class="tok-p">&gt;</span> <span class="tok-k">as</span> <span class="tok-nf">code</span><span class="tok-p">)</span>
	 <span class="tok-g">{ </span><span class="tok-ge">return</span><span class="tok-g"> ((</span><span class="tok-ge">char</span><span class="tok-g">)(Integer.parseInt(code, 16))); }</span></code></pre>
</div>
</div>
<div class="paragraph">
<p>The warning report for this rule lists the following as possible input
sequences which would result in an empty token error:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="pygments highlight"><code data-lang="reports"> <span class="tok-o">-</span> <span class="tok-sc">&#39;u&#39;</span> <span class="tok-sc">&#39;\u0000&#39;</span>
 <span class="tok-o">-</span> <span class="tok-sc">&#39;u&#39;</span> <span class="tok-sc">&#39;0&#39;</span> <span class="tok-sc">&#39;\u0000&#39;</span>
 <span class="tok-o">-</span> <span class="tok-sc">&#39;u&#39;</span> <span class="tok-sc">&#39;0&#39;</span> <span class="tok-sc">&#39;0&#39;</span> <span class="tok-sc">&#39;\u0000&#39;</span>
 <span class="tok-o">-</span> <span class="tok-sc">&#39;u&#39;</span> <span class="tok-sc">&#39;0&#39;</span> <span class="tok-sc">&#39;0&#39;</span> <span class="tok-sc">&#39;0&#39;</span> <span class="tok-sc">&#39;\u0000&#39;</span>
 <span class="tok-o">-</span> <span class="tok-sc">&#39;\u0000&#39;</span></code></pre>
</div>
</div>
<div class="paragraph">
<p>Indeed, the strings <code>"u\000"</code>, <code>"u0\000"</code> and so on cannot be matched
by the <code>escapeSequence</code> rule.  This is not an exhaustive list, of
course. In fact, when Dolmen internally compiles a lexer entry into a
deterministic finite automaton, it will look for different ways to
"get stuck" in the automaton, which correspond to input which would
not be recognized. When a way of traversing the automaton and getting
stuck is found, a corresponding <em>canonical</em> example is produced, by
taking the adequate string with the smallest characters. For instance,
the sequence <code>"u0\000"</code> stems for all input strings which start with a
<code>u</code>, followed by some hexadecimal digit (of which <code>0</code> is the
smallest), and then by any character other than a hexadecimal digit
(of which the null character <code>\000</code> is the smallest). Similarly, the
null character in the sequence <code>"\000"</code> is the smallest possible
character which <em>cannot</em> start a valid escape sequence. This is why
the null character frequently appears in these report messages.</p>
</div>
<div class="paragraph">
<p>In essence, these examples of problematic input sequences remind us
that our <code>escapeSequence</code> rule will fail to match:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>Unicode escape sequences which do not contain four
hexadecimal digits;</p>
</li>
<li>
<p>input which starts with a character that is neither <code>u</code>, nor
any of the valid escape characters (<code>b</code>, <code>t</code>, <code>n</code>&#8230;&#8203;).</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>Both instances reveal distinct syntactic problems and call for
separate specific error messages. To that end, let us add two
extra clauses to our entry:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="pygments highlight"><code data-lang="jl"><span class="tok-k">private</span> <span class="tok-g">{ </span><span class="tok-ge">char</span><span class="tok-g"> }</span> <span class="tok-k">rule</span> <span class="tok-nf">escapeSequence</span> <span class="tok-o">=</span>
...
<span class="tok-o">|</span> <span class="tok-sc">&#39;u&#39;</span>    <span class="tok-g">{ </span><span class="tok-ge">throw</span><span class="tok-g"> error(</span><span class="tok-gs">&quot;Invalid Unicode escape sequence: \\uxxxx expected&quot;</span><span class="tok-g">); }</span>
<span class="tok-o">|</span> <span class="tok-nf">_</span> <span class="tok-k">as</span> <span class="tok-nf">c</span> <span class="tok-g">{ </span><span class="tok-ge">throw</span><span class="tok-g"> error(</span><span class="tok-gs">&quot;Invalid escape character: &quot;</span><span class="tok-g"> + c + </span><span class="tok-gs">&quot;. Valid ones are &quot;</span><span class="tok-g"> +</span>
<span class="tok-g">           </span><span class="tok-gs">&quot;\\\\, \\/,  \\\&#39;, \\\&quot;, \\n, \\t, \\b, \\f, \\r.&quot;</span><span class="tok-g">);</span>
<span class="tok-g">         }</span></code></pre>
</div>
</div>
<div class="paragraph">
<p>The first clause handles any invalid Unicode escaping sequence by
matching a single <code>u</code> character&#8212;&#8203;recall that by the longest-match
disambiguation rule, this clause will not be used if <code>u</code> happens to be
followed by four hexadecimal digits. The second clause uses the
special <em>wildcard</em> regular expression <code>_</code>, which matches any single
character, to handle the case of all invalid escape characters. The
<a href="./javadoc/org/stekikun/dolmen/codegen/LexBuffer.html#error-java.lang.String-"><code>error()</code></a> method used in
the semantic actions here is a method exported
by Dolmen&#8217;s base class for lexical analyzers and which simply
returns a <code>LexicalError</code> exception with the given message and associated
to the current lexer location. You can learn more about semantic actions
<a href="#Lexers_Semantic_Actions_Ref">here</a>.</p>
</div>
<div class="admonitionblock warning">
<table>
<tr>
<td class="icon">
<i class="fa icon-warning" title="Warning"></i>
</td>
<td class="content">
<div class="paragraph">
<p>Note that this second clause <strong>must</strong> appear after the other clauses: it
matches exactly <em>one</em> character of the input stream, but so does the
other clause for &#8217;u'`and also the other clauses handling the various
valid escape characters. When the input matches more than one clause
and the longest-match rule does not apply, the clause appearing <strong>first</strong>
will be applied. In this case, we want to make sure the wildcard clause
is only used as a fall-back for invalid sequences, so we insert it last.</p>
</div>
<div class="paragraph">
<p>If we had put the two extra clauses above the other way around, Dolmen
would actually warn you that the <code>'u'</code> clause was being hidden by
another one, i.e. there would be one warning along these lines in the
report file:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="pygments highlight"><code data-lang="reports"><span class="tok-k">File</span> <span class="tok-s">&quot;mypackage/JsonLexer.jl&quot;</span><span class="tok-o">,</span> <span class="tok-k">line</span> <span class="tok-m">68</span><span class="tok-o">,</span> <span class="tok-k">characters</span> <span class="tok-m">1</span><span class="tok-o">-</span><span class="tok-m">5</span>:
<span class="tok-nl">Warning:</span> This clause is never used (entry escapeSequence<span class="tok-o">,</span> clause #<span class="tok-m">11</span>).</code></pre>
</div>
</div>
</td>
</tr>
</table>
</div>
<div class="paragraph">
<p>Now, if we recompile our lexer and look at the reports, we are
disappointed to see that there still is a warning about
<code>escapeSequence</code> being incomplete, albeit this time only a single
input example is reported in the diagnostic:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="pygments highlight"><code data-lang="reports"><span class="tok-k">File</span> <span class="tok-s">&quot;mypackage/JsonLexer.jl&quot;</span><span class="tok-o">,</span> <span class="tok-k">line</span> <span class="tok-m">50</span><span class="tok-o">,</span> <span class="tok-k">characters</span> <span class="tok-m">22</span><span class="tok-o">-</span><span class="tok-m">36</span>:
<span class="tok-nl">Warning:</span> The lexer entry escapeSequence cannot recognize all possible input sequences.
Here are examples of input sequences which will result in an empty token error:
 <span class="tok-o">-</span> <span class="tok-sc">&#39;EOF&#39;</span>
You may want to add <span class="tok-sc">&#39;_&#39;</span> or <span class="tok-sc">&#39;orelse&#39;</span> catch<span class="tok-o">-</span>all clauses and provide a better error report.</code></pre>
</div>
</div>
<div class="paragraph">
<p>The problematic input sequence is simply <code>EOF</code>, which is Dolmen&#8217;s way
of writing the special "end-of-input" character (not to be confused
with <code>eof</code>, which is the Dolmen keyword for the <em>regular expression</em>
that exactly matches this special character). Indeed, for reasons
which are detailed in a <a href="#Lexers_Wildcards">section dedicated to
wildcards</a> in this manual, the <code>_</code> regular expression in a clause
will match any character <strong>except</strong> <code>EOF</code>. Similarly, the character-set
complement construct <code>[^&#8230;&#8203;]</code> will not match <code>EOF</code> either (which means
that <code>_</code> and <code>[^]</code> are completely equivalent). In short, this stems
from the fact that the special end-of-input character behaves
differently from regular characters in regular expressions, and
usually calls for different error diagnostics in a lexical analyzer
anyways.  In our case, we can fix our <code>escapeSequence</code> rule for good
by adding yet another clause, this time simply dealing with the case
when the input ends right at the beginning of the escape sequence:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="pygments highlight"><code data-lang="jl"><span class="tok-k">private</span> <span class="tok-g">{ </span><span class="tok-ge">char</span><span class="tok-g"> }</span> <span class="tok-k">rule</span> <span class="tok-nf">escapeSequence</span> <span class="tok-o">=</span>
...
<span class="tok-o">|</span> <span class="tok-sc">&#39;u&#39;</span>    <span class="tok-g">{ </span><span class="tok-ge">throw</span><span class="tok-g"> error(</span><span class="tok-gs">&quot;Invalid Unicode escape sequence: \\uxxxx expected&quot;</span><span class="tok-g">); }</span>
<span class="tok-o">|</span> <span class="tok-nf">_</span> <span class="tok-k">as</span> <span class="tok-nf">c</span> <span class="tok-g">{ </span><span class="tok-ge">throw</span><span class="tok-g"> error(</span><span class="tok-gs">&quot;Invalid escape character: &quot;</span><span class="tok-g"> + c + </span><span class="tok-gs">&quot;. Valid ones are &quot;</span><span class="tok-g"> +</span>
<span class="tok-g">           </span><span class="tok-gs">&quot;\\\\, \\/,  \\\&#39;, \\\&quot;, \\n, \\t, \\b, \\f, \\r.&quot;</span><span class="tok-g">);</span>
<span class="tok-g">         }</span>
<span class="tok-o">|</span> <span class="tok-k">eof</span>    <span class="tok-g">{ </span><span class="tok-ge">throw</span><span class="tok-g"> error(</span><span class="tok-gs">&quot;Unterminated escape sequence&quot;</span><span class="tok-g">); }</span></code></pre>
</div>
</div>
<div class="paragraph">
<p>With these three fall-back clauses, our rule is finally warning-free,
and we can test their effect by trying to tokenize a few various
invalid sentences:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="pygments highlight"><code data-lang="doscon"><span class="tok-go">java -classpath bin:Dolmen_1.0.0.jar mypackage.Tokenizer</span>
<span class="tok-gp">&gt;</span> <span class="tok-s2">&quot;Some good escape:\nlike this&quot;</span> <span class="tok-s2">&quot;And not so \good escape&quot;</span>
<span class="tok-go">STRING(Some good escape:</span>
<span class="tok-go">like this)</span>
<span class="tok-go">org.stekikun.dolmen.codegen.LexBuffer$LexicalError: Invalid escape character: g. Valid ones are \\, \/,  \&#39;, \&quot;, \n, \t, \b, \f, \r. (stdin, at line 1, column 45)</span>
<span class="tok-go">	at org.stekikun.dolmen.codegen.LexBuffer.error(LexBuffer.java:651)</span>
<span class="tok-go">	at mypackage.JsonLexer.escapeSequence(JsonLexer.java:163)</span>
<span class="tok-go">        ...</span>
<span class="tok-gp">&gt;</span> <span class="tok-s2">&quot;Nice Unicode\u0020sequence&quot;</span> <span class="tok-s2">&quot;and a bad \u3 one&quot;</span>
<span class="tok-go">STRING(Nice Unicode sequence)</span>
<span class="tok-go">org.stekikun.dolmen.codegen.LexBuffer$LexicalError: Invalid Unicode escape sequence: \uxxxx expected (stdin, at line 1, column 42)</span>
<span class="tok-go">	at org.stekikun.dolmen.codegen.LexBuffer.error(LexBuffer.java:651)</span>
<span class="tok-go">	at mypackage.JsonLexer.escapeSequence(JsonLexer.java:159)</span>
<span class="tok-go">        ...</span>
<span class="tok-gp">&gt;</span> <span class="tok-s2">&quot;Aborted escape sequence\</span>
org.stekikun.dolmen.codegen.LexBuffer$LexicalError: Unterminated escape sequence (stdin, at line 1, column 26)
<span class="tok-go">	at org.stekikun.dolmen.codegen.LexBuffer.error(LexBuffer.java:651)</span>
<span class="tok-go">	at mypackage.JsonLexer.escapeSequence(JsonLexer.java:168)</span>
<span class="tok-go">        ...</span></code></pre>
</div>
</div>
<div class="paragraph">
<p>We can fix the similar warnings pertaining to the <code>main</code> and <code>string</code>
entries in a similar fashion, by adding clauses to deal with unhandled
characters:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="pygments highlight"><code data-lang="jl"><span class="tok-k">public</span> <span class="tok-g">{ Token }</span> <span class="tok-k">rule</span> <span class="tok-nf">main</span> <span class="tok-o">=</span>
...
<span class="tok-o">|</span> <span class="tok-nf">_</span> <span class="tok-k">as</span> <span class="tok-nf">c</span>   <span class="tok-g">{ </span><span class="tok-ge">throw</span><span class="tok-g"> error(</span><span class="tok-gs">&quot;Unexpected character: &quot;</span><span class="tok-g"> + c); }</span>
<span class="tok-o">|</span> <span class="tok-k">eof</span>      <span class="tok-g">{ </span><span class="tok-ge">return</span><span class="tok-g"> EOF; }</span>

<span class="tok-k">private</span> <span class="tok-g">{ String }</span> <span class="tok-k">rule</span> <span class="tok-nf">string</span> <span class="tok-o">=</span>
...
<span class="tok-o">|</span> <span class="tok-nf">_</span> <span class="tok-k">as</span> <span class="tok-nf">c</span>   <span class="tok-g">{ </span><span class="tok-ge">throw</span><span class="tok-g"> error(</span>
<span class="tok-g">               String.format(</span><span class="tok-gs">&quot;Forbidden character in string U+%04x&quot;</span><span class="tok-g">, (</span><span class="tok-ge">short</span><span class="tok-g">)c)); </span><i class="conum" data-value="1"></i><b>(1)</b>
<span class="tok-g">           }</span>
<span class="tok-o">|</span> <span class="tok-k">eof</span>      <span class="tok-g">{ </span><span class="tok-ge">throw</span><span class="tok-g"> error(</span><span class="tok-gs">&quot;Unterminated string literal&quot;</span><span class="tok-g">); }</span></code></pre>
</div>
</div>
<div class="colist arabic">
<table>
<tr>
<td><i class="conum" data-value="1"></i><b>1</b></td>
<td>In the <code>string</code> entry, we know invalid characters are all control
characters which are usually non-printable, and therefore we
display them using their Unicode standard notation.</td>
</tr>
</table>
</div>
<div class="paragraph">
<p>The lexer description now compiles without any warnings! Altogether,
we added six simple clauses, around 10 lines of code, and we
statically made sure the generated lexical analyzer will never throw a
generic empty token error, always using our custom messages.</p>
</div>
<div class="exampleblock">
<div class="title">The Art of Error Handling</div>
<div class="content">
<div class="paragraph">
<p>We have improved error reporting in our lexical analyzer by making the
rules explicitly deal with invalid input and customize error messages,
but we did not go overboard doing so. Here are a few ways to further
enhance error reporting:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>in <code>escapeSequence</code>, we could have made a special case for <code>Uxxxx</code>
to suggest the user should use lowercase <code>u</code> instead;</p>
</li>
<li>
<p>similarly, in <code>main</code> we could have parsed identifiers made of
letters and suggested either one of the actual JSON keywords
(<code>true</code>, <code>false</code> or <code>null</code>) based for instance on which one was the
closest for the
<a href="https://en.wikipedia.org/wiki/Levenshtein_distance">Levenshtein
distance</a>, or to suggest to enclose the identifier into double-quote
delimiters (as it is a common mistake to omit the delimiters in JSON
object keys, and many JSON parsers actually accept such invalid
input).</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>There is a compromise to be made between the amount of code and
maintenance that can be devoted to error handling on one side,
and the actual core functionality of the lexer on the other side.
In some contexts, it is
certainly desirable to put a lot of effort into instrumenting the
lexer in that fashion. In other contexts, such as when writing an
analyzer which will for instance be part of a validation tool, that is
often run in batch as part of continuous integration, or as part of
back-ends which must have a high throughput and do not interact with
users directly, then it is perfectly desirable to have the simplest
possible lexer description, with only the core functionality in place.</p>
</div>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_debugging_locations">Debugging locations</h4>
<div class="paragraph">
<p>Reporting nice helpful messages when encountering ill-formed input is
very valuable, but reporting them <em>at the correct place</em> is equally
important! The various lexical errors we encountered in our earlier
tests were always <em>located</em> at some position in the input, displayed
in terms of a line and a column number:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="pygments highlight"><code data-lang="doscon"><span class="tok-go">org.stekikun.dolmen.codegen.LexBuffer$LexicalError: Invalid Unicode escape sequence: \uxxxx expected (stdin, at line 1, column 42)</span>
<span class="tok-go">	at org.stekikun.dolmen.codegen.LexBuffer.error(LexBuffer.java:651)</span>
<span class="tok-go">        ...</span></code></pre>
</div>
</div>
<div class="paragraph">
<p>This is true for both the generic token errors raised by
Dolmen-generated code and the custom lexical errors we raise ourselves
in the semantic actions. Yet, for the latter, we never bothered to
explicitly specify an input location when throwing the exception; in
fact, the <a href="./javadoc/org/stekikun/dolmen/codegen/LexBuffer.html#error-java.lang.String-"><code>error()</code></a> library function
inherited from <a href="./javadoc/org/stekikun/dolmen/codegen/LexBuffer.html"><code>LexBuffer</code></a> that
we used to build the lexical exception did choose a position
automatically. To make sure these positions are relevant, one needs to
get a good grasp of the principles behind them. Not only are positions
used to report lexical errors, they are also typically used in parsers
built on top of the lexers, to report syntactic errors, decorate
parsed abstract syntax trees with source locations, etc. It is quite
hard to debug these mechanisms thoroughly and make sure they always
use correct locations, and errors later reported at invalid or random
locations in a compiler back-end can cause quite a few headaches.
Fortunately, we will see how Dolmen can help assist in achieving and
maintaining relevant locations throughout the lexical analysis.</p>
</div>
<div class="paragraph">
<p>For a start, it is about time we confront our lexical analyzer to a
fully fledged JSON file instead of one-line sentences. We could adapt
our <code>Tokenizer</code> class to read from a file and display all tokens, but
this time we are interested in displaying the input locations
associated to the tokens as well. The two methods
<a href="./javadoc/org/stekikun/dolmen/codegen/LexBuffer.html#getLexemeStart"><code>getLexemeStart()</code></a> and
<a href="./javadoc/org/stekikun/dolmen/codegen/LexBuffer.html#getLexemeEnd"><code>getLexemeEnd()</code></a> inherited from the base
<a href="./javadoc/org/stekikun/dolmen/codegen/LexBuffer.html"><code>LexBuffer</code></a> class can be used in semantic actions to
retrieve the positions of the part of the input which matched the
current clause: <code>getLexemeStart()</code> will return the position of the
first character of the match, while <code>getLexemeEnd()</code> will return the
position of the first character which <em>follows</em> the match.
The <a href="./javadoc/org/stekikun/dolmen/codegen/LexBuffer.Position.html">positions</a> themselves
consist of the following information:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>the <em>name</em> of the input where the position is to be interpreted,
it stems from the name given when creating the lexer instance;</p>
</li>
<li>
<p>the absolute <em>offset</em> of the position, in characters from the
start of the input;</p>
</li>
<li>
<p>the <em>line number</em> where the position occurs in the input;</p>
</li>
<li>
<p>the absolute offset of the start of that line in the input,
from which, together with the offset of the position, the
<em>column</em> number of the position can be retrieved.</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>Part of the position information, namely the name and absolute offset,
are managed automatically by the generated lexer, whereas the other
part is the responsibility of the developer writing the lexer
description. The
<a href="./javadoc/org/stekikun/dolmen/debug/package-summary.html">org.stekikun.dolmen.debug</a>
package contains utilities to help one debug lexical analyzers; using
the <code>Tokenizer</code> class from this package, it is very easy to tokenize an
input file as follows:</p>
</div>
<div class="listingblock">
<div class="title">mypackage/TokenizerLocs.java</div>
<div class="content">
<pre class="pygments highlight"><code data-lang="java"><span class="tok-kn">package</span> <span class="tok-nn">mypackage</span><span class="tok-o">;</span>

<span class="tok-kn">import</span> <span class="tok-nn">java.io.File</span><span class="tok-o">;</span>
<span class="tok-kn">import</span> <span class="tok-nn">java.io.IOException</span><span class="tok-o">;</span>
<span class="tok-kn">import</span> <span class="tok-nn">org.stekikun.dolmen.codegen.LexBuffer</span><span class="tok-o">;</span>
<span class="tok-kn">import</span> <span class="tok-nn">org.stekikun.dolmen.debug.Tokenizer</span><span class="tok-o">;</span>
<span class="tok-kn">import</span> <span class="tok-nn">mypackage.Token</span><span class="tok-o">;</span>
<span class="tok-kn">import</span> <span class="tok-nn">mypackage.JsonLexer</span><span class="tok-o">;</span>

<span class="tok-kd">public</span> <span class="tok-kd">class</span> <span class="tok-nc">TokenizerLocs</span> <span class="tok-o">{</span>
    <span class="tok-kd">public</span> <span class="tok-kd">static</span> <span class="tok-kt">void</span> <span class="tok-nf">main</span><span class="tok-o">(</span><span class="tok-n">String</span> <span class="tok-n">args</span><span class="tok-o">[])</span> <span class="tok-kd">throws</span> <span class="tok-n">IOException</span> <span class="tok-o">{</span>
        <span class="tok-n">String</span> <span class="tok-n">input</span> <span class="tok-o">=</span> <span class="tok-n">args</span><span class="tok-o">[</span><span class="tok-mi">0</span><span class="tok-o">];</span>
        <span class="tok-n">String</span> <span class="tok-n">output</span> <span class="tok-o">=</span> <span class="tok-n">args</span><span class="tok-o">[</span><span class="tok-mi">0</span><span class="tok-o">]</span> <span class="tok-o">+</span> <span class="tok-s">&quot;.tokens&quot;</span><span class="tok-o">;</span>
        <span class="tok-n">Tokenizer</span><span class="tok-o">.</span><span class="tok-na">file</span><span class="tok-o">(</span>
            <span class="tok-n">Tokenizer</span><span class="tok-o">.</span><span class="tok-na">LexerInterface</span><span class="tok-o">.</span><span class="tok-na">of</span><span class="tok-o">(</span><span class="tok-n">JsonLexer</span><span class="tok-o">::</span><span class="tok-k">new</span><span class="tok-o">,</span><i class="conum" data-value="1"></i><b>(1)</b>
                                        <span class="tok-n">JsonLexer</span><span class="tok-o">::</span><span class="tok-n">main</span><span class="tok-o">,</span><i class="conum" data-value="2"></i><b>(2)</b>
                                        <span class="tok-n">Token</span><span class="tok-o">.</span><span class="tok-na">EOF</span><span class="tok-o">),</span><i class="conum" data-value="3"></i><b>(3)</b>
            <span class="tok-k">new</span> <span class="tok-n">File</span><span class="tok-o">(</span><span class="tok-n">input</span><span class="tok-o">),</span> <span class="tok-k">new</span> <span class="tok-n">File</span><span class="tok-o">(</span><span class="tok-n">output</span><span class="tok-o">),</span><i class="conum" data-value="4"></i><b>(4)</b>
            <span class="tok-kc">true</span><span class="tok-o">);</span><i class="conum" data-value="5"></i><b>(5)</b>
    <span class="tok-o">}</span>
<span class="tok-o">}</span></code></pre>
</div>
</div>
<div class="colist arabic">
<table>
<tr>
<td><i class="conum" data-value="1"></i><b>1</b></td>
<td>A way to construct a lexical analyzer</td>
</tr>
<tr>
<td><i class="conum" data-value="2"></i><b>2</b></td>
<td>The lexer&#8217;s entry point to use during the tokenization</td>
</tr>
<tr>
<td><i class="conum" data-value="3"></i><b>3</b></td>
<td>The token at which tokenization should stop</td>
</tr>
<tr>
<td><i class="conum" data-value="4"></i><b>4</b></td>
<td>The input and output files to use</td>
</tr>
<tr>
<td><i class="conum" data-value="5"></i><b>5</b></td>
<td>Whether token locations should be output</td>
</tr>
</table>
</div>
<div class="paragraph">
<p>The
<a href="./javadoc/org/stekikun/dolmen/debug/Tokenizer.html#file-org.stekikun.dolmen.debug.Tokenizer.LexerInterface-java.io.File-java.io.File-boolean-">Tokenizer.file</a>
method used in this example requires an interface describing what
lexical analyzer to use, and how to use it, and will tokenize any
given input file, printing the results to the specified output
file. Suppose we have a simple JSON file, adequately called
<code>simple.json</code>, in a <code>resources</code> folder of our working directory:</p>
</div>
<div class="listingblock">
<div class="content">
<pre>./
 ├─ Dolmen_1.0.0.jar
 ├─ bin/
 │   └─ ...
 ├─ resources/
 │   └─ simple.json
 └─ mypackage/
     └─ ...</pre>
</div>
</div>
<div class="listingblock">
<div class="title">simple.json</div>
<div class="content">
<pre class="pygments highlight"><code data-lang="javascript"><span class="tok-p">{</span> <span class="tok-s2">&quot;persons&quot;</span><span class="tok-o">:</span> <span class="tok-p">[</span><span class="tok-s2">&quot;Joe&quot;</span><span class="tok-p">,</span> <span class="tok-s2">&quot;Bob&quot;</span><span class="tok-p">,</span> <span class="tok-kc">null</span><span class="tok-p">],</span>
  <span class="tok-s2">&quot;open&quot;</span><span class="tok-o">:</span> <span class="tok-kc">true</span><span class="tok-p">,</span>
  <span class="tok-s2">&quot;loc&quot;</span><span class="tok-o">:</span> <span class="tok-p">[</span><span class="tok-o">-</span><span class="tok-mf">12.45</span><span class="tok-p">,</span> <span class="tok-mf">3.40e1</span><span class="tok-p">],</span>
  <span class="tok-s2">&quot;text&quot;</span><span class="tok-o">:</span> <span class="tok-s2">&quot;sdfk\&quot;j&quot;</span>
<span class="tok-p">}</span></code></pre>
</div>
</div>
<div class="paragraph">
<p>Calling this tokenizer on <code>simple.son</code> will produce the following
results:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="pygments highlight"><code data-lang="console"><span class="tok-gp">$</span> java -classpath bin:Dolmen_1.0.0.jar mypackage.TokenizerLocs resources/simple.json
<span class="tok-gp">$</span> cat resources/simple.json.tokens
<span class="tok-go">LBRACE                 (simple.json[1,0+0]..simple.json[1,0+1])</span>
<span class="tok-go">STRING(persons)        (simple.json[1,0+10]..simple.json[1,0+11])</span>
<span class="tok-go">COLON                  (simple.json[1,0+11]..simple.json[1,0+12])</span>
<span class="tok-go">LBRACKET               (simple.json[1,0+13]..simple.json[1,0+14])</span>
<span class="tok-go">STRING(Joe)            (simple.json[1,0+18]..simple.json[1,0+19])</span>
<span class="tok-go">COMMA                  (simple.json[1,0+19]..simple.json[1,0+20])</span>
<span class="tok-go">STRING(Bob)            (simple.json[1,0+25]..simple.json[1,0+26])</span>
<span class="tok-go">COMMA                  (simple.json[1,0+26]..simple.json[1,0+27])</span>
<span class="tok-go">NULL                   (simple.json[1,0+28]..simple.json[1,0+32])</span>
<span class="tok-go">RBRACKET               (simple.json[1,0+32]..simple.json[1,0+33])</span>
<span class="tok-go">COMMA                  (simple.json[1,0+33]..simple.json[1,0+34])</span>
<span class="tok-go">STRING(open)           (simple.json[1,0+42]..simple.json[1,0+43])</span>
<span class="tok-go">COLON                  (simple.json[1,0+43]..simple.json[1,0+44])</span>
<span class="tok-go">...</span>
<span class="tok-go">RBRACE                 (simple.json[1,0+98]..simple.json[1,0+99])</span></code></pre>
</div>
</div>
<div class="paragraph">
<p>Each token is followed by its <code><em>(start..end)</em></code> locations, where each
position is given in the format <code><em>name[l,b+c]</em></code> where <code>name</code> is the
name of the input, <code>l</code> the line number, <code>b</code> the absolute offset of the
beginning of that line, and <code>c</code> the 0-based column number of the
position in that line. It is immediately clear that <code>JsonLexer</code> does
not update line numbers correctly since every token is supposedly at
line 1, whereas the column offsets keep growing. For instance, the
last closing curly brace is showed as being on the 99-th column of the
first line, wheras it is actually the first character of the 5-th
line; that being said, it is indeed the 99-th character of <em>the whole
file</em>, which shows the absolute position for this token was actually
right.</p>
</div>
<div class="paragraph">
<p>The issue here is that lexers generated by Dolmen keep track of a
current line number, but <strong>do not update it automatically</strong>. In order to
fix our locations, we must thus tell the underlying lexing buffer when
a new line starts. This is typically done from a semantic action by
calling the helper method <a href="./javadoc/org/stekikun/dolmen/codegen/LexBuffer.html#newline--"><code>newline()</code></a>,
available from the base <code>LexBuffer</code> class. Calling <code>newline()</code> will
simply increment the current line count, and tell the engine that a
new line starts at the <em>end</em> of the current match. This is the reason
why, earlier in this tutorial, we took care of writing two separate
clauses for regular whitespace and for linebreaks, making sure we
matched linebreaks separately, and <em>one at a time</em>:</p>
</div>
<div class="listingblock">
<div class="title">JsonLexer.jl</div>
<div class="content">
<pre class="pygments highlight"><code data-lang="jl"><span class="tok-k">public</span> <span class="tok-g">{ Token }</span> <span class="tok-k">rule</span> <span class="tok-nf">main</span> <span class="tok-o">=</span>
<span class="tok-o">|</span> <span class="tok-nf">ws</span>   <span class="tok-g">{ </span><span class="tok-ge">continue</span><span class="tok-g"> main; }</span>
<span class="tok-o">|</span> <span class="tok-nf">nl</span>   <span class="tok-g">{ </span><span class="tok-ge">continue</span><span class="tok-g"> main; }</span>
...</code></pre>
</div>
</div>
<div class="paragraph">
<p>It is easy now to fix the semantic action for our linebreak clause,
by calling <code>newline()</code> before continuing with the main rule:</p>
</div>
<div class="listingblock">
<div class="title">JsonLexer.jl</div>
<div class="content">
<pre class="pygments highlight"><code data-lang="jl"><span class="tok-k">public</span> <span class="tok-g">{ Token }</span> <span class="tok-k">rule</span> <span class="tok-nf">main</span> <span class="tok-o">=</span>
<span class="tok-o">|</span> <span class="tok-nf">ws</span>   <span class="tok-g">{ </span><span class="tok-ge">continue</span><span class="tok-g"> main; }</span>
<span class="tok-o">|</span> <span class="tok-nf">nl</span>   <span class="tok-g">{ newline(); </span><span class="tok-ge">continue</span><span class="tok-g"> main; }</span>
...</code></pre>
</div>
</div>
<div class="paragraph">
<p>There is no other clause in <code>JsonLexer.jl</code> which successfully matches
a line break, but if JSON allowed multi-line string literals for
instance, we would need a similar clause with a call to <code>newline()</code> in
the <code>string</code> entry. After this fix, the locations of our tokens look
better:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="pygments highlight"><code data-lang="console"><span class="tok-gp">$</span> java -classpath bin:Dolmen_1.0.0.jar mypackage.TokenizerLocs resources/simple.json
<span class="tok-gp">$</span> cat resources/simple.json.tokens
<span class="tok-go">LBRACE                 (simple.json[1,0+0]..simple.json[1,0+1])</span>
<span class="tok-go">STRING(persons)        (simple.json[1,0+10]..simple.json[1,0+11])</span>
<span class="tok-go">COLON                  (simple.json[1,0+11]..simple.json[1,0+12])</span>
<span class="tok-go">LBRACKET               (simple.json[1,0+13]..simple.json[1,0+14])</span>
<span class="tok-go">STRING(Joe)            (simple.json[1,0+18]..simple.json[1,0+19])</span>
<span class="tok-go">COMMA                  (simple.json[1,0+19]..simple.json[1,0+20])</span>
<span class="tok-go">STRING(Bob)            (simple.json[1,0+25]..simple.json[1,0+26])</span>
<span class="tok-go">COMMA                  (simple.json[1,0+26]..simple.json[1,0+27])</span>
<span class="tok-go">NULL                   (simple.json[1,0+28]..simple.json[1,0+32])</span>
<span class="tok-go">RBRACKET               (simple.json[1,0+32]..simple.json[1,0+33])</span>
<span class="tok-go">COMMA                  (simple.json[1,0+33]..simple.json[1,0+34])</span>
<span class="tok-go">STRING(open)           (simple.json[2,35+7]..simple.json[2,35+8])</span>
<span class="tok-go">COLON                  (simple.json[2,35+8]..simple.json[2,35+9])</span>
<span class="tok-go">...</span>
<span class="tok-go">RBRACE                 (simple.json[5,98+0]..simple.json[5,98+1])</span></code></pre>
</div>
</div>
<div class="admonitionblock tip">
<table>
<tr>
<td class="icon">
<i class="fa icon-tip" title="Tip"></i>
</td>
<td class="content">
<div class="paragraph">
<p>One may wonder why calling <code>newline()</code> from the semantic action
manually is required at all and why the generated lexers do not simply
detect linebreaks automatically in the first place. This is a design
choice motivated in particular by the following points:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>the lexical analyzers deal with character streams, and line and
column numbers raise completely separate presentation-specific
issues; in particular, linebreak sequences depend on computer
systems, conventions, editors, as does the width of tabulation
characters;</p>
</li>
<li>
<p>even if linebreaks were configurable in Dolmen, any robust way to
keep track of linebreaks automatically during the lexical analysis
would likely be less efficient than relying on the semantic actions,
in particular because of the way the input matching process uses
<em>backtracking</em>;</p>
</li>
<li>
<p>last but not least, control over line numbers and column positions
must anyway be left to developers in semantic actions to allow
lexical analyzers to implement special directives which modify
locations arbitrarily, such as GCC&#8217;s
<a href="https://gcc.gnu.org/onlinedocs/gcc-7.5.0/cpp/Line-Control.html"><code>#line</code>
directive</a>.</p>
</li>
</ul>
</div>
</td>
</tr>
</table>
</div>
<div class="paragraph">
<p>Looking closer at the locations returned for <code>simple.json</code>, it seems
that even though the line numbers now seem accurate, the actual
positions for some of the tokens look very suspicious; for instance,
the token <code>STRING(open)</code> for the <code>"open"</code> literal on line 2 only spans
<em>one</em> character according to the locations. We could look up the
actual positions in detail manually, but Dolmen&#8217;s
<a href="./javadoc/org/stekikun/dolmen/debug/TokenVisualizer.html"><code>TokenVisualizer</code></a> class offers a
more convenient way to check the token&#8217;s positions against the actual
input. Its usage is very similar to <code>Tokenizer</code> but instead of simply
displaying the tokens' information, it will generate a standalone HTML
page showing the tokens superimposed onto the original input:</p>
</div>
<div class="listingblock">
<div class="title">mypackage/Visualizer.java</div>
<div class="content">
<pre class="pygments highlight"><code data-lang="java"><span class="tok-kn">package</span> <span class="tok-nn">mypackage</span><span class="tok-o">;</span>

<span class="tok-kn">import</span> <span class="tok-nn">java.io.File</span><span class="tok-o">;</span>
<span class="tok-kn">import</span> <span class="tok-nn">java.io.IOException</span><span class="tok-o">;</span>
<span class="tok-kn">import</span> <span class="tok-nn">org.stekikun.dolmen.codegen.LexBuffer</span><span class="tok-o">;</span>
<span class="tok-kn">import</span> <span class="tok-nn">org.stekikun.dolmen.debug.TokenVisualizer</span><span class="tok-o">;</span>
<span class="tok-kn">import</span> <span class="tok-nn">mypackage.Token</span><span class="tok-o">;</span>
<span class="tok-kn">import</span> <span class="tok-nn">mypackage.JsonLexer</span><span class="tok-o">;</span>

<span class="tok-kd">public</span> <span class="tok-kd">class</span> <span class="tok-nc">Visualizer</span> <span class="tok-o">{</span>
    <span class="tok-kd">public</span> <span class="tok-kd">static</span> <span class="tok-kt">void</span> <span class="tok-nf">main</span><span class="tok-o">(</span><span class="tok-n">String</span> <span class="tok-n">args</span><span class="tok-o">[])</span> <span class="tok-kd">throws</span> <span class="tok-n">IOException</span> <span class="tok-o">{</span>
        <span class="tok-n">String</span> <span class="tok-n">input</span> <span class="tok-o">=</span> <span class="tok-n">args</span><span class="tok-o">[</span><span class="tok-mi">0</span><span class="tok-o">];</span>
        <span class="tok-n">String</span> <span class="tok-n">output</span> <span class="tok-o">=</span> <span class="tok-n">args</span><span class="tok-o">[</span><span class="tok-mi">0</span><span class="tok-o">]</span> <span class="tok-o">+</span> <span class="tok-s">&quot;.html&quot;</span><span class="tok-o">;</span>
        <span class="tok-n">TokenVisualizer</span><span class="tok-o">.</span><span class="tok-na">file</span><span class="tok-o">(</span>
            <span class="tok-n">TokenVisualizer</span><span class="tok-o">.</span><span class="tok-na">LexerInterface</span><span class="tok-o">.</span><span class="tok-na">of</span><span class="tok-o">(</span><span class="tok-n">JsonLexer</span><span class="tok-o">::</span><span class="tok-k">new</span><span class="tok-o">,</span><i class="conum" data-value="1"></i><b>(1)</b>
                                              <span class="tok-n">JsonLexer</span><span class="tok-o">::</span><span class="tok-n">main</span><span class="tok-o">,</span><i class="conum" data-value="2"></i><b>(2)</b>
                                              <span class="tok-n">Token</span><span class="tok-o">::</span><span class="tok-n">getClass</span><span class="tok-o">,</span><i class="conum" data-value="3"></i><b>(3)</b>
                                              <span class="tok-n">Token</span><span class="tok-o">.</span><span class="tok-na">EOF</span><span class="tok-o">),</span><i class="conum" data-value="4"></i><b>(4)</b>
            <span class="tok-n">input</span><span class="tok-o">,</span> <span class="tok-n">output</span><span class="tok-o">);</span><i class="conum" data-value="5"></i><b>(5)</b>
    <span class="tok-o">}</span>
<span class="tok-o">}</span></code></pre>
</div>
</div>
<div class="colist arabic">
<table>
<tr>
<td><i class="conum" data-value="1"></i><b>1</b></td>
<td>A way to construct a lexical analyzer</td>
</tr>
<tr>
<td><i class="conum" data-value="2"></i><b>2</b></td>
<td>The lexer&#8217;s entry point to use during the tokenization</td>
</tr>
<tr>
<td><i class="conum" data-value="3"></i><b>3</b></td>
<td>A way to split tokens into different <em>categories</em></td>
</tr>
<tr>
<td><i class="conum" data-value="4"></i><b>4</b></td>
<td>The token at which tokenization should stop</td>
</tr>
<tr>
<td><i class="conum" data-value="5"></i><b>5</b></td>
<td>The input and output files to use</td>
</tr>
</table>
</div>
<div class="paragraph">
<p>In addition to the simpler <code>Tokenizer</code>, <code>TokenVisualizer</code> requires a
function to partition the tokens into several <em>categories</em>; tokens in
the same category will be highlighted with the same colour. Here we
simply use <code>Token::getClass</code> to sort the tokens by their actual type.</p>
</div>
<div class="admonitionblock tip">
<table>
<tr>
<td class="icon">
<i class="fa icon-tip" title="Tip"></i>
</td>
<td class="content">
<div class="paragraph">
<p>When using a token class generated from a Dolmen parser, an
enumeration <code>Token.Kind</code> is generated which represents the terminal
symbol associated to each token: in that case, a reasonable choice
for categorizing tokens is to use their <em>kind</em>.</p>
</div>
</td>
</tr>
</table>
</div>
<div class="paragraph">
<p>Compiling our <code>Visualizer</code> class and running it on <code>simple.json</code> will
produce a
<a href="./files/simple.json.bad.html"><code>simple.json.html</code></a> file
in the <code>resources</code> folder which looks like this:</p>
</div>
<div class="imageblock" style="text-align: center">
<div class="content">
<img src="./images/simple_json_bad_html.png" alt="Tokenization of `simple.json`" width="90%">
</div>
</div>
<div class="paragraph">
<p>The various tokens are conveniently displayed on top of the JSON
input. Opening the file in a browser, we can hover the mouse over the
various tokens to show the actual corresponding token and its recorded
position:</p>
</div>
<div class="imageblock" style="text-align: center">
<div class="content">
<img src="./images/simple_json_bad_html_hover.png" alt="Hovering over a token" width="50%">
</div>
</div>
<div class="paragraph">
<p>In this instance, we can see the <em>contents</em> of the token itself are
correct, in the sense that it is the string literal <code>STRING(sdfk"j)</code>,
but its position is reduced to the closing double-quote, as is the
case for every string literal in the page. Tokens other than string
literals seem alright. To understand the issue with string literals,
remember that the lexeme start and end positions are updated <em>each
time</em> a clause is applied. Now, consider how the lexer will analyze
the first literal appearing in the file, <code>"persons"</code>:</p>
</div>
<div class="olist arabic">
<ol class="arabic">
<li>
<p>When the <code>main()</code> rule is entered after the first two characters have
been consumed already, both start and end positions point to the first
available character, namely <code>"</code>.</p>
<div class="imageblock" style="text-align: center">
<div class="content">
<img src="./images/string_lexing0.png" alt="Entering main" width="30%">
</div>
</div>
</li>
<li>
<p>The clause of <code>main()</code> which matches this input is:</p>
<div class="listingblock">
<div class="content">
<pre class="pygments highlight"><code data-lang="jl"><span class="tok-o">|</span> <span class="tok-sc">&#39;&quot;&#39;</span>      <span class="tok-g">{ buffer.setLength(0);</span>
<span class="tok-g">             String s = string(buffer);</span>
<span class="tok-g">             </span><span class="tok-ge">return</span><span class="tok-g"> STRING(s);</span>
<span class="tok-g">           }</span></code></pre>
</div>
</div>
<div class="paragraph">
<p>When entering this semantic action, the start and end positions
reflect the fact that only one character has been matched:</p>
</div>
<div class="imageblock" style="text-align: center">
<div class="content">
<img src="./images/string_lexing1.png" alt="Entering main's semantic action" width="30%">
</div>
</div>
</li>
<li>
<p>The semantic action perform a nested call to another entry, namely <code>string(&#8230;&#8203;)</code>.
The rule will match all the contents of the literal via this clause:</p>
<div class="listingblock">
<div class="content">
<pre class="pygments highlight"><code data-lang="jl"><span class="tok-o">|</span> <span class="tok-p">[</span><span class="tok-o">^</span><span class="tok-sc">&#39;\</span><span class="tok-s">000</span><span class="tok-sc">&#39;</span><span class="tok-o">-</span><span class="tok-sc">&#39;\</span><span class="tok-s">037</span><span class="tok-sc">&#39;</span> <span class="tok-sc">&#39;&quot;&#39;</span> <span class="tok-sc">&#39;\</span><span class="tok-s">\</span><span class="tok-sc">&#39;</span><span class="tok-p">]</span><span class="tok-o">+</span>
           <span class="tok-g">{ buf.append(getLexeme());</span>
<span class="tok-g">             </span><span class="tok-ge">continue</span><span class="tok-g"> string;</span>
<span class="tok-g">           }</span></code></pre>
</div>
</div>
<div class="paragraph">
<p>When entering this clause, the positions reflect the part of the input which was
matched:</p>
</div>
<div class="imageblock" style="text-align: center">
<div class="content">
<img src="./images/string_lexing2.png" alt="Entering string's semantic action 1/2" width="30%">
</div>
</div>
<div class="paragraph">
<p>Executing the action will append the match to the <code>buffer</code>, and reenter recursively
in the <code>string</code> rule.</p>
</div>
</li>
<li>
<p>As the <code>string</code> rule is reentered, the input will finally match the
closing delimiter via this clause:</p>
<div class="listingblock">
<div class="content">
<pre class="pygments highlight"><code data-lang="jl"><span class="tok-o">|</span> <span class="tok-sc">&#39;&quot;&#39;</span>      <span class="tok-g">{ </span><span class="tok-ge">return</span><span class="tok-g"> buf.toString(); }</span></code></pre>
</div>
</div>
<div class="paragraph">
<p>and will thus return the contents of the buffer, namely <code>persons</code>, back to
the semantic action of <code>main()</code> that was entered earlier. The positions at
this point reflect that the last match was the closing double-quote character:</p>
</div>
<div class="imageblock" style="text-align: center">
<div class="content">
<img src="./images/string_lexing3.png" alt="Entering string's semantic action 2/2" width="30%">
</div>
</div>
</li>
<li>
<p>Back in <code>main()</code> 's semantic action, the token <code>STRING(persons)</code> is
built and returned, but the positions are still those associated
with the last match.  This explains why the string literal tokens
ended up positioned at the corresponding closing <code>"</code>.</p>
</li>
</ol>
</div>
<div class="paragraph">
<p>In order to fix this, it is sufficient to simply save the current
start position after having matched the opening <code>"</code>, and restore
it after the nested call to the <code>string</code> rule has been completed.
That way, the situation in the lexer when the <code>STRING(..)</code> token
is returned is as follows:</p>
</div>
<div class="imageblock" style="text-align: center">
<div class="content">
<img src="./images/string_lexing4.png" alt="Leaving main's semantic action" width="30%">
</div>
</div>
<div class="paragraph">
<p>This tampering with positions is the main downside to using nested
entries in a lexer description. It must be noted though that only
nested calls returning a token require this: there is no issue with
the nested call to <code>escapeSequence</code> or with the various <code>continue
main</code> and <code>continue string</code>&#8201;&#8212;&#8201;which incidentally is the reason why
Dolmen does not automatically save positions on the stack in nested
calls. Moreover, the saving and restoring of a position can be
performed in an elegant fashion by simply wrapping the nested call
with the
<a href="./javadoc/org/stekikun/dolmen/codegen/LexBuffer.html#saveStart-java.util.function.Supplier-"><code>saveStart</code></a>
method exported by <code>LexBuffer</code>:</p>
</div>
<div class="listingblock">
<div class="title">Fixing the nested call to <code>string</code></div>
<div class="content">
<pre class="pygments highlight"><code data-lang="jl"><span class="tok-o">|</span> <span class="tok-sc">&#39;&quot;&#39;</span>      <span class="tok-g">{ buffer.setLength(0);</span>
<span class="tok-g">             String s = saveStart(() -&gt; string(buffer));</span>
<span class="tok-g">             </span><span class="tok-ge">return</span><span class="tok-g"> STRING(s);</span>
<span class="tok-g">           }</span></code></pre>
</div>
</div>
<div class="paragraph">
<p>After having amended our lexer description as above, recompiled
everything, and executed <code>Visualizer</code> again, the produced
<a href="./files/simple.json.good.html"><code>simple.json.html</code></a>
file now seems good all around:</p>
</div>
<div class="imageblock" style="text-align: center">
<div class="content">
<img src="./images/simple_json_good_html.png" alt="Tokenization of `simple.json`" width="90%">
</div>
</div>
<div class="admonitionblock tip">
<table>
<tr>
<td class="icon">
<i class="fa icon-tip" title="Tip"></i>
</td>
<td class="content">
<div class="paragraph">
<p>It may seem that <code>TokenVisualizer</code> is always more convenient than the
textual <code>Tokenizer</code> to inspect a lexer&#8217;s results, but the textual
output can be advantageous for a variety of reasons:
it is more compact, can be easily passed to another tool for some
automated processing, is a good candidate for recording the results
of the lexical analysis for the purpose of non-regression testing and
continuous integration in general.</p>
</div>
</td>
</tr>
</table>
</div>
</div>
<div class="sect3">
<h4 id="_afterword">Afterword</h4>
<div class="paragraph">
<p>We have now completed our lexical analyzer for JSON! In this tutorial,
we have come a long way in terms of understanding the various features
of a Dolmen lexer, how to best use them, and also how to overcome the
potential obstacles that frequently arise. Here is our final lexer
description:</p>
</div>
<div class="listingblock">
<div class="title">Our final JSON Dolmen lexer</div>
<div class="content">
<pre class="pygments highlight"><code data-lang="jl"><span class="tok-k">import</span> <span class="tok-nf">mypackage</span>.<span class="tok-nf">Token</span><span class="tok-p">;</span>
<span class="tok-k">import</span> <span class="tok-k">static</span> <span class="tok-nf">mypackage</span>.<span class="tok-nf">Token</span>.<span class="tok-o">*</span><span class="tok-p">;</span>

<span class="tok-g">{</span>
<span class="tok-g">  </span><span class="tok-ge">private</span><span class="tok-g"> </span><span class="tok-ge">final</span><span class="tok-g"> StringBuilder buffer = </span><span class="tok-ge">new</span><span class="tok-g"> StringBuilder();</span>
<span class="tok-g">}</span>

<span class="tok-nf">ws</span> <span class="tok-o">=</span> <span class="tok-p">[</span><span class="tok-sc">&#39;\</span><span class="tok-s">t</span><span class="tok-sc">&#39;</span> <span class="tok-sc">&#39; &#39;</span><span class="tok-p">]</span><span class="tok-o">+</span><span class="tok-p">;</span>
<span class="tok-nf">nl</span> <span class="tok-o">=</span> <span class="tok-p">(</span><span class="tok-sc">&#39;\</span><span class="tok-s">n</span><span class="tok-sc">&#39;</span> <span class="tok-o">|</span> <span class="tok-sc">&#39;\</span><span class="tok-s">r</span><span class="tok-sc">&#39;</span> <span class="tok-o">|</span> <span class="tok-s">&quot;\r\n&quot;</span><span class="tok-p">);</span>

<span class="tok-nf">digit</span> <span class="tok-o">=</span> <span class="tok-p">[</span><span class="tok-sc">&#39;0&#39;</span><span class="tok-o">-</span><span class="tok-sc">&#39;9&#39;</span><span class="tok-p">];</span>
<span class="tok-nf">nzdigit</span> <span class="tok-o">=</span> <span class="tok-nf">digit</span> <span class="tok-o">#</span> <span class="tok-sc">&#39;0&#39;</span><span class="tok-p">;</span>
<span class="tok-nf">int</span> <span class="tok-o">=</span> <span class="tok-sc">&#39;-&#39;</span><span class="tok-o">?</span> <span class="tok-p">(</span><span class="tok-sc">&#39;0&#39;</span> <span class="tok-o">|</span> <span class="tok-nf">nzdigit</span> <span class="tok-nf">digit</span><span class="tok-o">*</span><span class="tok-p">);</span>
<span class="tok-nf">frac</span> <span class="tok-o">=</span> <span class="tok-sc">&#39;.&#39;</span> <span class="tok-nf">digit</span><span class="tok-o">+</span><span class="tok-p">;</span>
<span class="tok-nf">e</span> <span class="tok-o">=</span> <span class="tok-p">(</span><span class="tok-sc">&#39;e&#39;</span> <span class="tok-o">|</span> <span class="tok-sc">&#39;E&#39;</span><span class="tok-p">)</span> <span class="tok-p">(</span><span class="tok-sc">&#39;+&#39;</span> <span class="tok-o">|</span> <span class="tok-sc">&#39;-&#39;</span><span class="tok-p">)</span><span class="tok-o">?</span><span class="tok-p">;</span>
<span class="tok-nf">exp</span> <span class="tok-o">=</span> <span class="tok-nf">e</span> <span class="tok-nf">digit</span><span class="tok-o">+</span><span class="tok-p">;</span>
<span class="tok-nf">number</span> <span class="tok-o">=</span> <span class="tok-nf">int</span> <span class="tok-nf">frac</span><span class="tok-o">?</span> <span class="tok-nf">exp</span><span class="tok-o">?</span><span class="tok-p">;</span>
<span class="tok-nf">hexDigit</span> <span class="tok-o">=</span> <span class="tok-nf">digit</span> <span class="tok-o">|</span> <span class="tok-p">[</span><span class="tok-sc">&#39;a&#39;</span><span class="tok-o">-</span><span class="tok-sc">&#39;f&#39;</span> <span class="tok-sc">&#39;A&#39;</span><span class="tok-o">-</span><span class="tok-sc">&#39;F&#39;</span><span class="tok-p">];</span>

<span class="tok-k">public</span> <span class="tok-g">{ Token }</span> <span class="tok-k">rule</span> <span class="tok-nf">main</span> <span class="tok-o">=</span>
<span class="tok-o">|</span> <span class="tok-nf">ws</span>       <span class="tok-g">{ </span><span class="tok-ge">continue</span><span class="tok-g"> main; }</span>
<span class="tok-o">|</span> <span class="tok-nf">nl</span>       <span class="tok-g">{ newline(); </span><span class="tok-ge">continue</span><span class="tok-g"> main; }</span>
<span class="tok-o">|</span> <span class="tok-sc">&#39;{&#39;</span>      <span class="tok-g">{ </span><span class="tok-ge">return</span><span class="tok-g"> LBRACE; }</span>
<span class="tok-o">|</span> <span class="tok-sc">&#39;}&#39;</span>      <span class="tok-g">{ </span><span class="tok-ge">return</span><span class="tok-g"> RBRACE; }</span>
<span class="tok-o">|</span> <span class="tok-sc">&#39;[&#39;</span>      <span class="tok-g">{ </span><span class="tok-ge">return</span><span class="tok-g"> LBRACKET; }</span>
<span class="tok-o">|</span> <span class="tok-sc">&#39;]&#39;</span>      <span class="tok-g">{ </span><span class="tok-ge">return</span><span class="tok-g"> RBRACKET; }</span>
<span class="tok-o">|</span> <span class="tok-sc">&#39;:&#39;</span>      <span class="tok-g">{ </span><span class="tok-ge">return</span><span class="tok-g"> COLON; }</span>
<span class="tok-o">|</span> <span class="tok-sc">&#39;,&#39;</span>      <span class="tok-g">{ </span><span class="tok-ge">return</span><span class="tok-g"> COMMA; }</span>
<span class="tok-o">|</span> <span class="tok-s">&quot;true&quot;</span>   <span class="tok-g">{ </span><span class="tok-ge">return</span><span class="tok-g"> TRUE; }</span>
<span class="tok-o">|</span> <span class="tok-s">&quot;false&quot;</span>  <span class="tok-g">{ </span><span class="tok-ge">return</span><span class="tok-g"> FALSE; }</span>
<span class="tok-o">|</span> <span class="tok-s">&quot;null&quot;</span>   <span class="tok-g">{ </span><span class="tok-ge">return</span><span class="tok-g"> NULL; }</span>
<span class="tok-o">|</span> <span class="tok-nf">number</span>   <span class="tok-g">{ </span><span class="tok-ge">return</span><span class="tok-g"> NUMBER(Double.parseDouble(getLexeme())); }</span>
<span class="tok-o">|</span> <span class="tok-sc">&#39;&quot;&#39;</span>      <span class="tok-g">{ buffer.setLength(0);</span>
<span class="tok-g">             String s = saveStart(() -&gt; string(buffer));</span>
<span class="tok-g">             </span><span class="tok-ge">return</span><span class="tok-g"> STRING(s);</span>
<span class="tok-g">           }</span>
<span class="tok-o">|</span> <span class="tok-nf">_</span> <span class="tok-k">as</span> <span class="tok-nf">c</span>   <span class="tok-g">{ </span><span class="tok-ge">throw</span><span class="tok-g"> error(</span><span class="tok-gs">&quot;Unexpected character: &quot;</span><span class="tok-g"> + c); }</span>
<span class="tok-o">|</span> <span class="tok-k">eof</span>      <span class="tok-g">{ </span><span class="tok-ge">return</span><span class="tok-g"> EOF; }</span>

<span class="tok-k">private</span> <span class="tok-g">{ String }</span> <span class="tok-k">rule</span> <span class="tok-nf">string</span><span class="tok-g">{StringBuilder buf}</span> <span class="tok-o">=</span>
<span class="tok-o">|</span> <span class="tok-sc">&#39;&quot;&#39;</span>      <span class="tok-g">{ </span><span class="tok-ge">return</span><span class="tok-g"> buf.toString(); }</span>
<span class="tok-o">|</span> <span class="tok-sc">&#39;\</span><span class="tok-s">\</span><span class="tok-sc">&#39;</span>     <span class="tok-g">{ </span><span class="tok-ge">char</span><span class="tok-g"> c = escapeSequence();</span>
<span class="tok-g">             buf.append(c);</span>
<span class="tok-g">             </span><span class="tok-ge">continue</span><span class="tok-g"> string;</span>
<span class="tok-g">           }</span>
<span class="tok-o">|</span> <span class="tok-p">[</span><span class="tok-o">^</span><span class="tok-sc">&#39;\</span><span class="tok-s">000</span><span class="tok-sc">&#39;</span><span class="tok-o">-</span><span class="tok-sc">&#39;\</span><span class="tok-s">037</span><span class="tok-sc">&#39;</span> <span class="tok-sc">&#39;&quot;&#39;</span> <span class="tok-sc">&#39;\</span><span class="tok-s">\</span><span class="tok-sc">&#39;</span><span class="tok-p">]</span><span class="tok-o">+</span>
           <span class="tok-g">{ buf.append(getLexeme());</span>
<span class="tok-g">             </span><span class="tok-ge">continue</span><span class="tok-g"> string;</span>
<span class="tok-g">           }</span>
<span class="tok-o">|</span> <span class="tok-nf">_</span> <span class="tok-k">as</span> <span class="tok-nf">c</span>   <span class="tok-g">{ </span><span class="tok-ge">throw</span><span class="tok-g"> error(</span>
<span class="tok-g">               String.format(</span><span class="tok-gs">&quot;Forbidden character in string literal: U+%04x&quot;</span><span class="tok-g">, (</span><span class="tok-ge">short</span><span class="tok-g">)c));</span>
<span class="tok-g">           }</span>
<span class="tok-o">|</span> <span class="tok-k">eof</span>      <span class="tok-g">{ </span><span class="tok-ge">throw</span><span class="tok-g"> error(</span><span class="tok-gs">&quot;Unterminated string literal&quot;</span><span class="tok-g">); }</span>

<span class="tok-k">private</span> <span class="tok-g">{ </span><span class="tok-ge">char</span><span class="tok-g"> }</span> <span class="tok-k">rule</span> <span class="tok-nf">escapeSequence</span> <span class="tok-o">=</span>
<span class="tok-o">|</span> <span class="tok-sc">&#39;b&#39;</span>	 <span class="tok-g">{ </span><span class="tok-ge">return</span><span class="tok-g"> </span><span class="tok-gs">&#39;\b&#39;</span><span class="tok-g">; }</span>
<span class="tok-o">|</span> <span class="tok-sc">&#39;t&#39;</span>	 <span class="tok-g">{ </span><span class="tok-ge">return</span><span class="tok-g"> </span><span class="tok-gs">&#39;\t&#39;</span><span class="tok-g">; }</span>
<span class="tok-o">|</span> <span class="tok-sc">&#39;n&#39;</span>	 <span class="tok-g">{ </span><span class="tok-ge">return</span><span class="tok-g"> </span><span class="tok-gs">&#39;\n&#39;</span><span class="tok-g">; }</span>
<span class="tok-o">|</span> <span class="tok-sc">&#39;f&#39;</span>	 <span class="tok-g">{ </span><span class="tok-ge">return</span><span class="tok-g"> </span><span class="tok-gs">&#39;\f&#39;</span><span class="tok-g">; }</span>
<span class="tok-o">|</span> <span class="tok-sc">&#39;r&#39;</span>	 <span class="tok-g">{ </span><span class="tok-ge">return</span><span class="tok-g"> </span><span class="tok-gs">&#39;\r&#39;</span><span class="tok-g">; }</span>
<span class="tok-o">|</span> <span class="tok-sc">&#39;&quot;&#39;</span>	 <span class="tok-g">{ </span><span class="tok-ge">return</span><span class="tok-g"> </span><span class="tok-gs">&#39;&quot;&#39;</span><span class="tok-g">; }</span>
<span class="tok-o">|</span> <span class="tok-sc">&#39;\</span><span class="tok-s">&#39;</span><span class="tok-sc">&#39;</span>	 <span class="tok-g">{ </span><span class="tok-ge">return</span><span class="tok-g"> </span><span class="tok-gs">&#39;\&#39;&#39;</span><span class="tok-g">; }</span>
<span class="tok-o">|</span> <span class="tok-sc">&#39;\</span><span class="tok-s">\</span><span class="tok-sc">&#39;</span>	 <span class="tok-g">{ </span><span class="tok-ge">return</span><span class="tok-g"> </span><span class="tok-gs">&#39;\\&#39;</span><span class="tok-g">; }</span>
<span class="tok-o">|</span> <span class="tok-sc">&#39;/&#39;</span>	 <span class="tok-g">{ </span><span class="tok-ge">return</span><span class="tok-g"> </span><span class="tok-gs">&#39;/&#39;</span><span class="tok-g">; }</span>
<span class="tok-o">|</span> <span class="tok-sc">&#39;u&#39;</span> <span class="tok-p">(</span><span class="tok-nf">hexDigit</span><span class="tok-p">&lt;</span><span class="tok-m">4</span><span class="tok-p">&gt;</span> <span class="tok-k">as</span> <span class="tok-nf">code</span><span class="tok-p">)</span>
	 <span class="tok-g">{ </span><span class="tok-ge">return</span><span class="tok-g"> ((</span><span class="tok-ge">char</span><span class="tok-g">)(Integer.parseInt(code, 16))); }</span>
<span class="tok-o">|</span> <span class="tok-sc">&#39;u&#39;</span>    <span class="tok-g">{ </span><span class="tok-ge">throw</span><span class="tok-g"> error(</span><span class="tok-gs">&quot;Invalid Unicode escape sequence: \\uxxxx expected&quot;</span><span class="tok-g">); }</span>
<span class="tok-o">|</span> <span class="tok-nf">_</span> <span class="tok-k">as</span> <span class="tok-nf">c</span> <span class="tok-g">{ </span><span class="tok-ge">throw</span><span class="tok-g"> error(</span><span class="tok-gs">&quot;Invalid escape character: &quot;</span><span class="tok-g"> + c + </span><span class="tok-gs">&quot;. Valid ones are &quot;</span><span class="tok-g"> +</span>
<span class="tok-g">           </span><span class="tok-gs">&quot;\\\\, \\/,  \\\&#39;, \\\&quot;, \\n, \\t, \\b, \\f, \\r.&quot;</span><span class="tok-g">);</span>
<span class="tok-g">         }</span>
<span class="tok-o">|</span> <span class="tok-k">eof</span>    <span class="tok-g">{ </span><span class="tok-ge">throw</span><span class="tok-g"> error(</span><span class="tok-gs">&quot;Unterminated escape sequence&quot;</span><span class="tok-g">); }</span>

<span class="tok-g">{ }</span></code></pre>
</div>
</div>
<div class="paragraph">
<p>It is 73 lines long, for a corresponding generated lexical analyzer of
just above 1000 lines. It strictly conforms to the lexical conventions
described in the <a href="http://www.ecma-international.org/publications/files/ECMA-ST/ECMA-404.pdf">JSON standard</a> and handles all lexical
errors explicitly. Looking back at the complete lexer description, it
should be noted that there was nothing particularly difficult in the
lexer we wrote: we took things step-by-step in a slow fashion, went
astray at times for didactic purposes, detailed many aspects of
working with Dolmen lexers, but the resulting lexer is short, arguably
easy to read and understand, and performs as fast as a manually
crafted lexical analyzer (see comparison with
<a href="https://github.com/google/gson">Gson</a> below).<br>
Whether you need lexical analysis for parsing a programming language
or for character streams' pre-processing, have fun with Dolmen!</p>
</div>
<div class="exampleblock">
<div class="title">Performance</div>
<div class="content">
<div class="paragraph">
<p>The main design principles for Dolmen emphasize a lightweight and
flexible approach, as well as the robustness and reviewability of the
generated code. Performance is not strictly an objective <em>per se</em>, but
it is always interesting to see how the generated lexer will behave in
comparison to other existing solutions.<br>
We test our JSON lexer using a
<a href="https://github.com/zemirco/sf-city-lots-json/">large JSON file</a> of
over 189Mb (and over 20 million tokens). The file is analyzed a couple
times to give a chance to the JVM to "heat up"; the average time required
for tokenizing the file is then computed over 50 additional analyses.
Tokenizing in this context consists in calling the lexer&#8217;s main entry
repeatedly, and throwing the returned token away, until the end-of-input
is reached. The average time taken by our Dolmen lexer to process the
whole file is 4050ms, which amounts to a lexing rate of 45.76Mb/s.</p>
</div>
<div class="paragraph">
<p>We performed the exact same tests using Google&#8217;s
<a href="https://github.com/google/gson">Gson</a> library, as well as
with lexers we wrote with
<a href="https://www.antlr.org/">ANTLR</a> and <a href="https://jflex.de/">JFlex</a>.
The results are summarized in the figure below:</p>
</div>
<div class="imageblock" style="text-align: center">
<div class="content">
<img src="./images/lexer_bench_2.png" alt="JSON lexing speed" width="90%">
</div>
</div>
<div class="paragraph">
<p>As you can see, the lexers generated by ANTLR and JFlex are slower
than Dolmen&#8217;s, which in turn is a fraction slower than Gson&#8217;s, by less
then a percent. Gson itself is not necessarily an industrial strength
JSON parser&#8201;&#8212;&#8201;there exists such heavy duty parsers which can process
hundreds of megabytes per second&#8201;&#8212;&#8201;but it is a mature library with a
carefully hand-written JSON parser of around 1600 lines. That we are
able to perform in a comparable fashion using a lexer generated from a
short description is quite satisfactory.</p>
</div>
</div>
</div>
<div style="page-break-after: always;"></div>
</div>
</div>
<div class="sect2">
<h3 id="_lexer_entries">Lexer Entries</h3>
<div class="paragraph">
<p>The main building blocks of a Dolmen lexical analyzer are the lexer
<em>entries</em>. Dolmen will generate a single Java method per entry in the
resulting generated lexical analyzer. The syntax of a lexer entry is
as follows:</p>
</div>
<div class="listingblock">
<div class="content">
<pre><a id="InJLEntry"></a>Entry :=
  (<strong>public</strong> | <strong>private</strong>)         // entry's visibility
  <a href="#JLACTION">ACTION</a>            // entry's return type
  <strong>rule</strong> <a href="#JLIDENT">IDENT</a>       // entry's name
  (<a href="#JLACTION">ACTION</a>)?         // entry's optional arguments
  <strong>=</strong> (<strong>shortest</strong>)?     // whether shortest or longest match rule is used
  <a href="#JLClause">Clause</a>+</pre>
</div>
</div>
<div class="paragraph">
<p>An entry has a visibility (public or private), a return type, a name
and optional parameters: all of these will propagate directly to the
Java method generated from the entry. The remainder of the entry
is a sequence of <em>clauses</em> which associate a regular expression
to some arbitrary Java <em>semantic action</em>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre><a id="InJLClause"></a>Clause :=
| <strong>|</strong> <a href="#JLRegular">Regular</a> <a href="#JLACTION">ACTION</a>
| <strong>|</strong> <strong>orelse</strong>  <a href="#JLACTION">ACTION</a></pre>
</div>
</div>
<div class="admonitionblock tip">
<table>
<tr>
<td class="icon">
<i class="fa icon-tip" title="Tip"></i>
</td>
<td class="content">
Instead of a regular expression, a clause can be introduced
     with the special <code>orelse</code> keyword, whose meaning is explained
     in a <a href="#Lexers_Wildcards">dedicated section below</a>.
</td>
</tr>
</table>
</div>
<div class="paragraph">
<p>In essence, Dolmen lexers let you conveniently program methods which
consume an input sequence of characters, recognize some input patterns
described by regular expressions, and take on different actions
depending on what patterns have been matched. Whether you use these
actions to tokenize the input stream, to transform the input stream by
extracting, decoding, encoding or filtering parts of it, to count
occurrences of certain patterns or anything else, is completely
irrelevant to Dolmen. Dolmen&#8217;s job is to take the high-level lexer
description and turn it into an efficient analyzer by taking care of
important details such as:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>managing input loading and buffering;</p>
</li>
<li>
<p>compiling an entry&#8217;s clauses into efficient code which matches
input and select the adequate semantic action;</p>
</li>
<li>
<p>keeping track of matched input positions, as well as those fragments
corresponding to patterns captured via the <code>&#8230;&#8203; as c</code> construct;</p>
</li>
<li>
<p>assisting users by statically detecting and reporting common
mistakes in lexer descriptions, such as useless clauses, etc.</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>When more than one clause in the entry matches the current input, the
default disambiguation rule is to pick the clause which yields the
<em>longest</em> match. This behaviour can be changed for a given entry by
using the <code><strong>shortest</strong></code> keyword prior to the clauses: in this case,
priority is given to the clause yielding the shortest match. In any
case, when several clauses yield matches with the same length, the
clause which appears first in the lexer description will be selected.</p>
</div>
<div class="paragraph">
<p>The shortest-match rule is seldom used, at least for tokenizing
purposes. It can prove useful when writing text stream processors, in
particular when reading input from a network staream or from standard
input, as entries which use the shortest-match rule never need to
"look ahead" in the input stream and backtrack before selecting the
correct clause, unlike regular longest-match entries.</p>
</div>
<div class="sect3">
<h4 id="Lexers_Regular_Expressions">Regular Expressions</h4>
<div class="paragraph">
<p>In this section, we describe the Dolmen syntax for regular
expressions. Regular expressions appear as part of clauses in lexer
entries, but auxiliary regular expressions can also be defined
before the lexer entries:</p>
</div>
<div class="listingblock">
<div class="content">
<pre><a id="InJLDefinition"></a>Definition :=
  <a href="#JLIDENT">IDENT</a> <strong>=</strong> <a href="#JLRegular">Regular</a> <strong>;</strong></pre>
</div>
</div>
<div class="paragraph">
<p>The identifier on the left-hand side in a regular expression
definition is the name which can be used to denote that regular
expression in subsequent definitions as well as in clauses. The
various regular expression constructs are summarized in
<a href="#Lexers_Regexps_Table">this table</a>, we detail each of them
in the following.</p>
</div>
<div class="dlist">
<dl>
<dt class="hdlist1">Literals</dt>
<dd>
<p>The most basic form of regular expression are the <em>character</em> and
<em>string</em> literals. A character literal such as <code>'a'</code> or <code>'\040'</code> is a
regular expression which simply matches the given character.
Similarly, a string literal such as <code>"foo"</code> or <code>"\r\n"</code> is a regular
expression which matches the given string. The exact syntax for
character and string literals is detailed in the the
<a href="#Lexers_Lexical_Conventions">lexical conventions</a>.</p>
<div class="listingblock">
<div class="content">
<pre class="pygments highlight"><code data-lang="jl"><span class="tok-c tok-c-Singleline">// Some literal regular expressions</span>
<span class="tok-nf">space</span> <span class="tok-o">=</span> <span class="tok-sc">&#39; &#39;</span><span class="tok-p">;</span>
<span class="tok-nf">pub</span> <span class="tok-o">=</span> <span class="tok-s">&quot;public&quot;</span><span class="tok-p">;</span></code></pre>
</div>
</div>
<div class="paragraph">
<p>Additionally, there are two "special" literals <code>_</code> and <code>eof</code>,
respectively called <em>wildcard</em> and <em>end-of-input</em>. <code>eof</code> is
a meta-character with represents the fact that the end of
the input stream has been reached; in particular it does not
really match a given character, but simply succeeds when the
input stream has been exhausted. On the other hand, the
wildcard <code>_</code> will match any single character from the input,
and thus in particular is mutually exclusive with <code>eof</code>.
These special literals are discussed further
<a href="#Lexers_Wildcards">below</a>.</p>
</div>
</dd>
<dt class="hdlist1">Character classes</dt>
<dd>
<div class="paragraph">
<p>A <em>character class</em> is a way of denoting a regular expression which
must only match a character in a subset of the whole character set. It
is introduced by square brackets <code>[&#8230;&#8203;]</code> and can contain any non-empty
sequence of:</p>
</div>
<div class="openblock">
<div class="content">
<div class="ulist">
<ul>
<li>
<p>single character literals, such as <code>'a'</code>, <code>'0'</code>;</p>
</li>
<li>
<p>character ranges, such as <code>'a'-'z'</code>, <code>'0'-'9'</code>, denoting all the
characters which belong to the specified range (inclusive on both
ends);</p>
</li>
<li>
<p>names of already defined regular expressions whose value corresponds
to a character class (or can be reduced to a character class, such
as a single character literal or the wildcard <code>_</code>).</p>
</li>
</ul>
</div>
</div>
</div>
<div class="paragraph">
<p>The meaning of a character class can also be completely <strong>inverted</strong>
if it starts with a <code>^</code> character, in which case it matches any
character which does not belong to the specified set.</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="pygments highlight"><code data-lang="jl"><span class="tok-c tok-c-Singleline">// Some character classes</span>
<span class="tok-nf">whitespace</span> <span class="tok-o">=</span> <span class="tok-p">[</span><span class="tok-sc">&#39;\</span><span class="tok-s">t</span><span class="tok-sc">&#39;</span> <span class="tok-nf">space</span> <span class="tok-sc">&#39;\</span><span class="tok-s">f</span><span class="tok-sc">&#39;</span><span class="tok-p">];</span>
<span class="tok-nf">alpha</span> <span class="tok-o">=</span> <span class="tok-p">[</span><span class="tok-sc">&#39;a&#39;</span><span class="tok-o">-</span><span class="tok-sc">&#39;z&#39;</span> <span class="tok-sc">&#39;A&#39;</span><span class="tok-o">-</span><span class="tok-sc">&#39;Z&#39;</span><span class="tok-p">];</span>
<span class="tok-nf">nonctrl</span> <span class="tok-o">=</span> <span class="tok-p">[</span><span class="tok-o">^</span><span class="tok-sc">&#39;\</span><span class="tok-s">000</span><span class="tok-sc">&#39;</span><span class="tok-o">-</span><span class="tok-sc">&#39;\</span><span class="tok-s">037</span><span class="tok-sc">&#39;</span><span class="tok-p">];</span></code></pre>
</div>
</div>
<div class="paragraph">
<p>The grammar for character classes is recalled in the
<a href="#JLCharClass">syntax reference</a>.</p>
</div>
</dd>
<dt class="hdlist1">Character class difference</dt>
<dd>
<p>The <em>difference operator</em> <code>r # s</code> lets one define a regular
expression by taking the set of characters which match
the given class <code>r</code> but do not match the class <code>s</code>. The regular
expressions used as operands for <code>#</code> must reduce to character
classes or a lexical error will be reported by Dolmen.</p>
<div class="listingblock">
<div class="content">
<pre class="pygments highlight"><code data-lang="jl"><span class="tok-c tok-c-Singleline">// Some character class differences</span>
<span class="tok-nf">digit</span> <span class="tok-o">=</span> <span class="tok-p">[</span><span class="tok-sc">&#39;0&#39;</span><span class="tok-o">-</span><span class="tok-sc">&#39;9&#39;</span><span class="tok-p">];</span>
<span class="tok-nf">nzdigit</span> <span class="tok-o">=</span> <span class="tok-nf">digit</span> <span class="tok-o">#</span> <span class="tok-sc">&#39;0&#39;</span><span class="tok-p">;</span>
<span class="tok-nf">lowercase</span> <span class="tok-o">=</span> <span class="tok-nf">alpha</span> <span class="tok-o">#</span> <span class="tok-p">[</span><span class="tok-sc">&#39;a&#39;</span><span class="tok-o">-</span><span class="tok-sc">&#39;z&#39;</span><span class="tok-p">];</span>
<span class="tok-nf">ctrl</span> <span class="tok-o">=</span> <span class="tok-nf">_</span> <span class="tok-o">#</span> <span class="tok-nf">nonctrl</span><span class="tok-p">;</span></code></pre>
</div>
</div>
</dd>
<dt class="hdlist1">Repetitions</dt>
<dd>
<div class="paragraph">
<p>Dolmen supports the following traditional postfix <em>repetition</em>
operators:</p>
</div>
<div class="openblock">
<div class="content">
<div class="ulist">
<ul>
<li>
<p><code>r?</code> matches zero or one occurrence of the regular expression <code>r</code>;</p>
</li>
<li>
<p><code>r+</code> matches one or more occurrences of the regular expression <code>r</code>;</p>
</li>
<li>
<p><code>r*</code> matches any number of occurrences of the regular expression
<code>r</code>, including zero.</p>
</li>
</ul>
</div>
</div>
</div>
<div class="paragraph">
<p>Besides these basic operators, it is also possible to specify any
finite number of repetitions using the following syntax where <code>n</code> and
<code>m</code> stand for literal decimal natural integers:</p>
</div>
<div class="openblock">
<div class="content">
<div class="ulist">
<ul>
<li>
<p><code>r&lt;n&gt;</code> matches exactly <code>n</code> occurrences of the regular expression <code>r</code>;</p>
</li>
<li>
<p><code>r&lt;n,m&gt;</code> matches anything between <code>n</code> and <code>m</code> (inclusive) occurrences
of the regular expression <code>r</code>.</p>
</li>
</ul>
</div>
</div>
</div>
<div class="paragraph">
<p>Note that <code>r&lt;n&gt;</code> is just syntactic shortcut for <code>r&lt;n,n&gt;</code>, and that
<code>r?</code> is completely equivalent to <code>r&lt;0,1&gt;</code>. There is no way to specify
an "infinite" upper bound, so <code>r+</code> and <code>r*</code> cannot be obtained with an
instance of <code>r&lt;n,m&gt;</code>. This is not a limitation in practice, since
something like any number of repetitions larger or equal to 3 can be
obtained by a combination such as <code>r&lt;3&gt;r*</code>.</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="pygments highlight"><code data-lang="jl"><span class="tok-c tok-c-Singleline">// Using repetition operators</span>
<span class="tok-nf">decimal</span> <span class="tok-o">=</span> <span class="tok-nf">digit</span><span class="tok-o">+</span><span class="tok-p">;</span>
<span class="tok-nf">hexcode</span> <span class="tok-o">=</span> <span class="tok-p">[</span><span class="tok-nf">digit</span> <span class="tok-sc">&#39;a&#39;</span><span class="tok-o">-</span><span class="tok-sc">&#39;f&#39;</span> <span class="tok-sc">&#39;A&#39;</span><span class="tok-o">-</span><span class="tok-sc">&#39;F&#39;</span><span class="tok-p">]&lt;</span><span class="tok-m">4</span><span class="tok-p">&gt;;</span>
<span class="tok-nf">word</span> <span class="tok-o">=</span> <span class="tok-p">[</span><span class="tok-sc">&#39;_&#39;</span> <span class="tok-nf">alpha</span><span class="tok-p">]</span><span class="tok-o">+</span><span class="tok-p">;</span>
<span class="tok-nf">blanks</span> <span class="tok-o">=</span> <span class="tok-nf">whitespace</span><span class="tok-o">*</span><span class="tok-p">;</span></code></pre>
</div>
</div>
</dd>
<dt class="hdlist1">Concatenation</dt>
<dd>
<div class="paragraph">
<p>The concatenation of two regular expressions <code>r s</code> is a regular
expression which first matches <code>r</code> and then <code>s</code>. Concatenation is
<em>right-associative</em>, and has strictly lower precedence than every
operator we have seen so far. In particular, a string literal regular
expression such as <code>"foo"</code> is just syntactic sugar for the
concatenation <code>'f''o''o'</code> of its character literals. Similarly, a
repetition <code>r&lt;4&gt;</code> is just another, shorter, way of writing <code>r r r r</code>.</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="pygments highlight"><code data-lang="jl"><span class="tok-c tok-c-Singleline">// Using concatenation</span>
<span class="tok-nf">float</span> <span class="tok-o">=</span> <span class="tok-nf">decimal</span> <span class="tok-p">(</span><span class="tok-sc">&#39;.&#39;</span> <span class="tok-nf">decimal</span><span class="tok-p">)</span><span class="tok-o">?</span><span class="tok-p">;</span>
<span class="tok-nf">string</span> <span class="tok-o">=</span> <span class="tok-sc">&#39;&quot;&#39;</span> <span class="tok-p">[</span><span class="tok-o">^</span> <span class="tok-nf">ctrl</span> <span class="tok-sc">&#39;&quot;&#39;</span><span class="tok-p">]</span><span class="tok-o">*</span> <span class="tok-sc">&#39;&quot;&#39;</span><span class="tok-p">;</span>
<span class="tok-nf">r1</span> <span class="tok-o">=</span> <span class="tok-sc">&#39;a&#39;&#39;b&#39;</span><span class="tok-o">+</span><span class="tok-p">;</span>  <span class="tok-c tok-c-Singleline">// ab......b</span>
<span class="tok-nf">r2</span> <span class="tok-o">=</span> <span class="tok-p">(</span><span class="tok-sc">&#39;a&#39;&#39;b&#39;</span><span class="tok-p">)</span><span class="tok-o">+</span><span class="tok-p">;</span>  <span class="tok-c tok-c-Singleline">// abab...ab</span></code></pre>
</div>
</div>
<div class="paragraph">
<p>Note how parentheses can be used to disambiguate or regroup regular
expressions when natural precedence rules would not yield the intended
result.</p>
</div>
</dd>
<dt class="hdlist1">Choice</dt>
<dd>
<div class="paragraph">
<p>The <em>choice operator</em> <code>r | s</code> matches anything that either regular
expression <code>r</code> or <code>s</code> matches. The choice operator is
<em>right-associative</em>, and has strictly lower precedence than every
operator we have seen so far, including concatenation. In particular,
the regular expression <code>r?</code> is equivalent to <code>r | ""</code>.</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="pygments highlight"><code data-lang="jl"><span class="tok-c tok-c-Singleline">// Using the choice operator</span>
<span class="tok-nf">ident</span> <span class="tok-o">=</span> <span class="tok-nf">alpha</span> <span class="tok-p">(</span><span class="tok-nf">alpha</span> <span class="tok-o">|</span> <span class="tok-nf">digit</span> <span class="tok-o">|</span> <span class="tok-sc">&#39;_&#39;</span><span class="tok-p">)</span><span class="tok-o">*</span><span class="tok-p">;</span>
<span class="tok-nf">newline</span> <span class="tok-o">=</span> <span class="tok-sc">&#39;\</span><span class="tok-s">r</span><span class="tok-sc">&#39;</span> <span class="tok-o">|</span> <span class="tok-sc">&#39;\</span><span class="tok-s">n</span><span class="tok-sc">&#39;</span> <span class="tok-o">|</span> <span class="tok-s">&quot;\r\n&quot;</span><span class="tok-p">;</span>
<span class="tok-nf">r3</span> <span class="tok-o">=</span> <span class="tok-sc">&#39;a&#39;</span><span class="tok-o">|</span><span class="tok-sc">&#39;b&#39;&#39;c&#39;</span><span class="tok-p">;</span>  <span class="tok-c tok-c-Singleline">// a or bc</span>
<span class="tok-nf">r4</span> <span class="tok-o">=</span> <span class="tok-p">(</span><span class="tok-sc">&#39;a&#39;</span><span class="tok-o">|</span><span class="tok-sc">&#39;b&#39;</span><span class="tok-p">)</span><span class="tok-sc">&#39;c&#39;</span><span class="tok-p">;</span>  <span class="tok-c tok-c-Singleline">// ac or bc</span></code></pre>
</div>
</div>
</dd>
<dt class="hdlist1">Capturing groups</dt>
<dd>
<div class="paragraph">
<p>The <em>capture</em> operator <code>r <strong>as</strong> c</code> matches exactly like the regular
expression <code>r</code> but when successful, it also saves the part of the
input stream which it matched. The matched contents are then made
available in the semantic action of the corresponding clause as a
local variable with name <code>c</code>. Captures are very convenient when
the semantic action would otherwise need to extract some interesting
part of the matched input, potentially at the cost of rescanning
some of it.</p>
</div>
<div class="paragraph">
<p>The type of a capture variable depends on the captured regular
expression, and on the overall clause&#8217;s expression it appears in. It
can be either <code>String</code>, <code>char</code>, <code>Optional&lt;String&gt;</code> or
<code>Optional&lt;Character&gt;</code>. The <code>Optional</code> wrappers are introduced when the
overall regular expression can succeed without the captured regular
expression having matched at all, such as in <code>(r <strong>as</strong> c)?</code> or <code>(r1
<strong>as</strong> c) | r2</code>. Other than that, a capture variable is normally of type
<code>String</code>, unless it captures a regular expression which can only
statically match a <em>single</em> character (e.g. a character literal, a
character class, a wildcard or an alternation of any of those), in
which case its type is that of a Java character.</p>
</div>
<div class="exampleblock">
<div class="content">
<div class="paragraph">
<p>The rationale behind the fact that the type of capture variables
adapts to the regular expression is twofold:</p>
</div>
<div class="olist arabic">
<ol class="arabic">
<li>
<p>Using a simpler type such as <code>char</code> in comparison to <code>String</code>
enhances efficiency since no heap-allocation is required to capture
a single character. Moreover, captured groups are always assigned
before entering a clause&#8217;s semantic action, even if it is never
going to be used in the semantic action.</p>
</li>
<li>
<p>Wrapping optional captured groups with <code>java.util.Optional</code> goes
against raw efficiency instead, but for the very good reason of
making sure that semantic actions always use captured variables in a
way that is consistent with the associated clause. In particular,
using <code>null</code> or default values instead would make it very easy
for a developer to break a semantic action&#8217;s intended behaviour
by only slightly changing the associated regular expression.
With our approach, such a breaking change will normally result
in a type-checking error in the compiler.</p>
</li>
</ol>
</div>
</div>
</div>
<div class="paragraph">
<p>Dolmen does not enforce that a capture variable appears only
once in a clause&#8217;s regular expression. This allows for instance
patterns such as <code>(r1 <strong>as</strong> c) | (r2 <strong>as</strong> c)</code> where <code>c</code> can
then be handled in a uniform fashion in the semantic action.
The type of a capture variable which appears more than once
in a regular expression is simply the "simplest" type which
can accomodate all occurrences of the variable. For instance,
the capture variable can only have type <code>char</code> if all its
occurrences can have type <code>char</code>, and so on.</p>
</div>
<div class="listingblock">
<div class="title">Examples of captures in action</div>
<div class="content">
<pre class="pygments highlight"><code data-lang="jl"><span class="tok-c tok-c-Singleline">// North-American style phone number, capturing groups</span>
<span class="tok-nf">phone</span> <span class="tok-o">=</span> <span class="tok-p">(</span><span class="tok-nf">digit</span><span class="tok-p">&lt;</span><span class="tok-m">3</span><span class="tok-p">&gt;</span> <span class="tok-k">as</span> <span class="tok-nf">area</span><span class="tok-p">)</span> <span class="tok-sc">&#39;-&#39;</span> <span class="tok-p">(</span><span class="tok-nf">digit</span><span class="tok-p">&lt;</span><span class="tok-m">3</span><span class="tok-p">&gt;</span> <span class="tok-k">as</span> <span class="tok-nf">office</span><span class="tok-p">)</span> <span class="tok-sc">&#39;-&#39;</span> <span class="tok-p">(</span><span class="tok-nf">digit</span><span class="tok-p">&lt;</span><span class="tok-m">4</span><span class="tok-p">&gt;</span> <span class="tok-k">as</span> <span class="tok-nf">num</span><span class="tok-p">);</span>
<span class="tok-c tok-c-Singleline">// Markdown-style header, capturing the title</span>
<span class="tok-nf">header</span> <span class="tok-o">=</span> <span class="tok-sc">&#39;#&#39;</span><span class="tok-o">+</span> <span class="tok-nf">blanks</span> <span class="tok-p">([</span><span class="tok-o">^</span> <span class="tok-sc">&#39;\</span><span class="tok-s">r</span><span class="tok-sc">&#39;</span> <span class="tok-sc">&#39;\</span><span class="tok-s">n</span><span class="tok-sc">&#39;</span><span class="tok-p">]</span><span class="tok-o">+</span> <span class="tok-k">as</span> <span class="tok-nf">title</span><span class="tok-p">)</span> <span class="tok-nf">newline</span><span class="tok-p">;</span>
<span class="tok-c tok-c-Singleline">// GCC #line directive, capturing filename and line number</span>
<span class="tok-nf">linedir</span> <span class="tok-o">=</span> <span class="tok-s">&quot;#line&quot;</span> <span class="tok-nf">blanks</span> <span class="tok-p">(</span><span class="tok-nf">digit</span><span class="tok-o">+</span> <span class="tok-k">as</span> <span class="tok-nf">line</span><span class="tok-p">)</span> <span class="tok-nf">blanks</span> <span class="tok-p">(</span><span class="tok-nf">string</span> <span class="tok-k">as</span> <span class="tok-nf">filename</span><span class="tok-p">);</span>
<span class="tok-c tok-c-Singleline">// Java Unicode escape sequence, capturing the code unit value</span>
<span class="tok-nf">unicode</span> <span class="tok-o">=</span> <span class="tok-sc">&#39;\</span><span class="tok-s">\</span><span class="tok-sc">&#39;</span> <span class="tok-sc">&#39;u&#39;</span><span class="tok-o">+</span> <span class="tok-p">(</span><span class="tok-nf">hexcode</span> <span class="tok-k">as</span> <span class="tok-nf">code</span><span class="tok-p">);</span></code></pre>
</div>
</div>
<div class="paragraph">
<p>Even when a capture variable is bound only once in a regular
expression, it is possible that it is part of a repeated expression,
for instance <code>(r <strong>as</strong> c)&lt;2&gt;</code>, and can therefore be matched several
times during a single overall match. In such a case, the variable will
be bound to the contents that correspond to the last match. Similarly,
if the same capture variable appears nested in a captured group, such
as in <code>(r0 (r1 <strong>as</strong> c) r2) <strong>as</strong> c</code>, only the outermost occurrence can
ever find its way into the semantic action. The innermost captures are
actually optimized away very early by Dolmen, and do not even
contribute to the choice of the type associated to the variable <code>c</code>.</p>
</div>
<div class="paragraph">
<p>Finally, there may be cases where there is not a unique way of
matching the input stream with some regular expression, and that the
different ways would yield different captured contents. For instance,
consider matching the string <code>aaaaa</code> with the regular expression
<code>('a'&lt;2,3&gt; <strong>as</strong> i) ('a'&lt;2,3&gt; <strong>as</strong> j)</code>: there are two correct ways in
which <code>i</code> and <code>j</code> could be assigned. In such a case, which one is
produced by the Dolmen-generated lexical analyzer is left unspecified.</p>
</div>
</dd>
</dl>
</div>
<div class="paragraph">
<p>The following table summarizes the different regular expression
constructs in order of <strong>decreasing</strong> precedence, i.e. operators
appearing first bind tighter than those appearing later down
the table.</p>
</div>
<table id="Lexers_Regexps_Table" class="tableblock frame-all grid-all spread">
<caption class="title">Table 1. Regular expression operators</caption>
<colgroup>
<col style="width: 25%;">
<col style="width: 25%;">
<col style="width: 25%;">
<col style="width: 25%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Name</th>
<th class="tableblock halign-left valign-top">Syntax</th>
<th class="tableblock halign-left valign-top">Meaning</th>
<th class="tableblock halign-left valign-top">Associative</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Difference</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>r # s</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Matches the characters in <code>r</code> which are not in <code>s</code>.
  Both <code>r</code> and <code>s</code> must reduce to character classes.</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">No</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Option</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>r?</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Matches like <code>r</code>, or the empty string.</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">No</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Kleene star</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>r*</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Matches any number of repetitions of <code>r</code>.</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">No</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Kleene plus</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>r+</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Matches one or more number of repetitions of <code>r</code>.</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">No</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Repetition</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>r&lt;n&gt;</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Matches exactly <code>n</code> repetitions of <code>r</code>.</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">No</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Bounded repetition</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>r&lt;n, m&gt;</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Matches between <code>n</code> and <code>m</code> (inclusive) repetitions of <code>r</code>.</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">No</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Concatenation</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>r s</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Matches <code>r</code> first and then <code>s</code>.</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Right-associative</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Choice</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>r | s</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Matches either <code>r</code> or <code>s</code>.</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Right-associative</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Capture</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>r as c</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Matches like <code>r</code> but associates the matched part
  to a local variable named <code>c</code>.</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Left-associative</p></td>
</tr>
</tbody>
</table>
</div>
<div class="sect3">
<h4 id="Lexers_Semantic_Actions_Ref">Semantic Actions</h4>
<div class="paragraph">
<p>When a matching clause has been chosen by the lexing engine and the
corresponding prefix of the input consumed, the associated semantic
action is executed. The semantic action can be almost arbitrary Java
code, but must respect a few principles.</p>
</div>
<div class="olist arabic">
<ol class="arabic">
<li>
<p>The semantic action must be such that all paths are guaranteed
to adequately exit the control-flow, which means that every
execution path must end with either of the following:</p>
<div class="ulist">
<ul>
<li>
<p>a <code>return</code> statement, compatible with the declared
return type of the enclosing entry;</p>
</li>
<li>
<p>the throwing of an uncaught exception (preferably a
<a href="./javadoc/org/stekikun/dolmen/codegen/LexBuffer.LexicalError.html"><code>LexicalError</code></a>
exception);</p>
</li>
<li>
<p>a Java <code>continue lbl</code> statement to restart the current lexer
entry <code>lbl</code> without actually calling the Java method implementing
the entry (cf. <a href="#Lexers_Tail_Recursion_Ref">tail-recursion</a>);
this works because Dolmen always generates the code of a lexer
entry in a loop with a
<a href="https://docs.oracle.com/javase/specs/jls/se8/html/jls-14.html#jls-LabeledStatement">labeled statement</a>
whose label is exactly the name of the entry.</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>When this principle is not respected, the generated code may
contain errors or warnings, and the behaviour of the generated
lexical analyzer is not predictable.</p>
</div>
</li>
<li>
<p>The generated lexer is a subclass of the
<a href="./javadoc/org/stekikun/dolmen/codegen/LexBuffer.html"><code>LexBuffer</code></a> class from the Dolmen
runtime, and as such has access to a number of fields and methods
inherited from <code>LexBuffer</code>. Some of these fields and methods are
provided primarily for use by user code in semantic actions, whereas
others deal with the internal functionality of the lexing engine and
should <strong>not</strong> be called or tampered with in semantic actions. The
reader may wonder why these fields and methods which are reserved for
internal use are declared as <code>protected</code>; they cannot be made
<code>private</code> in <code>LexBuffer</code> because they must be accessed from the
code of the subclass generated by Dolmen itself.</p>
<div class="paragraph">
<p>In order to document which protected members are intended for user
code and which are off limits, the
<a href="./javadoc/org/stekikun/dolmen/codegen/DolmenInternal.html"><code>DolmenInternal</code></a> annotation has
been introduced and is used to annotate every member which is declared
as <code>protected</code> but should not be accessed from user code (i.e. either
from semantic actions or from the prelude and postlude).  As a
refinement, a field can be annotated with <code>@DolmenInternal(read = true)</code>
in which case access to the field from user code is tolerated as long
as the value is not modified. In this context, "modifying" a field
encompasses both modifying the field itself, and in the case the field
is a reference object, modifying the actual value of the referred object
without changing the reference itself. For instance, the following
declaration is possible:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="pygments highlight"><code data-lang="java"><span class="tok-nd">@DolmenInternal</span><span class="tok-o">(</span><span class="tok-n">read</span> <span class="tok-o">=</span> <span class="tok-kc">true</span><span class="tok-o">)</span>
<span class="tok-kd">protected</span> <span class="tok-kd">final</span> <span class="tok-n">Set</span><span class="tok-o">&lt;</span><span class="tok-n">Integer</span><span class="tok-o">&gt;</span> <span class="tok-n">numbers</span><span class="tok-o">;</span></code></pre>
</div>
</div>
<div class="paragraph">
<p>It signifies that <code>numbers</code> can be read from user code&#8212;&#8203;the field
itself cannot be modified as it is final anyway&#8212;&#8203;but only methods
which do not change the contents of <code>numbers</code> should be allowed.  As
the Java language lacks a proper notion of <code>const</code>-ness, it cannot be
expressed in method signatures whether they observationally change
their receiver&#8217;s state or not so one must rely on documentation and
common sense in practice.</p>
</div>
<div class="paragraph">
<p>When internal members are used in semantic actions, the lexical
analyzer may behave unexpectedly as this can break some of the
internal invariants it relies on. Even if things seem to work fine,
such code can be broken by a future Dolmen update.</p>
</div>
</li>
</ol>
</div>
<div class="paragraph">
<p>We conclude this section on semantic actions with an exhaustive
presentation of the fields and methods from
<a href="./javadoc/org/stekikun/dolmen/codegen/LexBuffer.html"><code>LexBuffer</code></a> which are available for use
in semantic actions. One can always refer to the Javadoc associated
to these members, either via the <a href="./javadoc/org/stekikun/dolmen/codegen/LexBuffer.html">HTML pages</a>
or using your IDE when accessing the Dolmen runtime.</p>
</div>
<div class="dlist">
<dl>
<dt class="hdlist1">Input position</dt>
<dd>
<p>The following members available in semantic actions relate
to the management of the input position.</p>
<div class="openblock">
<div class="content">
<div class="dlist">
<dl>
<dt class="hdlist1"><span class="image"><img src="./images/field_protected_obj.png" alt="field protected obj" title="protected field"></span> <code>String filename</code></dt>
<dd>
<p>This field contains the <em>name</em> of the current input
being analyzed by the lexing engine. Despite the field&#8217;s name,
this name need not be an actual filename, it is only used in
positions and error reporting.<br>
It is not final as it may be
changed for instance when handling a GCC-like <code>#line</code>
directive.</p>
</dd>
<dt class="hdlist1"><span class="image"><img src="./images/field_protected_obj.png" alt="field protected obj" title="protected field"></span> <code>Position startLoc</code></dt>
<dd>
<p>This field contains the starting position of the current lexeme.<br>
It can be modified before returning from a semantic action, e.g.
for adjusting <a href="#Lexers_Token_Locations">token locations</a> when
the lexical analyzer is used by a parser.</p>
</dd>
<dt class="hdlist1"><span class="image"><img src="./images/field_protected_obj.png" alt="field protected obj" title="protected field"></span> <code>Position curLoc</code></dt>
<dd>
<p>This field contains the ending position of the current lexeme,
i.e. the position of the first character that <em>follows</em> the
lexeme.<br>
It can be modified before returning from a semantic action, e.g.
for adjusting <a href="#Lexers_Token_Locations">token locations</a> when
the lexical analyzer is used by a parser.</p>
</dd>
<dt class="hdlist1"><span class="image"><img src="./images/methpro_obj.png" alt="methpro obj" title="protected method"></span> <code>void newline()</code></dt>
<dd>
<p>Modifies the internal line and column counter to account
for the consumption of a line terminator. This needs to be
called in semantic actions accordingly if one wants to keep
correct track of lines and columns.</p>
</dd>
<dt class="hdlist1"><span class="image"><img src="./images/methpro_obj.png" alt="methpro obj" title="protected method"></span> <code>&lt;T&gt; T saveStart(Supplier&lt;T&gt; s)</code></dt>
<dd>
<p>This convenience method calls the given supplier <code>s</code>, returning
the same value as ̀s`, but saving the current value of <code>startLoc</code>
before the call and restoring it afterwards. This is used when
<a href="#Lexers_Nested_Rules">nested rules</a> are used to parse a token
and the token location needs to be adjusted.</p>
</dd>
<dt class="hdlist1"><span class="image"><img src="./images/methpro_obj.png" alt="methpro obj" title="protected method"></span> <code>&lt;T&gt; T savePosition(Supplier&lt;T&gt; s, Position start)</code></dt>
<dd>
<p>This convenience method calls the given supplier <code>s</code>, returning
the same value as ̀s`, but setting the value of <code>startLoc</code> to
<code>start</code> afterwards. This is used when
<a href="#Lexers_Nested_Rules">nested rules</a> are used to parse a token
and the token location needs to be adjusted.</p>
</dd>
<dt class="hdlist1"><span class="image"><img src="./images/methpro_obj.png" alt="methpro obj" title="protected method"></span> <code>void saveStart(Runnable r)</code></dt>
<dd>
<p>This convenience method calls the given runnable <code>r</code>, saving
the current value of <code>startLoc</code> before the call and restoring
it afterwards. This is used when
<a href="#Lexers_Nested_Rules">nested rules</a> are used to parse a token
and the token location needs to be adjusted.</p>
</dd>
<dt class="hdlist1"><span class="image"><img src="./images/methpro_obj.png" alt="methpro obj" title="protected method"></span> <code>void savePosition(Runnable r, Position start)</code></dt>
<dd>
<p>This convenience method calls the given runnable <code>r</code> and sets
the value of <code>startLoc</code> to <code>start</code> afterwards. This is used when
<a href="#Lexers_Nested_Rules">nested rules</a> are used to parse a token
and the token location needs to be adjusted.</p>
</dd>
</dl>
</div>
</div>
</div>
</dd>
<dt class="hdlist1">Lexeme</dt>
<dd>
<p>The following members available in semantic actions relate
to the retrieval of the last matched lexeme. They all refer
to the part of the input which was last matched by a lexer
clause; in the case where there have been calls to a
<a href="#Lexers_Nested_Rules">nested rule</a>, these methods will return
information relevant to the last matched clause, and not to
the lexeme which was matched by the clause of the <em>current</em>
semantic action.</p>
<div class="openblock">
<div class="content">
<div class="dlist">
<dl>
<dt class="hdlist1"><span class="image"><img src="./images/methpub_obj.png" alt="methpub obj" title="public method"></span> <code>String getLexeme()</code></dt>
<dd>
<p>Returns the last matched lexeme.</p>
</dd>
<dt class="hdlist1"><span class="image"><img src="./images/methpub_obj.png" alt="methpub obj" title="public method"></span> <code>Position getLexemeStart()</code></dt>
<dd>
<p>Returns the starting position of the last matched lexeme.</p>
</dd>
<dt class="hdlist1"><span class="image"><img src="./images/methpub_obj.png" alt="methpub obj" title="public method"></span> <code>Position getLexemeEnd()</code></dt>
<dd>
<p>Returns the end position of the last matched lexeme. By convention,
this is the position of the first character that <em>follows</em> the
lexeme.</p>
</dd>
<dt class="hdlist1"><span class="image"><img src="./images/methpub_obj.png" alt="methpub obj" title="public method"></span> <code>int getLexemeLength()</code></dt>
<dd>
<p>Returns the length of the last matched lexeme.</p>
</dd>
<dt class="hdlist1"><span class="image"><img src="./images/methpub_obj.png" alt="methpub obj" title="public method"></span> <code>char getLexemeChar(int idx)</code></dt>
<dd>
<p>Returns the character at index <code>idx</code> in the last matched lexeme.
The index is 0-based, and must be between 0 (inclusive) and
<code>getLexemeLength()</code> (exclusive).</p>
</dd>
<dt class="hdlist1"><span class="image"><img src="./images/methpub_obj.png" alt="methpub obj" title="public method"></span> <code>CharSequence getLexemeChars()</code></dt>
<dd>
<p>Returns the contents of the last matched lexeme as a character
sequence. The character sequence refers to the current internal
state of the lexing engine and becomes unspecified after
<a href="#Lexers_Nested_Rules">nested rule calls</a>, even if it was retrieved
before any nested call.</p>
</dd>
<dt class="hdlist1"><span class="image"><img src="./images/methpub_obj.png" alt="methpub obj" title="public method"></span> <code>void appendLexeme(StringBuilder buf)</code></dt>
<dd>
<p>Appends the contents of the last matched lexeme to the
given buffer <code>buf</code>.</p>
</dd>
</dl>
</div>
</div>
</div>
</dd>
<dt class="hdlist1">Input management</dt>
<dd>
<p>The following members available in semantic actions
relate to the management of the input stream during a lexical
analysis. The lexing engine supports switching input streams
in the middle of an analysis, and can manage an <em>input stack</em>
to let users implement inclusion directives like GCC&#8217;s <code>#include</code>
or TeX&#8217;s <code>\input</code>.</p>
<div class="openblock">
<div class="content">
<div class="dlist">
<dl>
<dt class="hdlist1"><span class="image"><img src="./images/methpro_obj.png" alt="methpro obj" title="protected method"></span> <code>void changeInput(String fn, Reader reader)</code></dt>
<dd>
<p>This closes the current input stream and switches to the new
input specified by <code>reader</code> and whose display name will be <code>fn</code>.</p>
</dd>
<dt class="hdlist1"><span class="image"><img src="./images/methpro_obj.png" alt="methpro obj" title="protected method"></span> <code>void pushInput(String fn, Reader reader)</code></dt>
<dd>
<p>This pushes the current input stream on the input stack and
start consuming the given <code>reader</code> instead. The stacked
input stream can be resumed with <code>popInput()</code>.</p>
</dd>
<dt class="hdlist1"><span class="image"><img src="./images/methpro_obj.png" alt="methpro obj" title="protected method"></span> <code>boolean hasMoreInput()</code></dt>
<dd>
<p>This returns whether the current stream is the last one
remaining in the input stack. In other words, only when
this method returns <code>true</code> can <code>popInput()</code> be used.</p>
</dd>
<dt class="hdlist1"><span class="image"><img src="./images/methpro_obj.png" alt="methpro obj" title="protected method"></span> <code>void popInput()</code></dt>
<dd>
<p>This closes the current stream and resumes the last one
which was pushed to the stack. Whether the stack is
empty or not can be checked beforehand with <code>hasMoreInput</code>.</p>
</dd>
</dl>
</div>
</div>
</div>
</dd>
<dt class="hdlist1">Error management</dt>
<dd>
<p>The following members available in semantic actions
relate to error management during a lexical analysis.</p>
<div class="openblock">
<div class="content">
<div class="dlist">
<dl>
<dt class="hdlist1"><span class="image"><img src="./images/methpro_obj.png" alt="methpro obj" title="protected method"></span> <code>LexicalError error(String msg)</code></dt>
<dd>
<p>Returns a <a href="./javadoc/org/stekikun/dolmen/codegen/LexBuffer.LexicalError.html"><code>LexicalError</code></a> exception
with the given message string and reported at the current lexer position.
This is the preferred way of reporting lexical errors in semantic actions.
Note that unlike the other methods here, <code>error</code> is not final: it can be
overriden so that one can for instance customize the way the error message
is built and presented. In particular it could be internationalized if need be.</p>
</dd>
<dt class="hdlist1"><span class="image"><img src="./images/methpro_obj.png" alt="methpro obj" title="protected method"></span> <code>char peekNextChar()</code></dt>
<dd>
<p>Returns the character which directly follows the last matched lexeme in
the input stream, or 0xFFFF if end-of-input has been reached. This can be
used to produce better error messages, or in some cases where a semantic
action needs to look ahead at the stream without consuming it to decide
what should be done.</p>
</dd>
<dt class="hdlist1"><span class="image"><img src="./images/methpro_obj.png" alt="methpro obj" title="protected method"></span> <code>int peekNextChars(char[] buf)</code></dt>
<dd>
<p>Copies the characters which directly follow the last matched lexeme in
the input stream to <code>buf</code>, and returns the number of characters actually
copied. This can be used to produce better error messages, or in some cases
where a semantic action needs to look ahead at the stream without consuming
it to decide what should be done.</p>
</dd>
</dl>
</div>
</div>
</div>
</dd>
</dl>
</div>
</div>
<div class="sect3">
<h4 id="Lexers_Wildcards">Understanding <code>eof</code>, <code>_</code> and <code>orelse</code></h4>
<div class="paragraph">
<p>In this section, we discuss the meaning of the special regular
expressions <code>eof</code> and <code>_</code>, which can sometimes be confusing, as well
as the special <code>orelse</code> keyword which can be used to introduce a
"catch-everything-else" clause in a lexer entry.</p>
</div>
<div class="dlist">
<dl>
<dt class="hdlist1">End-of-input</dt>
<dd>
<p>As explained <a href="#Lexers_Regular_Expressions">above</a>, <code>eof</code> is a special
regular expression literal which matches when the input stream has
been exhausted. It actually represents the single meta-character
<code>\uFFFF</code>, which is used internally to represent the end-of-input and
is not a valid escaping sequence in character or string literals.
Even if <code>eof</code> is internally encoded as a character, it does not behave
as a character:</p>
<div class="ulist">
<ul>
<li>
<p>matching <code>eof</code> does not <em>consume</em> any character from the input
stream, it simply checks that the end of the input stream has
indeed been reached; therefore it always matches an empty
input string, whereas regular characters always match an input
of size 1;</p>
</li>
<li>
<p>because it does not consume anything, <code>eof</code> has some rather
exotic properties when it comes to regular expressions;
for instance, <code>eof</code> and <code>eof+</code> are completely equivalent;</p>
</li>
<li>
<p><code>eof</code> is not considered as a regular expression which reduces to a
character class; hence it is not possible to use <code>eof</code> in a
character set difference operation <code>.. # ..</code>, or inside a character
class <code>[.. eof ..]</code>;</p>
</li>
<li>
<p>finally, even though <code>eof</code> stands for the end of the input stream,
any regular expression which matches the empty string can still
match after <code>eof</code>, e.g. <code>eof ""</code>, <code>eof ("" as c)</code> or even <code>eof
("foo"?)</code> will all successfully match the empty string <code>""</code>.</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>All in all, writing complex regular expressions using <code>eof</code> should be
really uncommon. As a rule of thumb, <code>eof</code> is usually best used all by
itself in a clause, as the end-of-input normally calls for some ad hoc
action, in particular in terms of <a href="#Lexers_Error_Reports">error
reporting</a>.</p>
</div>
</dd>
<dt class="hdlist1">Wildcard</dt>
<dd>
<p>The wildcard <code>_</code> is a regular expression which can match any valid
character. It is actually equivalent to the character class
<code>['\u0000' - '\uFFFE']</code>, and in particular <strong>excludes</strong> the end-of-input
meta-character. Therefore, <code>_</code> will behave in an expected way,
consuming exactly one character of the input stream, much like <code>.</code> in
many common regular expression engines.</p>
<div class="paragraph">
<p>What sometimes causes confusion is that <code>_</code> is not sufficient when
trying to write a default clause to catch any unexpected character for
instance:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="pygments highlight"><code data-lang="jl"><span class="tok-o">|</span> <span class="tok-nf">_</span> <span class="tok-k">as</span> <span class="tok-nf">c</span> <span class="tok-g">{ </span><span class="tok-ge">throw</span><span class="tok-g"> error(</span><span class="tok-gs">&quot;Unexpected character: &quot;</span><span class="tok-g"> + c); }</span></code></pre>
</div>
</div>
<div class="paragraph">
<p>This will catch any actual unexpected character but will still leave
<code>eof</code> unhandled&#8212;&#8203;and if so, this will be reported by Dolmen as a
warning for a potentially incomplete lexer entry. It is possible to
match <code>(_ | eof) as c</code> or <code>(_ as c) | eof</code> of course, but whereas <code>c</code>
in the clause above had type <code>char</code>, <code>c</code> in the latter examples would
be an <code>Optional&lt;Character&gt;</code> which means the semantic action will not
handle both cases in a uniform manner anyway. It is usually simpler to
just have another clause dedicated to <code>eof</code>.</p>
</div>
<div class="paragraph">
<p>Note that for the same reason that <code>_</code> only matches actual non
end-of-input characters, the character class complement operation
<code>[^&#8230;&#8203;]</code> only contains characters in the 0x0000-0xFFFE range. In
other words, the complement <code>[^ cset ]</code> of some character set
is actually equivalent to <code>_ # [cset]</code>.</p>
</div>
</dd>
<dt class="hdlist1">Clause <code>orelse</code></dt>
<dd>
<p>The keyword <code>orelse</code> can be used in place of a regular expression to
introduce a special form of clause:</p>
<div class="listingblock">
<div class="content">
<pre class="pygments highlight"><code data-lang="jl"><span class="tok-o">|</span> <span class="tok-k">orelse</span>  <span class="tok-g">{ ... }</span></code></pre>
</div>
</div>
<div class="paragraph">
<p>The meaning of the <code>orelse</code> pattern depends on the context in which it
is used, namely of the other clauses declared before in the same lexer
entry. Its purpose is to match the longest possible prefix of input
which could not possibly match any of the other clauses above.</p>
</div>
<div class="paragraph">
<p>More precisely, suppose <code>orelse</code> is preceded by <em>n</em> clauses with
respective regular expressions <code>r1</code>, &#8230;&#8203; <code>rn</code>; the regular expression
that <code>orelse</code> will denote is computed as follows:</p>
</div>
<div class="openblock">
<div class="content">
<div class="olist arabic">
<ol class="arabic">
<li>
<p>For each <code>ri</code>, compute the character set <code>Ci</code> of the characters
which can start a match of <code>ri</code>. This character set can easily
be computed by induction on the regular expression; for instance,
it is the first character of the string for a string literal,
the union of the first characters of <code>s</code> and <code>t</code> for a choice
expression <code>s | t</code>, and so on.</p>
</li>
<li>
<p>Compute the union <code>C</code> of all the character sets <code>Ci</code>, i.e. the set
of all the characters which can start a match of any of the <code>ri</code>.</p>
</li>
<li>
<p>Then, <code>orelse</code> will represent the regular expression <code>[^C]+</code>,
i.e. it will match any non-empty number of characters which
cannot start any of the <code>ri</code>.</p>
</li>
</ol>
</div>
</div>
</div>
<div class="paragraph">
<p>An <code>orelse</code> clause is useful when one is only interested in
recognizing certain patterns, but can pass over the rest of the
input without having to interpret it. Consider for instance
a lexer entry <code>mlcomment</code> which is entered when starting
a (possibly multi-line) comment <code>/* &#8230;&#8203; */</code> and which must
match until the end of the comment:</p>
</div>
<div class="listingblock">
<div class="title">An entry for multi-line comments</div>
<div class="content">
<pre class="pygments highlight"><code data-lang="jl"><span class="tok-k">private</span> <span class="tok-g">{ </span><span class="tok-ge">void</span><span class="tok-g"> }</span> <span class="tok-k">rule</span> <span class="tok-nf">mlcomment</span> <span class="tok-o">=</span>
<span class="tok-o">|</span> <span class="tok-s">&quot;*/&quot;</span>    <span class="tok-g">{ </span><span class="tok-ge">return</span><span class="tok-g">; }</span>
<span class="tok-o">|</span> <span class="tok-nf">newline</span> <span class="tok-g">{ newline(); </span><span class="tok-ge">continue</span><span class="tok-g"> mlcomment; }</span>
<span class="tok-o">|</span> <span class="tok-k">eof</span>     <span class="tok-g">{ </span><span class="tok-ge">throw</span><span class="tok-g"> error(</span><span class="tok-gs">&quot;Unterminated comment&quot;</span><span class="tok-g">); }</span>
<span class="tok-o">|</span> ...</code></pre>
</div>
</div>
<div class="paragraph">
<p>where <code>newline</code> is defined as <code>('\r' | '\n' | "\r\n")</code>.  As it is, the
entry recognizes the closing comment delimiter and also handles line
breaks and end-of-input gracefully. It still needs to be able to pass
everything else that the comment can contains. One correct way to do
that is to use a wildcard to catch everything else:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="pygments highlight"><code data-lang="jl">...
<span class="tok-o">|</span> <span class="tok-nf">_</span>     <span class="tok-g">{ </span><span class="tok-ge">continue</span><span class="tok-g"> mlcomment; }</span></code></pre>
</div>
</div>
<div class="paragraph">
<p>In particular this works because by the longest-match rule, it will not
match a <code>*</code> character if it happens to be followed by a <code>\</code>. Unfortunately,
reentering the rule at every character is somewhat inefficient in comparison
to matching largest parts of the comment at once; indeed, every time a
rule is entered or reentered, the generated lexical analyzer performs some
minor bookkeeping regarding the current lexeme&#8217;s positions. To pass as much
of the comment&#8217;s contents as we possibly can in one go, we can use an ad-hoc
regular expression like the following:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="pygments highlight"><code data-lang="jl">...
<span class="tok-o">|</span> <span class="tok-p">[</span><span class="tok-o">^</span><span class="tok-sc">&#39;*&#39;</span> <span class="tok-sc">&#39;\</span><span class="tok-s">r</span><span class="tok-sc">&#39;</span> <span class="tok-sc">&#39;\</span><span class="tok-s">n</span><span class="tok-sc">&#39;</span><span class="tok-p">]</span><span class="tok-o">+</span>     <span class="tok-g">{ </span><span class="tok-ge">continue</span><span class="tok-g"> mlcomment; }</span></code></pre>
</div>
</div>
<div class="paragraph">
<p>The issue with this is twofold:</p>
</div>
<div class="openblock">
<div class="content">
<div class="olist arabic">
<ol class="arabic">
<li>
<p>On one hand, it is fragile as it relies on correctly listing
all characters which are of interest to the other clauses in
the rule. Should we forget one of them, the Kleene <code>+</code> operator
and the longest-match rule will conspire to make sure our entry
does not work as intended. Also, this must be maintained when
adding new patterns to the rule.</p>
</li>
<li>
<p>On the other hand, it still does not cover the case of <code>*</code>
characters which are not followed by a <code>/</code>. One could of course
fix the regular expression like this:</p>
<div class="listingblock">
<div class="content">
<pre class="pygments highlight"><code data-lang="jl">...
<span class="tok-o">|</span> <span class="tok-p">([</span><span class="tok-o">^</span><span class="tok-sc">&#39;*&#39;</span> <span class="tok-sc">&#39;\</span><span class="tok-s">r</span><span class="tok-sc">&#39;</span> <span class="tok-sc">&#39;\</span><span class="tok-s">n</span><span class="tok-sc">&#39;</span><span class="tok-p">]</span><span class="tok-o">+</span> <span class="tok-o">|</span> <span class="tok-sc">&#39;*&#39;</span><span class="tok-o">+</span><span class="tok-p">[</span><span class="tok-o">^</span><span class="tok-sc">&#39;/&#39;</span> <span class="tok-sc">&#39;*&#39;</span><span class="tok-p">])</span><span class="tok-o">+</span>  <span class="tok-g">{ </span><span class="tok-ge">continue</span><span class="tok-g"> mlcomment; }</span></code></pre>
</div>
</div>
<div class="paragraph">
<p>but this would definitely make the first issue even more pregnant
(Hint: incidentally, this regular expression is still not good
enough!).</p>
</div>
</li>
</ol>
</div>
</div>
</div>
<div class="paragraph">
<p>Reliability and reviewability are design principles in Dolmen, and the
<code>orelse</code> clause was brought up precisely to bring an elegant solution
for such a case. Using <code>orelse</code> here will be equivalent to <code>[^'*' '\r'
'\n']+</code> but in a much less error-prone way:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="pygments highlight"><code data-lang="jl"><span class="tok-k">private</span> <span class="tok-g">{ </span><span class="tok-ge">void</span><span class="tok-g"> }</span> <span class="tok-k">rule</span> <span class="tok-nf">mlcomment</span> <span class="tok-o">=</span>
<span class="tok-o">|</span> <span class="tok-s">&quot;*/&quot;</span>    <span class="tok-g">{ </span><span class="tok-ge">return</span><span class="tok-g">; }</span>
<span class="tok-o">|</span> <span class="tok-nf">newline</span> <span class="tok-g">{ newline(); </span><span class="tok-ge">continue</span><span class="tok-g"> mlcomment; }</span>
<span class="tok-o">|</span> <span class="tok-k">eof</span>     <span class="tok-g">{ </span><span class="tok-ge">throw</span><span class="tok-g"> error(</span><span class="tok-gs">&quot;Unterminated comment&quot;</span><span class="tok-g">); }</span>
<span class="tok-o">|</span> <span class="tok-sc">&#39;*&#39;</span>     <span class="tok-g">{ </span><span class="tok-ge">continue</span><span class="tok-g"> mlcomment; }</span>
<span class="tok-o">|</span> <span class="tok-k">orelse</span>  <span class="tok-g">{ </span><span class="tok-ge">continue</span><span class="tok-g"> mlcomment; }</span></code></pre>
</div>
</div>
<div class="paragraph">
<p>Of course, lonely <code>*</code> characters still need to be singled out but this
is reasonably simple. One can even switch the last two clauses around
and use a wildcard:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="pygments highlight"><code data-lang="jl"><span class="tok-k">private</span> <span class="tok-g">{ </span><span class="tok-ge">void</span><span class="tok-g"> }</span> <span class="tok-k">rule</span> <span class="tok-nf">mlcomment</span> <span class="tok-o">=</span>
...
<span class="tok-o">|</span> <span class="tok-k">orelse</span>  <span class="tok-g">{ </span><span class="tok-ge">continue</span><span class="tok-g"> mlcomment; }</span>
<span class="tok-o">|</span> <span class="tok-nf">_</span>       <span class="tok-g">{ </span><span class="tok-ge">continue</span><span class="tok-g"> mlcomment; }</span></code></pre>
</div>
</div>
<div class="paragraph">
<p>Writing the entry this way will make maintenance really
straightforward. For instance, suppose we want to start
allowing nested <code>/* &#8230;&#8203; */</code> comments, this can be achieved
by keeping track of the current comment "depth" in a local
field and add a clause to handle opening delimiters:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="pygments highlight"><code data-lang="jl"><span class="tok-k">private</span> <span class="tok-g">{ </span><span class="tok-ge">void</span><span class="tok-g"> }</span> <span class="tok-k">rule</span> <span class="tok-nf">mlcomment</span> <span class="tok-o">=</span>
<span class="tok-o">|</span> <span class="tok-s">&quot;*/&quot;</span>    <span class="tok-g">{ </span><span class="tok-ge">if</span><span class="tok-g"> (--depth == 0) </span><span class="tok-ge">return</span><span class="tok-g">; </span><span class="tok-ge">continue</span><span class="tok-g"> mlcomment; }</span>
<span class="tok-o">|</span> <span class="tok-s">&quot;/*&quot;</span>    <span class="tok-g">{ ++depth; </span><span class="tok-ge">continue</span><span class="tok-g"> mlcomment; }</span>
<span class="tok-o">|</span> <span class="tok-nf">newline</span> <span class="tok-g">{ newline(); </span><span class="tok-ge">continue</span><span class="tok-g"> mlcomment; }</span>
<span class="tok-o">|</span> <span class="tok-k">eof</span>     <span class="tok-g">{ </span><span class="tok-ge">throw</span><span class="tok-g"> error(</span><span class="tok-gs">&quot;Unterminated comment&quot;</span><span class="tok-g">); }</span>
<span class="tok-o">|</span> <span class="tok-k">orelse</span>  <span class="tok-g">{ </span><span class="tok-ge">continue</span><span class="tok-g"> mlcomment; }</span>
<span class="tok-o">|</span> <span class="tok-nf">_</span>       <span class="tok-g">{ </span><span class="tok-ge">continue</span><span class="tok-g"> mlcomment; }</span></code></pre>
</div>
</div>
<div class="paragraph">
<p>The benefit of using <code>orelse</code> and a wildcard instead of complex
hand-crafted expressions is immediately apparent, as this is all that
we have to do to handle nested comments in our entry. <code>orelse</code> will
now take care of not consuming <code>/</code> characters, whereas the wildcard
will deal with <code>/</code> characters that are not followed by a <code>*</code>.</p>
</div>
<div class="paragraph">
<p>Note that as in the example above, the <code>orelse</code> clause need not
be the last one in the entry, it will simply depend on the clauses
defined above. It is even syntactically possible to have more than
one <code>orelse</code> clause in an entry, although all such extra clauses
will be shadowed by the first one by construction.</p>
</div>
</dd>
</dl>
</div>
</div>
<div class="sect3">
<h4 id="Lexers_Options">Lexer Options</h4>
<div class="paragraph">
<p>The lexical analyzer generator accepts some options which can
be specified right at the top of a lexer description, with
the following syntax:</p>
</div>
<div class="listingblock">
<div class="title">Syntax for configuration options</div>
<div class="content">
<pre class="pygments highlight"><code data-lang="jl"><span class="tok-p">[</span><span class="tok-nf">key1</span> <span class="tok-o">=</span> <span class="tok-s">&quot;value1&quot;</span><span class="tok-p">]</span>
<span class="tok-p">[</span><span class="tok-nf">key2</span> <span class="tok-o">=</span> <span class="tok-s">&quot;value2&quot;</span><span class="tok-p">]</span>
...</code></pre>
</div>
</div>
<div class="paragraph">
<p>A configuration option given as a key-value pair where the
key identifies the option being set, and the value is a
string literal. Unlike string literals in regular expressions,
option values can be multi-line string literals.</p>
</div>
<div class="paragraph">
<p>In the following, we list the different configuration options
available in lexer descriptions and document their effect.</p>
</div>
<div class="dlist">
<dl>
<dt class="hdlist1">class_annnotations</dt>
<dd>
<p>The <code>class_annotations</code> option lets one specify arbitrary annotations
that will be added on the class generated by the lexical
analyzer. Indeed, a lexer description will result in the generation of
a single public class extending the <a href="./javadoc/org/stekikun/dolmen/codegen/LexBuffer.html">base
lexing buffer class</a> from the Dolmen runtime.</p>
<div class="paragraph">
<p>This can be useful in particular to add particular instances of
<code>@SuppressWarnings(&#8230;&#8203;)</code> annotations. Dolmen tries very hard to
generate code without warnings&#8212;&#8203;not counting warnings from the
semantic actions of course, at least for a reasonable default
configuration of the Java compiler. When working in a project with
stronger requirements, generated classes may have warnings and the
<code>class_annotations</code> option can be used to explicitly ignore these
warnings. For instance, to suppress warnings on missing Java
documentation in the generated lexer, one can use:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="pygments highlight"><code data-lang="jl"><span class="tok-p">[</span><span class="tok-nf">class_annotations</span> <span class="tok-o">=</span> <span class="tok-s">&quot;@SuppressWarnings(\&quot;javadoc\&quot;)&quot;</span><span class="tok-p">]</span></code></pre>
</div>
</div>
<div class="paragraph">
<p>When referencing an annotation from another package, make sure it is
fully qualified or add the corresponding import to the imports section
of the lexer description, so that the annotation can be resolved in
the generated Java compilation unit. For instance, when working in a
project which uses the
<a href="https://help.eclipse.org/2019-12/index.jsp?topic=%2Forg.eclipse.jdt.doc.user%2Ftasks%2Ftask-using_null_annotations.htm">Eclipse
JDT null analysis</a>, one may need something like this:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="pygments highlight"><code data-lang="jl"><span class="tok-p">[</span><span class="tok-nf">class_annotations</span> <span class="tok-o">=</span> <span class="tok-s">&quot;@org.eclipse.jdt.annotation.NonNullByDefault&quot;</span><span class="tok-p">]</span></code></pre>
</div>
</div>
<div class="paragraph">
<p>as Dolmen is implemented with the full null analysis enabled and uses
a non-null type default policy.</p>
</div>
</dd>
</dl>
</div>
</div>
<div class="sect3">
<h4 id="Lexers_CLI">Command Line Interface</h4>
<div class="paragraph">
<p>The Dolmen runtime is an executable Java archive which can be used as
a command-line tool to generate a lexical analyzer from a lexer
description. Another way of using Dolmen is via the companion
<a href="https://dolmenplugin.stekikun.org">Eclipse plug-in</a>; nonetheless, the
command line is useful in a variety of scenarios like building
scripts, Makefile, continuous integration, etc.</p>
</div>
<div class="paragraph">
<p>The command line interface can be invoked as follows:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="pygments highlight"><code data-lang="console"><span class="tok-gp">$</span> java -jar Dolmen_1.0.0.jar -l ..options.. <span class="tok-nb">source</span></code></pre>
</div>
</div>
<div class="paragraph">
<p>where <code>source</code> is the name of the source lexer description. The <code>-l</code>
option instructs Dolmen that the source is a lexer description and that
a lexical analyzer should be generated. The <code>-l</code> flag can be omitted
if the source file has the <code>.jl</code> extension. The other available
command line options are detailed in the following table.</p>
</div>
<table class="tableblock frame-all grid-all spread">
<caption class="title">Table 2. Command line options</caption>
<colgroup>
<col style="width: 25%;">
<col style="width: 25%;">
<col style="width: 25%;">
<col style="width: 25%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Name</th>
<th class="tableblock halign-left valign-top">Type</th>
<th class="tableblock halign-left valign-top">Default</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>-h/--help</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Flag</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">No</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Displays help about command line usage.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>-q/--quiet</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Flag</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">No</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Quiet mode: suppresses all output except for error report.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>-l/--lexer</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Flag</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">No</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Generates a lexical analyzer from the source file.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>-o/--output</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">String</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Working directory</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Output directory for the generated class.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>-c/--class</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">String</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Name of the source file</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Name of the generated class.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>-p/--package</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">String</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><strong>Required</strong></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Name of the package for the generated class.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>-r/--reports</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">String</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Name of the source file + <code>.reports</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">No</p></td>
</tr>
</tbody>
</table>
<div class="paragraph">
<p>String options must follow the option name directly, e.g.  <code>-o mydir
--class Foo</code> instructs Dolmen to generate the class <code>Foo.java</code> in the
<code>mydir</code> directory.  Flag values in their short form can be grouped
together. For instance, <code>-lq</code> instructs Dolmen to generate a lexical
analyzer in quiet mode. <strong>Note that the <code>--package/-p</code> option is
required:</strong> the generated class will be declared in the given package,
and Dolmen does not support generating classes in the <em>default</em>
package.</p>
</div>
<div class="exampleblock">
<div class="title">Example 1</div>
<div class="content">
<div class="paragraph">
<p>The following command will generate a lexical analyzer in
<code>src/foo/bar/MyLexer.java</code>, in the package <code>foo.bar</code>.
Only errors will be reported on the standard output, other
reports will be in <code>MyLexer.jl.reports</code>.</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="pygments highlight"><code data-lang="console"><span class="tok-gp">$</span> java -jar Dolmen_1.0.0.jar -q -p foo.bar -o src/foo/bar MyLexer.jl</code></pre>
</div>
</div>
</div>
</div>
<div class="exampleblock">
<div class="title">Example 2</div>
<div class="content">
<div class="paragraph">
<p>The following command will generate a lexical analyzer in
<code>src/foo/bar/MyLexer.java</code>, in the package <code>foo.bar</code>.
The <code>-l</code> flag is required as Dolmen cannot recognize the
extension of the source description.<br>
Dolmen will output information on the different phases
of the lexical analyzer generation, including any errors.
Other problem reports will be written to <code>lexer.reports</code>.</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="pygments highlight"><code data-lang="console"><span class="tok-gp">$</span> java -jar Dolmen_1.0.0.jar -l -p foo.bar --reports lexer.reports src/foo/bar/MyLexer.lexer</code></pre>
</div>
</div>
</div>
</div>
</div>
</div>
<div class="sect2">
<h3 id="_advanced_concepts">Advanced Concepts</h3>
<div class="paragraph">
<p><em>Coming soon</em></p>
</div>
<div class="sect3">
<h4 id="Lexers_Nested_Rules">Nested Rules</h4>
<div class="paragraph">
<p><em>Coming soon</em></p>
</div>
</div>
<div class="sect3">
<h4 id="Lexers_Token_Locations">Managing Token Locations</h4>
<div class="paragraph">
<p><em>Coming soon</em></p>
</div>
</div>
<div class="sect3">
<h4 id="Lexers_Tail_Recursion_Ref">Tail-Recursion</h4>
<div class="paragraph">
<p><em>Coming soon</em></p>
</div>
<div style="page-break-after: always;"></div>
</div>
</div>
<div class="sect2">
<h3 id="Lexers_Syntax_Ref">Dolmen Lexers: Syntax Reference</h3>
<div class="paragraph">
<p>In this section we present the complete syntax reference for Dolmen
lexer descriptions. We start with the lexical structure of Dolmen
lexers before describing the actual grammar of the language.</p>
</div>
<div class="sect3">
<h4 id="Lexers_Lexical_Conventions">Lexical conventions</h4>
<div class="paragraph">
<p>The following lexical conventions explain how the raw characters in a
Dolmen lexer description are split into the lexical elements that are then
used as terminals of the grammar.</p>
</div>
<div class="dlist">
<dl>
<dt class="hdlist1">White space</dt>
<dd>
<p>The five following characters are considered as white space: <em>space</em>
<code>(0x20)</code>, <em>horizontal tab</em> <code>(0x09)</code>, <em>line feed</em> <code>(0x0A)</code>, <em>form
feed</em> <code>(0x0C)</code> and <em>carriage return</em> <code>(0x0D)</code>. The line feed and
carriage return characters are called <em>line terminators</em>. White
space does not produce lexical elements but can serve as separator
between other lexical elements.</p>
</dd>
<dt class="hdlist1">Comments</dt>
<dd>
<p>Comments follow the same rules as in the Java language. They can be
either end-of-line comments <code>// &#8230;&#8203;</code> extending up to a line
terminator, or traditional multi-line comments <code>/* ... */</code>. Comments
cannot be <em>nested</em>, which means in particular that neither <code>//</code> nor
<code>/*</code> are interpreted inside a traditional multi-line comment. As
with white space, comments do not produce lexical elements but can
serve as separators between other lexical elements.</p>
</dd>
<dt class="hdlist1"><a id="JLIDENT"></a>Identifiers (<code>IDENT</code>)</dt>
<dd>
<p>Identifiers are formed by non empty-sequences of <em>letters</em> (a
lowercase letter from <code>a</code> to <code>z</code>, an uppercase letter from <code>A</code> to
<code>Z</code>, or the underscore character <code>_</code>) and <em>digits</em> (from <code>0</code> to
<code>9</code>), and <strong>must</strong> start with a letter. For instance, <code>id</code>, <code>_FOO</code>
or <code>_x32_y</code> are valid identifiers. Some otherwise valid sequences
of letters are reserved as <a href="#JLKeywords"><em>keywords</em></a> and cannot be
used as identifiers.</p>
</dd>
<dt class="hdlist1"><a id="LNAT"></a>Literal integers (<code>LNAT</code>)</dt>
<dd>
<p>A literal integer is either <code>0</code> or any non-zero digit followed by a
number of digits between <code>0</code> and <code>9</code>. Its value is interpreted as a
decimal integer. Any such sequence of digits which produces a value
that does not fit in a 32-bit <strong>signed</strong> integer results in a lexical
error.</p>
</dd>
<dt class="hdlist1"><a id="LCHAR"></a>Character literals (<code>LCHAR</code>)</dt>
<dd>
<p>A character literal is expressed as a simple character or an <em>escape
sequence</em> between single quotes <code>'&#8230;&#8203;'</code>. A simple character can be
any character other than <code>'</code>, <code>\</code> and line terminators. An escape
sequence can be any of the following:</p>
<div class="ulist">
<ul>
<li>
<p>an octal character code between <code>\000</code> and <code>\377</code>, representing the
character with the given octal ASCII code;</p>
</li>
<li>
<p>an escape sequence amongst <code>\\</code>, <code>\'</code>, <code>\"</code>, <code>\r</code> (0x0D),
<code>\n</code> (0x0A), <code>\b</code> (0x08), <code>\t</code> (0x09) and <code>\f</code> (0x0C);</p>
</li>
<li>
<p>a Unicode character code between <code>\u0000</code> and <code>\uFFFE</code>, representing
the corresponding UTF-16 <em>code unit</em>; just like in Java, there can be
any positive number of <code>u</code> characters before the actual hexadecimal
code.</p>
</li>
</ul>
</div>
<div class="exampleblock">
<div class="content">
<div class="paragraph">
<p>For instance, possible character literals are <code>'g'</code>, <code>'$'</code>, <code>'\''</code>,
<code>'\047'</code> or <code>'\uuu0027'</code>. The last three happen to all represent the
same character.</p>
</div>
</div>
</div>
<div class="paragraph">
<p>Note that the character <code>\uFFFF</code> is not allowed as it is reserved to
represent the end-of-input; it is not a valid Unicode character anyway.</p>
</div>
</dd>
<dt class="hdlist1"><a id="JLLSTRING"></a><a id="JLMLSTRING"></a>String literals (<code>LSTRING</code>, <code>MLSTRING</code>)</dt>
<dd>
<p>A string literal is expressed as a sequence of simple characters and
escape sequences between double quotes <code>"&#8230;&#8203;"</code>. A simple character
is any character other than <code>"</code> and <code>\</code>. An escape sequence is
exactly as described for <a href="#LCHAR"><em>character literals</em></a>.<br>
Unlike in Java, line terminators may be allowed inside string
literals, representing their own value. Nonetheless, single-line
string literals and multi-line string literals will produce
different lexical elements (resp. <code>LSTRING</code> and <code>MLSTRING</code>) which
can then be distinguished in the grammar. Indeed, multi-line string
literals are only syntactically valid as <a href="#JLOption">option values</a>,
and their usage elsewhere will result in a syntax error during the
parsing phase.</p>
</dd>
</dl>
</div>
<div class="admonitionblock warning">
<table>
<tr>
<td class="icon">
<i class="fa icon-warning" title="Warning"></i>
</td>
<td class="content">
Characters and escape sequences in a string literal are
  interpreted greedily in the order in which they appear, and
  therefore a <code>\</code> character will only be understood as the start of an
  escape sequence if the number of other backslash <code>\</code> that
  <strong>contiguously</strong> precede it is even (which includes zero).<br>
  Therefore, the string literal <code>"\\u006E"</code> is interpreted as an
  escaped backslash followed by <code>"u006E"</code>.
</td>
</tr>
</table>
</div>
<div class="admonitionblock tip">
<table>
<tr>
<td class="icon">
<i class="fa icon-tip" title="Tip"></i>
</td>
<td class="content">
As in Java, Unicode code points outside the Basic Multilingual
  Plane cannot be represented with a single character or escape
  sequence; one must use two code points (a
  <a href="https://docs.oracle.com/javase/tutorial/i18n/text/supplementaryChars.html"><em>surrogate
  pair</em></a>) instead. For instance, the Unicode code point <code>U+1D11E</code>,
  which is the symbol for the musical G clef &#119070;, can be
  obtained with two Unicode escape sequences <code>\uD834\uDD1E</code>.
</td>
</tr>
</table>
</div>
<div class="dlist">
<dl>
<dt class="hdlist1"><a id="JLACTION"></a>Java actions (<code>ACTION</code>)</dt>
<dd>
<p>Java actions are lexical elements which represent verbatim excerpts
of Java code. They are used as part of the semantic actions
associated to a lexer entry&#8217;s <a href="#Clause">clauses</a>, to express the
Java return type and arguments of a <a href="#Entry">lexer entry</a>, and also
for the top-level header and footer of the generated lexical
analyzer.<br>
A Java action is a block of <em>well-delimited</em> Java code between curly
braces: <code>{ &#8230;&#8203;well-delimited Java code&#8230;&#8203; }</code>. A snippet of Java code
is well-delimited if every character literal, string literal,
instruction block, method, class or comment that it contains is
correctly closed and balanced. This essentially ensures that Dolmen
is able to correctly and safely identify the closing <code>}</code> which
delimits the end of the Java action.</p>
</dd>
</dl>
</div>
<div class="exampleblock">
<div class="title">Example (Comments)</div>
<div class="content">
<div class="paragraph">
<p>The following snippet:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="pygments highlight"><code data-lang="jl"><span class="tok-g">{ </span><span class="tok-gd">// TODO Later }</span><span class="tok-g"></span></code></pre>
</div>
</div>
<div class="paragraph">
<p>is not a valid Java action because the internal end-of-line comment
is not closed inside the action. In fact the closing <code>}</code> is understood
as being part of the Java snippet and thus part of the comment (as
revealed by the syntax highlighting). Adding
a line break makes this a valid Java action:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="pygments highlight"><code data-lang="jl"><span class="tok-g">{ </span><span class="tok-gd">// TODO Later</span><span class="tok-g"></span>
<span class="tok-g">}</span></code></pre>
</div>
</div>
</div>
</div>
<div class="exampleblock">
<div class="title">Example (Literals)</div>
<div class="content">
<div class="paragraph">
<p>The following snippet:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="pygments highlight"><code data-lang="jl"><span class="tok-g">{ System.out.printf(</span><span class="tok-gs">&quot;In action \&quot;Foo\&quot;); }</span></code></pre>
</div>
</div>
<div class="paragraph">
<p>is not a valid Java action because the internal String literal
is not properly closed inside the action. Closing the literal
makes this a valid Java action:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="pygments highlight"><code data-lang="jl"><span class="tok-g">{ System.out.printf(</span><span class="tok-gs">&quot;In action \&quot;Foo\&quot;&quot;</span><span class="tok-g">); }</span></code></pre>
</div>
</div>
</div>
</div>
<div class="admonitionblock tip">
<table>
<tr>
<td class="icon">
<i class="fa icon-tip" title="Tip"></i>
</td>
<td class="content">
Dolmen&#8217;s companion <a href="https://dolmenplugin.stekikun.org">Eclipse plug-in</a> offers
     editors with syntax highlighting, including relevant syntax highlighting
     inside Java actions. It is obvious in the examples above that decent Java-aware
     syntax highlighting goes a long way in helping one avoid silly typos
     and syntactic mistakes inside Java actions.
</td>
</tr>
</table>
</div>
<div class="admonitionblock warning">
<table>
<tr>
<td class="icon">
<i class="fa icon-warning" title="Warning"></i>
</td>
<td class="content">
Dolmen&#8217;s lexical conventions for white space, comments and
         literals follow those used in the Java programming
         language. In particular, Dolmen will follow the same rules
         when encountering character or string literals inside and
         outside Java actions. There is a subtle but important
         difference between Dolmen and Java though:
         <a href="https://docs.oracle.com/javase/specs/jls/se9/html/jls-3.html#jls-3.3">unlike
         Java</a>, Dolmen does not unescape Unicode sequences in a
         <em>preliminary</em> pass but during the main lexical translation
         instead. Therefore, if one uses a Unicode escape code to
         stand for a line terminator, a delimiter or a character in an
         escape sequence, it is possible to write valid Java code that
         is not a valid Java action, or the other way around.<br>
         Consider for instance the Java literal <code>"Hello\u0022</code>: this
         is a valid Java string because <code>\u0022</code> is first replaced by
         the double quote character <code>"</code>, but as far as Dolmen is
         concerned this is an incomplete string literal whose first
         six characters were <code>Hello"</code>. Another example is <code>"\u005C"</code>
         which is a valid Dolmen string representing the single
         character <code>\</code>, and is understood by Java as being an
         incomplete string literal whose first character is <code>"</code>.<br>
</td>
</tr>
</table>
</div>
<div class="dlist">
<dl>
<dt class="hdlist1"><a id="JLKeywords"></a>Keywords</dt>
<dd>
<p>The following lower-case identifiers are reserved keywords of the
language:<br>
<code>as</code>, <code>eof</code>, <code>import</code>, <code>orelse</code>, <code>private</code>, <code>public</code>,
<code>rule</code>, <code>shortest</code>, <code>static</code>.</p>
</dd>
<dt class="hdlist1">Operators and punctuation</dt>
<dd>
<p>The following symbols serve as operators or punctuation symbols in
Dolmen lexer descriptions:<br>
<code>=</code>, <code>|</code>, <code>[</code>, <code>]</code>, <code>*</code>, <code>?</code>, <code>+</code>, <code>(</code>,
<code>)</code>, <code>^</code>, <code>-</code>, <code>#</code>, <code>.</code>, <code>&lt;</code>, <code>&gt;</code>, <code>,</code>, <code>;</code>.</p>
</dd>
</dl>
</div>
<div class="paragraph">
<p>Any input sequence which does not match any of the categories above
will result in a lexical error.</p>
</div>
</div>
<div class="sect3">
<h4 id="_grammar_of_dolmen_lexers">Grammar of Dolmen Lexers</h4>
<div class="paragraph">
<p>We give the complete grammar for Dolmen lexer descriptions below. The
terminals of the grammar are the lexical elements described <em>infra</em>,
and keywords, punctuation and operator symbols are displayed in
<strong>boldface</strong>.  The main symbol is <a href="#Lexer">Lexer</a> and we use traditional
<a href="https://en.wikipedia.org/wiki/Backus%E2%80%93Naur_form">BNF syntax</a> to
present the grammar&#8217;s rules, augmented with the usual repetition
operators <code>?</code> (at most one), <code>+</code> (at least one) and <code>*</code> (any number
of repetitions).</p>
</div>
<div class="listingblock">
<div class="content">
<pre><a id="Lexer"></a>Lexer :=
  <a href="#JLOption">Option</a>*
  <a href="#JLImport">Import</a>*
  <a href="#JLACTION">ACTION</a>        // header
  <a href="#JLDefinition">Definition</a>*
  <a href="#JLEntry">Entry</a>+
  <a href="#JLACTION">ACTION</a>        // footer</pre>
</div>
</div>
<div class="sect4">
<h5 id="_options_imports_and_auxiliary_definitions">Options, Imports and Auxiliary Definitions</h5>
<div class="listingblock">
<div class="content">
<pre><a id="JLOption"></a>Option :=
| <strong>[</strong> <a href="#JLIDENT">IDENT</a> <strong>=</strong> <a href="#JLLSTRING">MLSTRING</a> <strong>]</strong>
| <strong>[</strong> <a href="#JLIDENT">IDENT</a> <strong>=</strong> <a href="#JLMLSTRING">MLSTRING</a> <strong>]</strong></pre>
</div>
</div>
<div class="listingblock">
<div class="content">
<pre><a id="JLImport"></a>Import :=
  <strong>import</strong> (<strong>static</strong>)? <a href="#JLTypename">Typename</a> <strong>;</strong></pre>
</div>
</div>
<div class="listingblock">
<div class="content">
<pre><a id="JLTypename"></a>Typename :=
| <a href="#JLIDENT">IDENT</a>
| <a href="#JLIDENT">IDENT</a> <strong>.</strong> <a href="#JLTypename">Typename</a>
| <a href="#JLIDENT">IDENT</a> <strong>.</strong> <strong>*</strong></pre>
</div>
</div>
<div class="listingblock">
<div class="content">
<pre><a id="JLDefinition"></a>Definition :=
  <a href="#JLIDENT">IDENT</a> <strong>=</strong> <a href="#JLRegular">Regular</a> <strong>;</strong></pre>
</div>
</div>
</div>
<div class="sect4">
<h5 id="_lexer_entries_2">Lexer Entries</h5>
<div class="listingblock">
<div class="content">
<pre><a id="JLEntry"></a>Entry :=
  (<strong>public</strong> | <strong>private</strong>)
  <a href="#JLACTION">ACTION</a>            // entry's return type
  <strong>rule</strong> <a href="#JLIDENT">IDENT</a>
  (<a href="#JLACTION">ACTION</a>)?         // entry's optional arguments
  <strong>=</strong> (<strong>shortest</strong>)?     // whether shortest-match or longest-match rule is used
  <a href="#JLClause">Clause</a>+</pre>
</div>
</div>
<div class="listingblock">
<div class="content">
<pre><a id="JLClause"></a>Clause :=
| <strong>|</strong> <a href="#JLRegular">Regular</a> <a href="#JLACTION">ACTION</a>
| <strong>|</strong> <strong>orelse</strong>  <a href="#JLACTION">ACTION</a></pre>
</div>
</div>
</div>
<div class="sect4">
<h5 id="_regular_expressions_2">Regular Expressions</h5>
<div class="listingblock">
<div class="content">
<pre><a id="JLRegular"></a>Regular :=
| <a href="#JLRegular">Regular</a> <strong>as</strong> <a href="#JLIDENT">IDENT</a>    // <strong>as</strong> is left-associative
| <a href="#JLAltRegular">AltRegular</a>

<a id="JLAltRegular"></a>AltRegular :=
| <a href="#JLSeqRegular">SeqRegular</a> <strong>|</strong> <a href="#JLAltRegular">AltRegular</a>        // choice
| <a href="#JLSeqRegular">SeqRegular</a>

<a id="JLSeqRegular"></a>SeqRegular :=
| <a href="#JLPostfixRegular">PostfixRegular</a> <a href="#JLSeqRegular">SeqRegular</a>      // concatenation
| <a href="#JLPostfixRegular">PostfixRegular</a>

<a id="JLPostfixRegular"></a>PostfixRegular :=
| <a href="#JLDiffRegular">DiffRegular</a> <strong>*</strong>                    // zero, one or more occurrences
| <a href="#JLDiffRegular">DiffRegular</a> <strong>+</strong>                    // at least one occurrence
| <a href="#JLDiffRegular">DiffRegular</a> <strong>?</strong>                    // at most one occurrence
| <a href="#JLDiffRegular">DiffRegular</a> <strong>&lt;</strong> <a href="#LNAT">LNAT</a> <strong>&gt;</strong>             // fixed # of occurrences
| <a href="#JLDiffRegular">DiffRegular</a> <strong>&lt;</strong> <a href="#LNAT">LNAT</a> <strong>,</strong> <a href="#LNAT">LNAT</a> <strong>&gt;</strong>      // min. and max. # of occurrences
| <a href="#JLDiffRegular">DiffRegular</a>

<a id="JLDiffRegular"></a>DiffRegular :=
| <a href="#JLAtomicRegular">AtomicRegular</a> <strong>#</strong> <a href="#JLAtomicRegular">AtomicRegular</a>  // only with char classes
| <a href="#JLAtomicRegular">AtomicRegular</a>

<a id="JLAtomicRegular"></a>AtomicRegular :=
| <strong>_</strong>                           // all characters except <strong>eof</strong>
| <strong>eof</strong>                         // end-of-input
| <a href="#LCHAR">LCHAR</a>                       // a single character
| <a href="#JLLSTRING">LSTRING</a>                     // an exact sequence of characters
| <a href="#JLIDENT">IDENT</a>                       // defined regular expression
| <a href="#JLCharClass">CharClass</a>                   // a character class
| <strong>(</strong> <a href="#JLRegular">Regular</a> <strong>)</strong></pre>
</div>
</div>
<div class="listingblock">
<div class="content">
<pre><a id="JLCharClass"></a>CharClass :=
  <strong>[</strong> <a href="#JLCharSet">CharSet</a> <strong>]</strong>

<a id="JLCharSet"></a>CharSet :=
| <strong>^</strong> <a href="#JLCharSetPositive">CharSetPositive</a>         // complement character set
| <a href="#JLCharSetPositive">CharSetPositive</a>

<a id="JLCharSetPositive"></a>CharSetPositive :=
| <a href="#LCHAR">LCHAR</a>                     // a single character
| <a href="#LCHAR">LCHAR</a> <strong>-</strong> <a href="#LCHAR">LCHAR</a>             // a range of characters (inclusive)
| <a href="#JLIDENT">IDENT</a>                     // defined character set
| <a href="#JLCharSetPositive">CharSetPositive</a> <a href="#JLCharSetPositive">CharSetPositive</a> // union of character sets</pre>
</div>
</div>
<div style="page-break-after: always;"></div>
</div>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="Parsers">Parsers</h2>
<div class="sectionbody">
<div class="paragraph">
<p><em>Coming soon</em></p>
</div>
<div style="page-break-after: always;"></div>
<div class="sect2">
<h3 id="_dolmen_parsers_syntax_reference">Dolmen Parsers: Syntax Reference</h3>
<div class="paragraph">
<p>In this section we present the complete syntax reference for Dolmen
parser descriptions. We start with the lexical structure of Dolmen
parsers before describing the actual grammar of the language.</p>
</div>
<div class="sect3">
<h4 id="_lexical_conventions">Lexical conventions</h4>
<div class="paragraph">
<p>The following lexical conventions explain how the raw characters in a
Dolmen parser description are split into the lexical elements that are
then used as terminals of the grammar.</p>
</div>
<div class="dlist">
<dl>
<dt class="hdlist1">White space</dt>
<dd>
<p>The five following characters are considered as white space: <em>space</em>
<code>(0x20)</code>, <em>horizontal tab</em> <code>(0x09)</code>, <em>line feed</em> <code>(0x0A)</code>, <em>form
feed</em> <code>(0x0C)</code> and <em>carriage return</em> <code>(0x0D)</code>. The line feed and
carriage return characters are called <em>line terminators</em>. White
space does not produce lexical elements but can serve as separator
between other lexical elements.</p>
</dd>
<dt class="hdlist1">Comments</dt>
<dd>
<p>Comments follow the same rules as in the Java language. They can be
either end-of-line comments <code>// &#8230;&#8203;</code> extending up to a line
terminator, or traditional multi-line comments <code>/* ... */</code>. Comments
cannot be <em>nested</em>, which means in particular that neither <code>//</code> nor
<code>/*</code> are interpreted inside a traditional multi-line comment. As
with white space, comments do not produce lexical elements but can
serve as separators between other lexical elements.</p>
</dd>
<dt class="hdlist1"><a id="JGIDENT"></a>Identifiers (<code>IDENT</code>)</dt>
<dd>
<p>Identifiers are formed by non empty-sequences of <em>letters</em> (a
lowercase letter from <code>a</code> to <code>z</code>, an uppercase letter from <code>A</code> to
<code>Z</code>, or the underscore character <code>_</code>) and <em>digits</em> (from <code>0</code> to
<code>9</code>), and <strong>must</strong> start with a letter. For instance, <code>id</code>, <code>_FOO</code>
or <code>_x32_y</code> are valid identifiers. Some otherwise valid sequences
of letters are reserved as <a href="#Keywords"><em>keywords</em></a> and cannot be
used as identifiers.</p>
</dd>
<dt class="hdlist1"><a id="JGMLSTRING"></a>String literals (<code>MLSTRING</code>)</dt>
<dd>
<p>A string literal is expressed as a sequence of simple characters and
escape sequences between double quotes <code>"&#8230;&#8203;"</code>. A simple character
is any character other than <code>"</code> and <code>\</code>; in particular string literals
can span multiple lines in a Dolmen parser description. An escape
sequence can be any of the following:</p>
<div class="ulist">
<ul>
<li>
<p>an octal character code between <code>\000</code> and <code>\377</code>, representing the
character with the given octal ASCII code;</p>
</li>
<li>
<p>an escape sequence amongst <code>\\</code>, <code>\'</code>, <code>\"</code>, <code>\r</code> (0x0D),
<code>\n</code> (0x0A), <code>\b</code> (0x08), <code>\t</code> (0x09) and <code>\f</code> (0x0C);</p>
</li>
<li>
<p>a Unicode character code between <code>\u0000</code> and <code>\uFFFF</code>, representing
the corresponding UTF-16 <em>code unit</em>; just like in Java, there can be
any positive number of <code>u</code> characters before the actual hexadecimal
code.</p>
</li>
</ul>
</div>
<div class="exampleblock">
<div class="content">
<div class="paragraph">
<p>For instance, possible characters in a string literal are <code>g</code>, <code>$</code>,
<code>\'</code>, <code>\047</code> or <code>\uuu0027</code>. The last three happen to all represent
the same character.</p>
</div>
</div>
</div>
</dd>
</dl>
</div>
<div class="admonitionblock warning">
<table>
<tr>
<td class="icon">
<i class="fa icon-warning" title="Warning"></i>
</td>
<td class="content">
Characters and escape sequences in a string literal are
  interpreted greedily in the order in which they appear, and
  therefore a <code>\</code> character will only be understood as the start of an
  escape sequence if the number of other backslash <code>\</code> that
  <strong>contiguously</strong> precede it is even (which includes zero).<br>
  Therefore, the string literal <code>"\\u006E"</code> is interpreted as an
  escaped backslash followed by <code>"u006E"</code>.
</td>
</tr>
</table>
</div>
<div class="admonitionblock tip">
<table>
<tr>
<td class="icon">
<i class="fa icon-tip" title="Tip"></i>
</td>
<td class="content">
As in Java, Unicode code points outside the Basic Multilingual
  Plane cannot be represented with a single character or escape
  sequence; one must use two code points (a
  <a href="https://docs.oracle.com/javase/tutorial/i18n/text/supplementaryChars.html"><em>surrogate
  pair</em></a>) instead. For instance, the Unicode code point <code>U+1D11E</code>,
  which is the symbol for the musical G clef &#119070;, can be
  obtained with two Unicode escape sequences <code>\uD834\uDD1E</code>.
</td>
</tr>
</table>
</div>
<div class="dlist">
<dl>
<dt class="hdlist1"><a id="JGACTION"></a>Java actions (<code>ACTION</code>)</dt>
<dd>
<p>Java actions are lexical elements which represent verbatim excerpts
of Java code. They are used as part of the semantic actions
associated to a parser rule&#8217;s <a href="#JGProduction">productions</a>, to express
the Java return type of a <a href="#JGRule">rule</a> or the Java type of the
value associated to a <a href="#JGTokenDecl">token</a>, and also for the top-level
header and footer of the generated syntactic analyzer.<br>
A Java action is a block of <em>well-delimited</em> Java code between curly
braces: <code>{ &#8230;&#8203;well-delimited Java code&#8230;&#8203; }</code>. A snippet of Java code
is well-delimited if every character literal, string literal,
instruction block, method, class or comment that it contains is
correctly closed and balanced. This essentially ensures that Dolmen
is able to correctly and safely identify the closing <code>}</code> which
delimits the end of the Java action.<br>
Because Dolmen grammar rules can be <a href="#JGFormalParams">parametric</a>,
Java actions are not necessarily copied verbatim in the generated
parser: some generic parts of the Java action may undergo a
<em>substitution</em> to account for the actual instantiation of a rule&#8217;s
formal parameters. To that end, Java actions can contain
placeholders of the form <code>#<em>key</em></code> called <em>holes</em>, where <code>key</code> must be
any <a href="#JGIDENT">identifier</a> starting with a lower-case letter. When
instantiating grammar rules, these holes are filled by Dolmen
with the Java types of the formal parameters whose names match the
holes' keys. One limitation of this mechanism is that holes are
<strong>not</strong> interpreted when they appear inside a Java comment, character
literal or string literal. In other contexts, the <code>#</code> character can
safely be interpreted as a hole marker since it is not a Java separator
or operator symbol.</p>
</dd>
</dl>
</div>
<div class="exampleblock">
<div class="title">Example (Comments)</div>
<div class="content">
<div class="paragraph">
<p>The following snippet:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="pygments highlight"><code data-lang="jg"><span class="tok-g">{ </span><span class="tok-gd">// TODO Later }</span><span class="tok-g"></span></code></pre>
</div>
</div>
<div class="paragraph">
<p>is not a valid Java action because the internal end-of-line comment
is not closed inside the action. In fact the closing <code>}</code> is understood
as being part of the Java snippet and thus part of the comment (as
revealed by the syntax highlighting). Adding
a line break makes this a valid Java action:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="pygments highlight"><code data-lang="jg"><span class="tok-g">{ </span><span class="tok-gd">// TODO Later</span><span class="tok-g"></span>
<span class="tok-g">}</span></code></pre>
</div>
</div>
</div>
</div>
<div class="exampleblock">
<div class="title">Example (Literals)</div>
<div class="content">
<div class="paragraph">
<p>The following snippet:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="pygments highlight"><code data-lang="jg"><span class="tok-g">{ System.out.printf(</span><span class="tok-gs">&quot;In action \&quot;Foo\&quot;); }</span></code></pre>
</div>
</div>
<div class="paragraph">
<p>is not a valid Java action because the internal String literal
is not properly closed inside the action. Closing the literal
makes this a valid Java action:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="pygments highlight"><code data-lang="jg"><span class="tok-g">{ System.out.printf(</span><span class="tok-gs">&quot;In action \&quot;Foo\&quot;&quot;</span><span class="tok-g">); }</span></code></pre>
</div>
</div>
</div>
</div>
<div class="exampleblock">
<div class="title">Example (Holes)</div>
<div class="content">
<div class="paragraph">
<p>The following snippet:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="pygments highlight"><code data-lang="jg"><span class="tok-g">{</span>
<span class="tok-g">  </span><span class="tok-gd">// See A#foo()</span><span class="tok-g"></span>
<span class="tok-g">  List&lt;</span><span class="tok-gi">#elt</span><span class="tok-g">&gt; l = </span><span class="tok-ge">new</span><span class="tok-g"> ArrayList&lt;</span><span class="tok-gi">#elt</span><span class="tok-g">&gt;();</span>
<span class="tok-g">}</span></code></pre>
</div>
</div>
<div class="paragraph">
<p>is a valid Java action with holes referencing some formal
parameter <code>elt</code>. The <code>#foo</code> in the comment is not
interpreted as a hole.</p>
</div>
</div>
</div>
<div class="admonitionblock tip">
<table>
<tr>
<td class="icon">
<i class="fa icon-tip" title="Tip"></i>
</td>
<td class="content">
Dolmen&#8217;s companion <a href="https://dolmenplugin.stekikun.org">Eclipse
     plug-in</a> offers editors with syntax highlighting, including
     relevant syntax highlighting inside Java actions which also
     recognizes holes. It is obvious in the examples above that decent
     Java-aware syntax highlighting goes a long way in helping one
     avoid silly typos and syntactic mistakes inside Java actions.
</td>
</tr>
</table>
</div>
<div class="admonitionblock warning">
<table>
<tr>
<td class="icon">
<i class="fa icon-warning" title="Warning"></i>
</td>
<td class="content">
Dolmen&#8217;s lexical conventions for white space, comments and
         literals follow those used in the Java programming
         language. In particular, Dolmen will follow the same rules
         when encountering character or string literals inside and
         outside Java actions. There is a subtle but important
         difference between Dolmen and Java though:
         <a href="https://docs.oracle.com/javase/specs/jls/se9/html/jls-3.html#jls-3.3">unlike
         Java</a>, Dolmen does not unescape Unicode sequences in a
         <em>preliminary</em> pass but during the main lexical translation
         instead. Therefore, if one uses a Unicode escape code to
         stand for a line terminator, a delimiter or a character in an
         escape sequence, it is possible to write valid Java code that
         is not a valid Java action, or the other way around.<br>
         Consider for instance the Java literal <code>"Hello\u0022</code>: this
         is a valid Java string because <code>\u0022</code> is first replaced by
         the double quote character <code>"</code>, but as far as Dolmen is
         concerned this is an incomplete string literal whose first
         six characters were <code>Hello"</code>. Another example is <code>"\u005C"</code>
         which is a valid Dolmen string representing the single
         character <code>\</code>, and is understood by Java as being an
         incomplete string literal whose first character is <code>"</code>.<br>
</td>
</tr>
</table>
</div>
<div class="dlist">
<dl>
<dt class="hdlist1"><a id="JGARGUMENTS"></a>Java arguments (<code>ARGUMENTS</code>)</dt>
<dd>
<p>Java arguments are very similar to <a href="#JGACTION">Java actions</a> in that
they are lexical elements which represent verbatim excerpts of Java
code. They are used to declare a <a href="#JGRule">parser rule</a>'s arguments
and to pass arguments to a non-terminal in a
<a href="#JGProduction">production</a>.<br>
Java arguments are formed by a block of <em>well-delimited</em> Java code
between parentheses: <code>( &#8230;&#8203;well-delimited Java code&#8230;&#8203; )</code>. The
snippet of Java code is well-delimited if every character literal,
string literal, or parenthesized expression that it
contains is correctly closed and balanced. This essentially ensures
that Dolmen is able to correctly and safely identify the closing <code>)</code>
which delimits the end of the Java arguments.<br>
Like Java actions, Java arguments can contain <em>holes</em> in the form of
identifiers introduced by a <code>#</code> character. Holes are only interpreted
outside Java comments and literals.</p>
</dd>
<dt class="hdlist1"><a id="Keywords"></a>Keywords</dt>
<dd>
<p>The following lower-case identifiers are reserved keywords of the
language:<br>
<code>continue</code>, <code>import</code>, <code>private</code>, <code>public</code>,
<code>rule</code>, <code>static</code>, <code>token</code>.</p>
</dd>
<dt class="hdlist1">Operators and punctuation</dt>
<dd>
<p>The following symbols serve as operators or punctuation symbols in
Dolmen lexer descriptions:<br>
<code>=</code>, <code>|</code>, <code>[</code>, <code>]</code>, <code>.</code>, <code>&lt;</code>, <code>&gt;</code>, <code>,</code>, <code>;</code>.</p>
</dd>
</dl>
</div>
<div class="paragraph">
<p>Any input sequence which does not match any of the categories above
will result in a lexical error.</p>
</div>
</div>
<div class="sect3">
<h4 id="_grammar_of_dolmen_parsers">Grammar of Dolmen Parsers</h4>
<div class="paragraph">
<p>We give the complete grammar for Dolmen parser descriptions below. The
terminals of the grammar are the lexical elements described <em>infra</em>,
and keywords, punctuation and operator symbols are displayed in
<strong>boldface</strong>.  The main symbol is <a href="#JGParser">Parser</a> and we use traditional
<a href="https://en.wikipedia.org/wiki/Backus%E2%80%93Naur_form">BNF syntax</a> to
present the grammar&#8217;s rules, augmented with the usual repetition
operators <code>?</code> (at most one), <code>+</code> (at least one) and <code>*</code> (any number
of repetitions).</p>
</div>
<div class="listingblock">
<div class="content">
<pre><a id="JGParser"></a>Parser :=
  <a href="#JGOption">Option</a>*
  <a href="#JGImport">Import</a>*
  <a href="#JGTokenDecl">TokenDecl</a>*
  <a href="#JGACTION">ACTION</a>        // header
  <a href="#JGRule">Rule</a>*
  <a href="#JGACTION">ACTION</a>        // footer</pre>
</div>
</div>
<div class="sect4">
<h5 id="_options_imports_and_auxiliary_definitions_2">Options, Imports and Auxiliary Definitions</h5>
<div class="listingblock">
<div class="content">
<pre><a id="JGOption"></a>Option :=
  <strong>[</strong> <a href="#JGIDENT">IDENT</a> <strong>=</strong> <a href="#JGMLSTRING">MLSTRING</a> <strong>]</strong></pre>
</div>
</div>
<div class="listingblock">
<div class="content">
<pre><a id="JGImport"></a>Import :=
  <strong>import</strong> (<strong>static</strong>)? <a href="#JGTypename">Typename</a> <strong>;</strong></pre>
</div>
</div>
<div class="listingblock">
<div class="content">
<pre><a id="JGTypename"></a>Typename :=
| <a href="#JGIDENT">IDENT</a>
| <a href="#JGIDENT">IDENT</a> <strong>.</strong> <a href="#JGTypename">Typename</a>
| <a href="#JGIDENT">IDENT</a> <strong>.</strong> <strong>*</strong></pre>
</div>
</div>
</div>
<div class="sect4">
<h5 id="_token_declarations">Token Declarations</h5>
<div class="listingblock">
<div class="content">
<pre><a id="JGTokenDecl"></a>TokenDecl :=
  <strong>token</strong> (<a href="#JGACTION">ACTION</a>)? <a href="#JGIDENT">IDENT</a>+      // all uppercase identifiers only</pre>
</div>
</div>
</div>
<div class="sect4">
<h5 id="_grammar_rules_and_productions">Grammar Rules and Productions</h5>
<div class="listingblock">
<div class="content">
<pre><a id="JGRule"></a>Rule :=
  (<strong>public</strong> | <strong>private</strong>)
  <a href="#JGACTION">ACTION</a>              // rule's return type
  <strong>rule</strong> <a href="#JGIDENT">IDENT</a>          // must start with lowercase letter
  (<a href="#JGFormalParams">FormalParams</a>)?     // rule's optional formal parameters
  (<a href="#JGARGUMENTS">ARGUMENTS</a>)?        // rule's optional arguments
  <strong>=</strong> <a href="#JGProduction">Production</a>+ <strong>;</strong>

<a id="JGFormalParams"></a>FormalParams :=
  <strong>&lt;</strong> <a href="#JGIDENT">IDENT</a> (<strong>,</strong> <a href="#JGIDENT">IDENT</a>)* <strong>&gt;</strong>    //  formals must start with lowercase letter

<a id="JGProduction"></a>Production :=
  <strong>|</strong> <a href="#JGItem">Item</a>*</pre>
</div>
</div>
</div>
<div class="sect4">
<h5 id="_production_items_and_actuals">Production Items and Actuals</h5>
<div class="listingblock">
<div class="content">
<pre><a id="JGItem"></a>Item :=
| <a href="#JGACTION">ACTION</a>                     // a semantic action
| (<a href="#JGIDENT">IDENT</a> <strong>=</strong>)? <a href="#JGActual">Actual</a>          // a grammar symbol, potentially bound to some value
| <strong>continue</strong>                   // can only appear last in a production</pre>
</div>
</div>
<div class="listingblock">
<div class="content">
<pre><a id="JGActual"></a>Actual :=
  <a href="#JGActualExpr">ActualExpr</a> (<a href="#JGARGUMENTS">ARGUMENTS</a>)?         // optional arguments to the actual</pre>
</div>
</div>
<div class="listingblock">
<div class="content">
<pre><a id="JGActualExpr"></a>ActualExpr :=
| <a href="#JGIDENT">IDENT</a>                                  // a terminal or ground non-terminal
| <a href="#JGIDENT">IDENT</a> <strong>&lt;</strong> <a href="#JGActualExpr">ActualExpr</a> (<strong>,</strong> <a href="#JGActualExpr">ActualExpr</a>)* <strong>&gt;</strong>   // application of a parametric non-terminal</pre>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
<div id="footer">
<div id="footer-text">
Last updated 2020-02-02 00:42:06 CET
</div>
</div>
</body>
</html>